{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projeto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/projeto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP583IXGNeHC",
        "colab_type": "text"
      },
      "source": [
        "# Projeto de Simplificação de Texto\n",
        "\n",
        "Nas primeiras abordagens, houve uma tentativa de produzir uma rede neural que tivesse como entrada o *token frequence* e saida outro *token frequence*. Apesar disso poder ser considerado um resultado válido para a tentativa de melhorar a classificação de texto, não podemos considerar uma frase como um conjunto de palavras com a propriedade da comutatividade. A ordem das palavras acaba importando muito para os humanos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptDnWb-pbJUb",
        "colab_type": "text"
      },
      "source": [
        "## importando bugingangas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh5apxspbJ0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "from urllib import request as req\n",
        "from gensim.models import keyedvectors as kv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQFno4IJOzW3",
        "colab_type": "text"
      },
      "source": [
        "## Paper With Code\n",
        "\n",
        "~~Após um gole de sorte, eu acabo por encontrar essa maravilha~~ chamado de [Paper With Code](https://paperswithcode.com/sota/document-summarization-on-cnn-daily-mail), é um ~~bom~~ compilado de resultados cientificos sobre determinados problemas da computação. O primeiro artigo do link de cima, mostra uma solução com ROGUE-1 de 43.83 para o problema de sumarização de documentos como o *state of the art*.\n",
        "\n",
        "![paper with code](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/paperwithcode.png?raw=true)\n",
        "<center>paper with code</center>\n",
        "\n",
        "No artigo *Text Summarization with Pretrained Encoders* (LIU e LAPATA, 2019), os autores representam o texto como *Bert*, que é gerado por uma rede neural e é um caso especial do *word2vec*.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npzGa9dI5viX",
        "colab_type": "text"
      },
      "source": [
        "## Representação do Bert word2vec\n",
        "\n",
        "*Kyubyong* criou um preset do Bert, um dicionário onde cada palavra é representada por um vetor de 768 valores decimais. Visto algumas limitações das plataformas *Google Colab* e do *Github*, serão usadas apenas 300 instâncias do CNN, que gerou um dicionário reduzido de apenas 25mb.\n",
        "\n",
        "![Bert is Evil](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/audio-banner.jpg?raw=true)\n",
        "<center>Bert is Evil</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iap7h5R65zWn",
        "colab_type": "text"
      },
      "source": [
        "## Base de dados CNN\n",
        "\n",
        "A base de dados pode ser encontrado [nesse github da google](https://github.com/google-research-datasets/sentence-compression), no formato *Json*. Essa base de dados é formada com notícias da CNN com a primeira linha da noticia, com o título, com todos os bigramas possíveis e com informações do NER. Porém no trabalho apenas será usado a primeira linha como entrada e o título como saída.\n",
        "\n",
        "![Json](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/Jasonf.jpg?raw=true)\n",
        "<center>Json</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKjJH3pbaixJ",
        "colab_type": "text"
      },
      "source": [
        "## Abrindo uma noticia (bert) e convertendo para texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6WEsqOPajg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "7f98ccec-bb16-4052-e7fc-b29465f74e36"
      },
      "source": [
        "# Abrindo o dicionario\n",
        "dicurl = 'https://raw.githubusercontent.com/x-channel/Mining-Text-Simplifica-o-de-Texto/master/dataset/dicionario.csv'\n",
        "#dicloader = req.urlopen(dicurl)\n",
        "dicio = []\n",
        "\n",
        "with req.urlopen(dicurl) as f:\n",
        "  #print(f.read()[0:20000].decode())\n",
        "  meucsv = f.read().decode('charmap')\n",
        "  meucsv = meucsv.split('\\n')\n",
        "  print(meucsv[0])\n",
        "  #data = csv.reader(meucsv)\n",
        "  print(type(data))\n",
        "  print(len(meucsv))\n",
        "  for i in meucsv:\n",
        "    dicio.append(i)\n",
        "\n",
        "print(dicio[0])\n",
        "\n",
        "#abrindo a noticia\n",
        "#nn = input(\"digite um numero entre 0 e 199: \")\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "five,-0.00221736589,-0.000327187416,-0.024606755,-0.0176957119,0.0173947439,-0.0174167212,-0.0306010358,-0.00145815569,0.0187633559,-0.0108142281,0.0432017148,-0.0502034388,-0.00846801512,-0.0576570071,0.0322442949,-0.020834649,-0.0111211119,0.00136801903,0.00872333068,0.0229032859,-0.0216196161,-0.0165795088,0.0135502145,-0.0349892341,-0.0627112761,0.0271395817,0.0384537391,-0.00406109542,-0.0425047055,-0.0520481579,-0.00754025206,-0.0537302122,0.00043773267,-0.0310549233,-0.0576889291,-0.0168994479,0.0107453763,0.012590304,-0.0184273627,-0.0116608078,-0.0242777597,-0.0558727495,-0.0306073502,-0.0593236089,-0.0174500663,0.00768886693,-0.0218660533,0.0144082364,0.00758720376,0.0240487028,0.00155591127,0.026569115,-0.00286716945,0.0214601867,0.00812067464,-0.0130317695,0.0433732457,-0.061860837,-0.0274253748,0.0190580823,-0.0728581473,-0.0425258093,-0.0313723385,-0.0307020862,-0.0634120479,0.00250072358,-0.0189387277,-0.0331520401,-0.0607296601,0.0383252986,0.0210423823,-0.0433877259,-0.0667930916,-0.058501482,-0.0388801806,-0.0101490319,-0.063200362,0.00195891294,0.0155744478,0.01527113,0.0335751697,0.0406874977,0.00296703726,-0.0188105125,-0.0716511682,0.0058816052,0.0367320366,0.024193801,0.00182745699,-0.0137877492,-0.0448959284,-0.0358709693,-0.0119221918,-0.00642860355,0.0124006374,-0.0174523965,-0.0502866171,-0.0122667551,0.0396837853,0.00145396695,0.0254955478,0.0146387238,-0.0106961941,-0.0118623795,-0.0604580231,0.0246737022,-0.0539759025,-0.0507545769,-0.0237876978,-0.0503818728,-0.0428179391,0.0107089467,0.0266649053,-0.0514964946,-0.00470005302,-0.0140664773,0.0243687127,0.013255382,0.00509580458,0.00575726712,0.0507485121,0.0432396047,-0.0204801075,-0.030664403,-0.0129700704,-0.077774033,0.0232538022,-0.0152484626,-0.000333510136,0.0324048959,-0.0621734858,0.0263224598,0.0330513753,-0.018834589,-0.04202874,0.0246960577,-0.0528197177,-0.0224688686,0.0232917052,-0.00697160698,-0.0107221575,-0.0214143023,-0.0427947976,-0.00141149049,0.0247105416,0.03034858\n",
            "<class '_csv.reader'>\n",
            "25550798\n",
            "['f']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK4CtNKfAFwv",
        "colab_type": "text"
      },
      "source": [
        "## Referencias\n",
        "\n"
      ]
    }
  ]
}