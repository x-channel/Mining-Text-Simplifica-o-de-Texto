{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projeto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/projeto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP583IXGNeHC",
        "colab_type": "text"
      },
      "source": [
        "# Projeto de Simplificação de Texto\n",
        "\n",
        "Nas primeiras abordagens, houve uma tentativa de produzir uma rede neural que tivesse como entrada o *token frequence* e saida outro *token frequence*.\n",
        " Apesar disso poder ser considerado um resultado válido para a tentativa de melhorar a classificação de texto, não podemos considerar uma frase como um conjunto de palavras com a propriedade da comutatividade.\n",
        "  A ordem das palavras acaba importando muito para os humanos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptDnWb-pbJUb",
        "colab_type": "text"
      },
      "source": [
        "## importando bugingangas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh5apxspbJ0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import random\n",
        "#import pandas as pd\n",
        "from urllib import request as req\n",
        "from gensim.models import keyedvectors as kv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQFno4IJOzW3",
        "colab_type": "text"
      },
      "source": [
        "## Paper With Code\n",
        "\n",
        "~~Após um gole de sorte, eu acabo por encontrar essa maravilha~~ chamado de [Paper With Code](https://paperswithcode.com/sota/document-summarization-on-cnn-daily-mail), é um ~~bom~~ compilado de resultados cientificos sobre determinados problemas da computação. O primeiro artigo do link de cima, mostra uma solução com ROGUE-1 de 43.83 para o problema de sumarização de documentos como o *state of the art*.\n",
        "\n",
        "![paper with code](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/paperwithcode.png?raw=true)\n",
        "<center>paper with code</center>\n",
        "\n",
        "No artigo *Text Summarization with Pretrained Encoders* (LIU e LAPATA, 2019), os autores representam o texto como *Bert*, que é gerado por uma rede neural e é um caso especial do *word2vec*.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npzGa9dI5viX",
        "colab_type": "text"
      },
      "source": [
        "## Representação do Bert word2vec\n",
        "\n",
        "*Kyubyong* criou um preset do Bert, um dicionário onde cada palavra é representada por um vetor de 768 valores decimais.\n",
        "Visto algumas limitações das plataformas *Google Colab* e do *Github*, serão usadas apenas 300 instâncias do CNN, que gerou um dicionário reduzido de apenas 25mb.\n",
        "\n",
        "![Bert is Evil](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/audio-banner.jpg?raw=true)\n",
        "<center>Bert is Evil</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iap7h5R65zWn",
        "colab_type": "text"
      },
      "source": [
        "## Base de dados da Cable News Network\n",
        "\n",
        "A base de dados pode ser encontrado [nesse github da google](https://github.com/google-research-datasets/sentence-compression), no formato *Json*. Essa base de dados é formada com notícias da CNN com a primeira linha da noticia, com o título, com todos os bigramas possíveis e com informações do TAG. Porém no trabalho apenas será usado a primeira linha como entrada e o título como saída.\n",
        "\n",
        "![Json](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/Jasonf.jpg?raw=true)\n",
        "<center>Json</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Nkg503WqUi",
        "colab_type": "text"
      },
      "source": [
        "## Mesclar o bert com o json.\n",
        "\n",
        "Basicamente esse script carrega o vocabulário do dicionário bert, onde a partir da segunda linha, cada linha é uma palavra, seguida de sua representação vetorial com 768 valores.\n",
        "Eventualmente aparecem algumas palavras estranhas como \"##,\".\n",
        "Essa palavra significa somente que a palavra anterior termina com uma virgula.\n",
        "\n",
        "Depois de carregar o vocabulário, ele começa a ler as noticias do json.\n",
        "Ele segmenta uma noticia, a transformando em um dicionário do python, procura os textos alvos\n",
        "### jfk['graph']['sentence'] e jfk['headline'].\n",
        "\n",
        "Com os textos em mãos, ele cata as palavras de cada texto, criando uma matriz de tamanho 768*2 pela quantidade de linhas do subtitulo da noticia.\n",
        "\n",
        "Observar que para esse código rodar ele deve estar na seguinte pasta ~~por isso está comentado~~. Com o json nomeado *in.json*, com o bert nomeado *dicionariolongo.vec* e uma pasta vazia chamada de *instancias*. O script vai gerar um *dicionario.csv* e varias noticias dentro da pasta instancias. Infelizmente algumas noticias tem caracters que não permitem seu uso como nome do arquivo, por isso todas as noticias foram nomeadas de *arquivo_n.csv* ~~Outro motivo para você guardar seus dados em um único arquivo json~~.\n",
        "\n",
        ">O diretório do arquivo.\n",
        ">>in.json \\n\n",
        "dicionariolongo.vec \\n\n",
        "preprobert.py\n",
        ">>> instancias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Uesl-rWdP1",
        "colab_type": "code",
        "outputId": "7fdf54b0-2e68-4e3b-b415-0a7b42ccd900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "#texto para matriz Bert\n",
        "\n",
        "#!/usr/bin/python\n",
        "# -*- coding: UTF-8 -*-\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "import fileinput\n",
        "\n",
        "import codecs\n",
        "\n",
        "import os\n",
        "\n",
        "dici = {}\n",
        "fins = {}\n",
        "dico = {} #dicionario reduzido\n",
        "\n",
        "\n",
        "#carrega o dicionario bert\n",
        "with open(\"dicionariolongo.vec\", \"r\", encoding=\"utf-8\") as d:\n",
        "    for i in d:\n",
        "        if len(i) > 200: #isso aqui eh para tirar a primeira linha, altura x largura\n",
        "            try:\n",
        "                a = i.split()\n",
        "                if '##' in a[0]:\n",
        "                    fins[a[0][2:].lower()] = []\n",
        "                    for j in a[1:]:\n",
        "                        fins[a[0][2:].lower()].append(float(j))\n",
        "                elif (not a[0].lower() in dici) or a[0].islower():\n",
        "                    dici[a[0].lower()] = []\n",
        "                    for j in a[1:]:\n",
        "                        dici[a[0].lower()].append(float(j))\n",
        "            except ValueError:\n",
        "                print(\"problema com uma palavra\")\n",
        "\n",
        "\n",
        "\n",
        "with open(\"in.json\", 'rb') as f:\n",
        "    data = f.read()\n",
        "\n",
        "data = str(data)[2:-1]\n",
        "data = data.replace('\\\\n}', '\\\\n}-----')\n",
        "data = data.split('-----')\n",
        "\n",
        "blanckl = []\n",
        "for i in range(768):\n",
        "    blanckl.append('')\n",
        "\n",
        "instancias = 0\n",
        "for p in data[0:-1]:\n",
        "    entrada = []\n",
        "    saida = []\n",
        "    try:\n",
        "        jfk = json.loads(codecs.decode(p, 'unicode_escape'))\n",
        "        arquivo = jfk['graph']['sentence'].lower().replace(\"/\",\"\").replace(\"\\\\\",\"\")\n",
        "        lg = jfk['graph']['sentence'].lower().split()\n",
        "        st = jfk['headline'].lower().split()\n",
        "\n",
        "        for i in lg: #isso deveria ser uma funcao, addlist() #semTempo\n",
        "            if i in dico: #dicionario reduzido\n",
        "                entrada.append(dico[i])\n",
        "            elif i in dici:\n",
        "                dico[i] = dici[i]\n",
        "                entrada.append(dico[i])\n",
        "            else:\n",
        "                for j, jj in fins.items():\n",
        "                    if j in i[-len(j):]:\n",
        "                        i = i[:-len(j)]\n",
        "                        if i in dico: #assim ela poderia ser chamada aqui\n",
        "                            entrada.append(dico[i])\n",
        "                        elif i in dici:\n",
        "                            dico[i] = dici[i]\n",
        "                            entrada.append(dico[i])\n",
        "                        if j in dico:\n",
        "                            entrada.append(dico[j])\n",
        "                        else:\n",
        "                            dico[j] = fins[j]\n",
        "                            entrada.append(dico[j])\n",
        "                        break\n",
        "        for i in st: #isso deveria ser uma funcao, addlist() #semTempo\n",
        "            if i in dico: #dicionario reduzido\n",
        "                saida.append(dico[i])\n",
        "            elif i in dici:\n",
        "                dico[i] = dici[i]\n",
        "                saida.append(dico[i])\n",
        "            else:\n",
        "                for j, jj in fins.items():\n",
        "                    if j in i[-len(j):]:\n",
        "                        i = i[:-len(j)]\n",
        "                        if i in dico: #assim ela poderia ser chamada aqui\n",
        "                            saida.append(dico[i])\n",
        "                        elif i in dici:\n",
        "                            dico[i] = dici[i]\n",
        "                            saida.append(dico[i])\n",
        "                        if j in dico:\n",
        "                            saida.append(dico[j])\n",
        "                        else:\n",
        "                            dico[j] = fins[j]\n",
        "                            saida.append(dico[j])\n",
        "                        break\n",
        "    except ValueError:\n",
        "        print(\"Houve um Erro\")\n",
        "\n",
        "        \n",
        "    sv = os.getcwd() + '\\\\instancias\\\\arquivo_%i'%instancias + '.csv'\n",
        "    instancias += 1\n",
        "    try:\n",
        "        with open(sv, 'w', newline = '') as file:\n",
        "            writer = csv.writer(file)\n",
        "            tam = 0\n",
        "            while tam < len(entrada):\n",
        "                tm = []\n",
        "                #print(type(tm))\n",
        "                tm.extend(entrada[tam])\n",
        "                if tam < len(saida):\n",
        "                    tm.extend(saida[tam])\n",
        "                else:\n",
        "                    tm.extend(blanckl)\n",
        "                tam += 1\n",
        "                writer.writerow(tm)\n",
        "    except ValueError:\n",
        "        print(\"erro no json\")\n",
        "\n",
        "with open(\"dicionario.csv\", \"w\", newline = '') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for i, ii in dico.items():\n",
        "\ttm = []\n",
        "\ttm.append(i)\n",
        "\ttm.extend(ii)\n",
        "        writer.writerow(tm)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#texto para matriz Bert\\n\\n#!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\n\\nimport pandas as pd\\nimport csv\\n\\nimport nltk\\nimport numpy as np\\n\\nimport json\\nimport fileinput\\n\\nimport codecs\\n\\nimport os\\n\\ndici = {}\\nfins = {}\\ndico = {} #dicionario reduzido\\n\\n\\n#carrega o dicionario bert\\nwith open(\"dicionariolongo.vec\", \"r\", encoding=\"utf-8\") as d:\\n    for i in d:\\n        if len(i) > 200: #isso aqui eh para tirar a primeira linha, altura x largura\\n            try:\\n                a = i.split()\\n                if \\'##\\' in a[0]:\\n                    fins[a[0][2:].lower()] = []\\n                    for j in a[1:]:\\n                        fins[a[0][2:].lower()].append(float(j))\\n                elif (not a[0].lower() in dici) or a[0].islower():\\n                    dici[a[0].lower()] = []\\n                    for j in a[1:]:\\n                        dici[a[0].lower()].append(float(j))\\n            except ValueError:\\n                print(\"problema com uma palavra\")\\n\\n\\n\\nwith open(\"in.json\", \\'rb\\') as f:\\n    data = f.read()\\n\\ndata = str(data)[2:-1]\\ndata = data.replace(\\'\\\\n}\\', \\'\\\\n}-----\\')\\ndata = data.split(\\'-----\\')\\n\\nblanckl = []\\nfor i in range(768):\\n    blanckl.append(\\'\\')\\n\\ninstancias = 0\\nfor p in data[0:-1]:\\n    entrada = []\\n    saida = []\\n    try:\\n        jfk = json.loads(codecs.decode(p, \\'unicode_escape\\'))\\n        arquivo = jfk[\\'graph\\'][\\'sentence\\'].lower().replace(\"/\",\"\").replace(\"\\\\\",\"\")\\n        lg = jfk[\\'graph\\'][\\'sentence\\'].lower().split()\\n        st = jfk[\\'headline\\'].lower().split()\\n\\n        for i in lg: #isso deveria ser uma funcao, addlist() #semTempo\\n            if i in dico: #dicionario reduzido\\n                entrada.append(dico[i])\\n            elif i in dici:\\n                dico[i] = dici[i]\\n                entrada.append(dico[i])\\n            else:\\n                for j, jj in fins.items():\\n                    if j in i[-len(j):]:\\n                        i = i[:-len(j)]\\n                        if i in dico: #assim ela poderia ser chamada aqui\\n                            entrada.append(dico[i])\\n                        elif i in dici:\\n                            dico[i] = dici[i]\\n                            entrada.append(dico[i])\\n                        if j in dico:\\n                            entrada.append(dico[j])\\n                        else:\\n                            dico[j] = fins[j]\\n                            entrada.append(dico[j])\\n                        break\\n        for i in st: #isso deveria ser uma funcao, addlist() #semTempo\\n            if i in dico: #dicionario reduzido\\n                saida.append(dico[i])\\n            elif i in dici:\\n                dico[i] = dici[i]\\n                saida.append(dico[i])\\n            else:\\n                for j, jj in fins.items():\\n                    if j in i[-len(j):]:\\n                        i = i[:-len(j)]\\n                        if i in dico: #assim ela poderia ser chamada aqui\\n                            saida.append(dico[i])\\n                        elif i in dici:\\n                            dico[i] = dici[i]\\n                            saida.append(dico[i])\\n                        if j in dico:\\n                            saida.append(dico[j])\\n                        else:\\n                            dico[j] = fins[j]\\n                            saida.append(dico[j])\\n                        break\\n    except ValueError:\\n        print(\"Houve um Erro\")\\n\\n        \\n    sv = os.getcwd() + \\'\\\\instancias\\\\arquivo_%i\\'%instancias + \\'.csv\\'\\n    instancias += 1\\n    try:\\n        with open(sv, \\'w\\', newline = \\'\\') as file:\\n            writer = csv.writer(file)\\n            tam = 0\\n            while tam < len(entrada):\\n                tm = []\\n                #print(type(tm))\\n                tm.extend(entrada[tam])\\n                if tam < len(saida):\\n                    tm.extend(saida[tam])\\n                else:\\n                    tm.extend(blanckl)\\n                tam += 1\\n                writer.writerow(tm)\\n    except ValueError:\\n        print(\"erro no json\")\\n\\nwith open(\"dicionario.csv\", \"w\", newline = \\'\\') as file:\\n    writer = csv.writer(file)\\n    for i, ii in dico.items():\\n\\ttm = []\\n\\ttm.append(i)\\n\\ttm.extend(ii)\\n        writer.writerow(tm)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKjJH3pbaixJ",
        "colab_type": "text"
      },
      "source": [
        "## Abrindo uma noticia (bert) e convertendo para texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6WEsqOPajg1",
        "colab_type": "code",
        "outputId": "eb50f475-cbfb-4fb1-85fb-ec8770c0fb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# Abrindo o dicionario criado com o outro script\n",
        "dicurl = 'https://raw.githubusercontent.com/x-channel/Mining-Text-Simplifica-o-de-Texto/master/dataset/dicionario.csv'\n",
        "#dicloader = req.urlopen(dicurl)\n",
        "vetores = []\n",
        "palavras = []\n",
        "\n",
        "with req.urlopen(dicurl) as f:\n",
        "  meucsv = f.read().decode('charmap')\n",
        "  meucsv = meucsv.split('\\n')[:-1]\n",
        "  for i in meucsv:\n",
        "    j = i.replace('\\r','').split(',')\n",
        "    palavras.append(j[0])\n",
        "    vetores.append(j[1:])\n",
        "\n",
        "# colocando o dicionario no gensim.\n",
        "dicio = kv.Word2VecKeyedVectors(768)\n",
        "dicio.add(palavras, np.array(vetores).astype(float))\n",
        "\n",
        "#busca por um vetor parecido\n",
        "five = dicio.get_vector('five')\n",
        "friends = dicio.get_vector('friends')\n",
        "\n",
        "print(dicio.similar_by_vector(five, 1), dicio.similar_by_vector(friends, 1))\n",
        "\n",
        "#abrindo a noticia\n",
        "#nn = input(\"digite um numero entre 0 e 199: \")\n",
        "nn = 1\n",
        "noticia = 'https://raw.githubusercontent.com/x-channel/Mining-Text-Simplifica-o-de-Texto/master/dataset/noticias/arquivo_%i.csv'%nn\n",
        "\n",
        "pastaNoticias = 'https://raw.githubusercontent.com/x-channel/Mining-Text-Simplifica-o-de-Texto/master/dataset/noticias/%s_%i.csv'\n",
        "\n",
        "def abrirNoticia(urlnoticia):\n",
        "  sentence = []\n",
        "  head = []\n",
        "  with req.urlopen(urlnoticia) as f:\n",
        "    meucsv = f.read().decode('charmap')\n",
        "    meucsv = meucsv.split('\\n')[:-1]\n",
        "    for i in meucsv:\n",
        "      j = i.replace('\\r',',').replace(',,', ',0.0,').replace(',,', ',0.0,')[:-1]\n",
        "      j = j.split(',')\n",
        "      sentence.append(j[:768])\n",
        "      head.append(j[768:])\n",
        "  sentence = np.array(sentence).astype(float)\n",
        "  head = np.array(head).astype(float)\n",
        "  return sentence, head\n",
        "\n",
        "def abrirNoticias(urlfolder, total, nome = 'arquivo'):\n",
        "  primeiro = []\n",
        "  cabecalh = []\n",
        "  for i in range(total):\n",
        "    par = abrirNoticia(urlfolder%(nome,i))\n",
        "    primeiro.append(par[0])\n",
        "    cabecalh.append(par[1])\n",
        "  return np.array(primeiro),np.array(cabecalh)\n",
        "\n",
        "\n",
        "def vec2head(matriz, model, li):\n",
        "  head = []\n",
        "  for i in matriz:\n",
        "    j = model.similar_by_vector(i,1)\n",
        "    if j[0][1] > li:\n",
        "      head.append(j)\n",
        "  return head\n",
        "\n",
        "s, h = abrirNoticia(noticia)\n",
        "\n",
        "titulo = vec2head(h, dicio, 0.5)\n",
        "print (titulo)\n",
        "\n",
        "noticias,cabecalhos = abrirNoticias(pastaNoticias, 200)\n",
        "print(vec2head(noticias[1], dicio, 0.5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('five', 1.0)] [('friends', 1.0)]\n",
            "[[('several', 1.0)], [('school', 1.0)], [('districts', 1.0)], [('hold', 1.0)], [('classes', 1.0)], [('on', 1.0)], [('president', 0.6351367831230164)], [(\"##'\", 0.9999998807907104)], [('day', 1.0000001192092896)], [('to', 1.0)], [('make', 1.0)], [('up', 1.0000001192092896)], [('for', 1.0)], [('days', 1.0)], [('missed', 1.0)]]\n",
            "[[('several', 1.0)], [('school', 1.0)], [('districts', 1.0)], [('in', 1.0)], [('hampton', 1.0)], [('roads', 1.0)], [('are', 0.9999999403953552)], [('holding', 1.0)], [('classes', 1.0)], [('this', 1.0000001192092896)], [('president', 0.6351367831230164)], [(\"##'\", 0.9999998807907104)], [('day', 1.0000001192092896)], [('to', 1.0)], [('make', 1.0)], [('up', 1.0000001192092896)], [('for', 1.0)], [('days', 1.0)], [('missed', 1.0)], [('because', 1.0)], [('of', 1.0)], [('the', 1.0)], [(\"##'\", 0.696808934211731)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNJpRDlg4kQW",
        "colab_type": "text"
      },
      "source": [
        "## Dividindo a base de dados\n",
        "\n",
        "Aqui a base de dados é dividida em: Treinamento, validação e teste.\n",
        "\n",
        "OBS: não encontrei isso implementado nem no scikit learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AorJ_zzpsZIO",
        "colab_type": "code",
        "outputId": "b0840278-ba91-4884-8395-757bee6684ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#pading, para tudo ter o mesmo tamanho\n",
        "\n",
        "maxlen = 0\n",
        "\n",
        "for i in noticias:\n",
        "  if i.shape[0] > maxlen:\n",
        "    maxlen = i.shape[0]\n",
        "\n",
        "for i in range(len(noticias)):\n",
        "  pad = np.zeros((maxlen, 768))\n",
        "  pad[:noticias[i].shape[0],:] = noticias[i]\n",
        "  noticias[i] = pad\n",
        "  pad = np.zeros((maxlen, 768))\n",
        "  pad[:cabecalhos[i].shape[0],:] = cabecalhos[i]\n",
        "  cabecalhos[i] = pad\n",
        "\n",
        "print(maxlen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9psE79f5CmX",
        "colab_type": "code",
        "outputId": "395f7f69-7286-49d6-ebcd-a9445219a1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "treinamento = []\n",
        "#validacao = []\n",
        "teste = []\n",
        "\n",
        "xt = []\n",
        "yt = []\n",
        "\n",
        "xr = []\n",
        "yr = []\n",
        "\n",
        "atreino = 0.9\n",
        "#avalidacao = 0.3\n",
        "\n",
        "d = []\n",
        "for i in range(len(noticias)):\n",
        "  d.append(i)\n",
        "\n",
        "random.shuffle(d)\n",
        "\n",
        "# deixar essa linha para validar os parametros dos primeiros testes\n",
        "d = [117, 135, 181, 2, 129, 167, 65, 183, 107, 104, 158, 111, 69, 194, 8, 101, 21, 35, 31, 188, 106, 196, 148, 198, 67, 60, 102, 82, 16, 88, 119, 61, 11, 115, 113, 56, 169, 98, 64, 40, 49, 162, 36, 127, 157, 66, 164, 180, 41, 138, 62, 34, 72, 178, 27, 189, 121, 154, 96, 14, 133, 145, 97, 43, 199, 51, 25, 163, 155, 47, 70, 150, 12, 30, 123, 195, 32, 55, 18, 176, 171, 68, 175, 120, 110, 59, 141, 6, 23, 44, 103, 151, 125, 130, 79, 73, 173, 1, 58, 165, 118, 46, 39, 191, 10, 74, 166, 24, 147, 131, 190, 20, 156, 26, 22, 187, 182, 75, 63, 52, 9, 132, 87, 5, 144, 192, 42, 142, 90, 85, 143, 13, 153, 174, 122, 139, 184, 128, 19, 50, 161, 172, 168, 83, 48, 71, 185, 53, 126, 4, 29, 86, 15, 7, 92, 45, 197, 76, 134, 37, 54, 152, 57, 84, 112, 3, 28, 93, 0, 109, 136, 177, 77, 170, 100, 146, 137, 179, 80, 33, 17, 124, 89, 193, 38, 160, 78, 95, 140, 114, 159, 81, 186, 99, 108, 105, 116, 94, 149, 91]\n",
        "\n",
        "for i in range(len(noticias)):\n",
        "  if i < atreino*len(noticias):\n",
        "    xt.append(noticias[d[i]])\n",
        "    yt.append(cabecalhos[d[i]])\n",
        "  else:\n",
        "    xr.append(noticias[d[i]])\n",
        "    yr.append(cabecalhos[d[i]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "xt = np.array(xt)\n",
        "yt = np.array(yt)\n",
        "\n",
        "xr = np.array(xr)\n",
        "yr = np.array(yr)\n",
        "\n",
        "xt = xt.reshape(xt.shape[0], maxlen, 768, 1)\n",
        "yt = yt.reshape(yt.shape[0], maxlen, 768, 1)\n",
        "\n",
        "xr = xr.reshape(xr.shape[0], maxlen, 768, 1)\n",
        "yr = yr.reshape(yr.shape[0], maxlen, 768, 1)\n",
        "\n",
        "print(len(xt), len(yt))\n",
        "print(len(xr), len(xr[1]), len(xr[1][1]))\n",
        "\n",
        "'''\n",
        "for i in range(len(noticias)):\n",
        "  if i < atreino*len(noticias):\n",
        "    treinamento.append(noticias[d[i]])\n",
        "  elif i < (atreino+avaliacao)*len(noticias):\n",
        "    validacao.append(noticias[d[i]])\n",
        "  else:\n",
        "    teste.append(noticias[d[i]])'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180 180\n",
            "20 56 768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor i in range(len(noticias)):\\n  if i < atreino*len(noticias):\\n    treinamento.append(noticias[d[i]])\\n  elif i < (atreino+avaliacao)*len(noticias):\\n    validacao.append(noticias[d[i]])\\n  else:\\n    teste.append(noticias[d[i]])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7aMectc4YIn",
        "colab_type": "text"
      },
      "source": [
        "## Construindo a Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx1l-6QCQCSY",
        "colab_type": "code",
        "outputId": "75fed62e-1a32-4abb-d217-36915d4ac4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "#Importando o keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Deconvolution2D, Reshape\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thAFO7kN4eFU",
        "colab_type": "code",
        "outputId": "aed99c02-c992-4a39-ccc9-b18b0d0c6f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "model = Sequential()\n",
        "#model.add(Conv2D(2, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,768,1)))\n",
        "con = Conv2D(2, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,768,1),padding=\"same\")\n",
        "model.add(con)\n",
        "print(con.input_shape)\n",
        "print(con.output_shape)\n",
        "model.add(Conv2D(4, (2,2), activation = \"tanh\",padding=\"same\"))\n",
        "print(model.output_shape)\n",
        "#model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "#print(model.output_shape)\n",
        "\n",
        "print()\n",
        "model.add(Deconvolution2D(1, (2,2),padding=\"same\", dilation_rate =2))\n",
        "print(model.output_shape)\n",
        "\n",
        "#model.add(Reshape((maxlen,768,1)))\n",
        "#print(model.output_shape)\n",
        "\n",
        "#model.add(Conv2DTranspose(1,(2,2),output_shape=(768,), activation=\"tanh\"))\n",
        "#print(model.output_shape)\n",
        "#rs = Reshape((maxlen,768,1))\n",
        "#print(rs.output_shape)\n",
        "#print(rs.input_shape)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse',metrics=[\"acc\"])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 56, 768, 1)\n",
            "(None, 56, 768, 2)\n",
            "(None, 56, 768, 4)\n",
            "\n",
            "(None, 56, 768, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnC1bMvV4eme",
        "colab_type": "text"
      },
      "source": [
        "## Treinando a rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyMsp1u95Jo2",
        "colab_type": "code",
        "outputId": "2ecf3a94-a328-4c49-fd60-f3910d3cfa1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(xt,yt,epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "180/180 [==============================] - 8s 42ms/step - loss: 3.6676e-04 - acc: 0.8577\n",
            "Epoch 2/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 3.3654e-04 - acc: 0.8577\n",
            "Epoch 3/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 3.1417e-04 - acc: 0.8577\n",
            "Epoch 4/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.9694e-04 - acc: 0.8577\n",
            "Epoch 5/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.8390e-04 - acc: 0.8577\n",
            "Epoch 6/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.7363e-04 - acc: 0.8577\n",
            "Epoch 7/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.6579e-04 - acc: 0.8577\n",
            "Epoch 8/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.5951e-04 - acc: 0.8577\n",
            "Epoch 9/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.5444e-04 - acc: 0.8577\n",
            "Epoch 10/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.5032e-04 - acc: 0.8577\n",
            "Epoch 11/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.4685e-04 - acc: 0.8577\n",
            "Epoch 12/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.4394e-04 - acc: 0.8577\n",
            "Epoch 13/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.4157e-04 - acc: 0.8577\n",
            "Epoch 14/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3950e-04 - acc: 0.8577\n",
            "Epoch 15/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3774e-04 - acc: 0.8577\n",
            "Epoch 16/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3623e-04 - acc: 0.8577\n",
            "Epoch 17/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3490e-04 - acc: 0.8577\n",
            "Epoch 18/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3376e-04 - acc: 0.8577\n",
            "Epoch 19/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3277e-04 - acc: 0.8577\n",
            "Epoch 20/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3189e-04 - acc: 0.8577\n",
            "Epoch 21/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3110e-04 - acc: 0.8577\n",
            "Epoch 22/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.3044e-04 - acc: 0.8577\n",
            "Epoch 23/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2983e-04 - acc: 0.8577\n",
            "Epoch 24/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2931e-04 - acc: 0.8577\n",
            "Epoch 25/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2884e-04 - acc: 0.8577\n",
            "Epoch 26/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2842e-04 - acc: 0.8577\n",
            "Epoch 27/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2806e-04 - acc: 0.8577\n",
            "Epoch 28/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2774e-04 - acc: 0.8577\n",
            "Epoch 29/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2746e-04 - acc: 0.8577\n",
            "Epoch 30/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2719e-04 - acc: 0.8577\n",
            "Epoch 31/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2693e-04 - acc: 0.8577\n",
            "Epoch 32/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2670e-04 - acc: 0.8577\n",
            "Epoch 33/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2650e-04 - acc: 0.8577\n",
            "Epoch 34/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2631e-04 - acc: 0.8577\n",
            "Epoch 35/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2620e-04 - acc: 0.8577\n",
            "Epoch 36/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2610e-04 - acc: 0.8577\n",
            "Epoch 37/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2594e-04 - acc: 0.8577\n",
            "Epoch 38/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2581e-04 - acc: 0.8577\n",
            "Epoch 39/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2569e-04 - acc: 0.8577\n",
            "Epoch 40/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2555e-04 - acc: 0.8577\n",
            "Epoch 41/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2540e-04 - acc: 0.8577\n",
            "Epoch 42/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2531e-04 - acc: 0.8577\n",
            "Epoch 43/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2521e-04 - acc: 0.8577\n",
            "Epoch 44/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2510e-04 - acc: 0.8577\n",
            "Epoch 45/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2499e-04 - acc: 0.8577\n",
            "Epoch 46/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2496e-04 - acc: 0.8577\n",
            "Epoch 47/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2484e-04 - acc: 0.8577\n",
            "Epoch 48/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2477e-04 - acc: 0.8577\n",
            "Epoch 49/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2469e-04 - acc: 0.8577\n",
            "Epoch 50/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2463e-04 - acc: 0.8577\n",
            "Epoch 51/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2455e-04 - acc: 0.8577\n",
            "Epoch 52/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2448e-04 - acc: 0.8577\n",
            "Epoch 53/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2446e-04 - acc: 0.8577\n",
            "Epoch 54/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2439e-04 - acc: 0.8577\n",
            "Epoch 55/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2429e-04 - acc: 0.8577\n",
            "Epoch 56/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2423e-04 - acc: 0.8577\n",
            "Epoch 57/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2420e-04 - acc: 0.8577\n",
            "Epoch 58/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2415e-04 - acc: 0.8577\n",
            "Epoch 59/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2408e-04 - acc: 0.8577\n",
            "Epoch 60/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2402e-04 - acc: 0.8577\n",
            "Epoch 61/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2394e-04 - acc: 0.8577\n",
            "Epoch 62/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2387e-04 - acc: 0.8577\n",
            "Epoch 63/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2384e-04 - acc: 0.8577\n",
            "Epoch 64/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2376e-04 - acc: 0.8577\n",
            "Epoch 65/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2373e-04 - acc: 0.8577\n",
            "Epoch 66/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2367e-04 - acc: 0.8577\n",
            "Epoch 67/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2365e-04 - acc: 0.8577\n",
            "Epoch 68/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2360e-04 - acc: 0.8577\n",
            "Epoch 69/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2355e-04 - acc: 0.8577\n",
            "Epoch 70/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2347e-04 - acc: 0.8577\n",
            "Epoch 71/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2344e-04 - acc: 0.8577\n",
            "Epoch 72/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2340e-04 - acc: 0.8577\n",
            "Epoch 73/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2337e-04 - acc: 0.8577\n",
            "Epoch 74/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2333e-04 - acc: 0.8577\n",
            "Epoch 75/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2328e-04 - acc: 0.8577\n",
            "Epoch 76/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2324e-04 - acc: 0.8577\n",
            "Epoch 77/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2319e-04 - acc: 0.8577\n",
            "Epoch 78/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2316e-04 - acc: 0.8577\n",
            "Epoch 79/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2316e-04 - acc: 0.8577\n",
            "Epoch 80/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2308e-04 - acc: 0.8577\n",
            "Epoch 81/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2303e-04 - acc: 0.8577\n",
            "Epoch 82/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2301e-04 - acc: 0.8577\n",
            "Epoch 83/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2297e-04 - acc: 0.8577\n",
            "Epoch 84/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2293e-04 - acc: 0.8577\n",
            "Epoch 85/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2291e-04 - acc: 0.8577\n",
            "Epoch 86/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2291e-04 - acc: 0.8577\n",
            "Epoch 87/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2285e-04 - acc: 0.8577\n",
            "Epoch 88/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2282e-04 - acc: 0.8577\n",
            "Epoch 89/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2278e-04 - acc: 0.8577\n",
            "Epoch 90/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2275e-04 - acc: 0.8577\n",
            "Epoch 91/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2278e-04 - acc: 0.8577\n",
            "Epoch 92/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2276e-04 - acc: 0.8577\n",
            "Epoch 93/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2276e-04 - acc: 0.8577\n",
            "Epoch 94/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2271e-04 - acc: 0.8577\n",
            "Epoch 95/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2269e-04 - acc: 0.8577\n",
            "Epoch 96/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2263e-04 - acc: 0.8577\n",
            "Epoch 97/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2261e-04 - acc: 0.8577\n",
            "Epoch 98/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2262e-04 - acc: 0.8577\n",
            "Epoch 99/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2267e-04 - acc: 0.8577\n",
            "Epoch 100/100\n",
            "180/180 [==============================] - 0s 1ms/step - loss: 2.2258e-04 - acc: 0.8577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f78fe888a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYJKsJ5ckLT",
        "colab_type": "text"
      },
      "source": [
        "##Teste da rede\n",
        "\n",
        "Aqui a rede é testada, sem produzir de fato saidas legíveis, mas apenas mostrando uma acurácia da rede em relação ao vetor bert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QS0KNZscwX3",
        "colab_type": "code",
        "outputId": "bda7e823-69a7-4f48-9562-e005b7d933a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "print(xt.shape)\n",
        "\n",
        "aaaaa = xr[0].reshape(1, 56, 768, 1)\n",
        "bbbbb = yr[0].reshape(56,768)\n",
        "\n",
        "ttttt = model.predict(aaaaa)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-92d6505108b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maaaaa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbbbbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fii8I_hiMzqS",
        "colab_type": "code",
        "outputId": "abfe7c3e-10f9-4462-c17d-f7c6cd01197c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "ttttt = ttttt.reshape(56,768)\n",
        "print(ttttt.shape)\n",
        "\n",
        "asdf = vec2head(ttttt,dicio,0.5)\n",
        "print(asdf)\n",
        "\n",
        "fdsa = vec2head(bbbbb,dicio,0.5)\n",
        "print(fdsa)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56, 768)\n",
            "[[('201', 0.6595737934112549)], [(\"##'\", 0.6446463465690613)], [(\"##'\", 0.6573339700698853)], [(\"##'\", 0.5432831048965454)], [(\"##'\", 0.6223398447036743)], [('201', 0.5796380639076233)], [('`', 0.6158039569854736)], [('2013', 0.5690800547599792)], [('`', 0.6030287146568298)], [('##t', 0.5703284740447998)], [(\"##'\", 0.6209338903427124)], [(\"##'\", 0.5253568887710571)], [('announced', 0.5673514604568481)], [('today', 0.6322273015975952)], [('today', 0.699204683303833)], [('that', 0.7536540031433105)], [('it', 0.6571808457374573)], [('has', 0.6315385103225708)], [('completed', 0.6037743091583252)], [('previously', 0.6270340085029602)], [('announced', 0.6219427585601807)], [('acquisition', 0.6369504332542419)], [('acquisition', 0.6638456583023071)], [('bel', 0.6234313249588013)], [('bel', 0.643802285194397)], [('##o', 0.6251477003097534)], [('##5', 0.5489922165870667)], [('##5', 0.5892611742019653)], [('per', 0.6156011819839478)], [('per', 0.640164315700531)], [('share', 0.658423900604248)], [('cash', 0.6922643184661865)], [('cash', 0.699795663356781)], [('addition', 0.5645601749420166)], [('addition', 0.5870875120162964)], [('to', 0.6178958415985107)], [('to', 0.6096583008766174)], [('the', 0.5603827834129333)], [('assumption', 0.6398985385894775)], [('##5', 0.6375483870506287)], [('million', 0.659980297088623)], [('million', 0.6873966455459595)], [('outstanding', 0.6335018873214722)], [('debt', 0.6725428104400635)], [('debt', 0.733618974685669)], [('for', 0.5038665533065796)], [('for', 0.6387195587158203)], [('total', 0.6516909599304199)], [('total', 0.6319130659103394)], [('value', 0.6599929928779602)], [('value', 0.6980164051055908)], [('##2', 0.5823213458061218)], [('billion', 0.7406005859375)], [('billion', 0.8020639419555664)], [(\"##'\", 0.5492129921913147)]]\n",
            "[[('##t', 1.0)], [('completed', 0.5599807500839233)], [('##s', 0.9999998807907104)], [('acquisition', 1.0)], [('of', 1.0)], [('bel', 1.0)], [('##o', 1.0)]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZGIJBRi5J7m",
        "colab_type": "text"
      },
      "source": [
        "## Teste de predição\n",
        "\n",
        "Aqui a rede é rodada como teste. A metrica mais usada para esse teste é o ROUGE-1, que conta quantas palavras da saída do sistema está dentro do texto de referência, depois divide pelo número de palavras no texto de referência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFw4uRsm5Kuu",
        "colab_type": "code",
        "outputId": "e45b163d-bdd2-4578-a6ab-e2be246ddd6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "\n",
        "#rouge-1\n",
        "def rouge(src, ref):\n",
        "  acertos = 0\n",
        "  for i in src:\n",
        "    if i in ref:\n",
        "      acertos += 1\n",
        "  return acertos/float(len(ref))\n",
        "\n",
        "sistem = ['five', 'plane']\n",
        "refere = ['five', 'in', 'plane']\n",
        "\n",
        "si = []\n",
        "re = []\n",
        "\n",
        "for i in asdf:\n",
        "  si.append(i[0])\n",
        "\n",
        "for i in fdsa:\n",
        "  re.append(i[0])\n",
        "\n",
        "print(rouge(sistem, refere))\n",
        "print(rouge(si,re))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666666\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE9N8xIG5tBd",
        "colab_type": "text"
      },
      "source": [
        "# SHAME!\n",
        "\n",
        "Certo, o resultado de 85% de precisão da rede neural não produziu nenhuma sentença compatível com a sua referência. Vamos tentar outra coisa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0so6Iax2wMQ",
        "colab_type": "text"
      },
      "source": [
        "## Classificação\n",
        "\n",
        "Há uma base de dados que compreende recomendações dos jogos da steam. https://github.com/mulhod/steam_reviews\n",
        "\n",
        "\n",
        "Porém aqui será usado somente o word2vec, visto que a base de dados é outra e não é possível somente importar o dicionário do bert.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJri0htt2vT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To reimportando para nao precisar rodar tudo.\n",
        "import gensim\n",
        "import numpy as np\n",
        "import json\n",
        "import keras\n",
        "\n",
        "from urllib import request as req\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7htR7oL9tX3",
        "colab_type": "text"
      },
      "source": [
        "## importando a base de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbidOvKs9si3",
        "colab_type": "code",
        "outputId": "f09fe5ca-b741-43bb-99a5-415c688afde4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "source": [
        "#urlpastareviews = \"https://github.com/mulhod/steam_reviews/tree/master/data\"\n",
        "vetorarqui = [\"Arma_3.jsonlines\",\"Counter_Strike.jsonlines\",\"Counter_Strike_Global_Offensive.jsonlines\",\"Dota_2.jsonlines\",\"Football_Manager_2015.jsonlines\",\"Garrys_Mod.jsonlines\",\"Grand_Theft_Auto_V.jsonlines\",\"Sid_Meiers_Civilization_5.jsonlines\",\"Team_Fortress_2.jsonlines\",\"The_Elder_Scrolls_V.jsonlines\",\"Warframe.jsonlines\"]\n",
        "cadaReview = \"https://raw.githubusercontent.com/mulhod/steam_reviews/master/data/%s\"\n",
        "\n",
        "#user/game, rating\n",
        "gamerat = [[],[]]\n",
        "reviews = []\n",
        "\n",
        "erros = 0\n",
        "\n",
        "#aqui o vetor reviews sera acrescido de instancias.\n",
        "for i in vetorarqui:\n",
        "  with req.urlopen(cadaReview%i) as f:\n",
        "    data = f.read().decode('charmap')\n",
        "  data = data.replace('}\\n', '}-----')\n",
        "  data = data.split('-----')\n",
        "  print(\"reviews coletadas para esse jogo\",len(data))\n",
        "  for j in data:\n",
        "    try:\n",
        "      jfk = json.loads(j)\n",
        "      # infelizmente a base de dados contem instancias duplicadas\n",
        "      # Eventualmente um jogador comentou em dois jogos\n",
        "      # Eventualmente os jogadores mudam de nome, entao eh mais seguro filtrar pelo \"orig_url\"\n",
        "      #hum += 1\n",
        "      user = \"%s in %s\"%(jfk[\"orig_url\"], i[:-10])\n",
        "      revi = jfk[\"review\"]\n",
        "      revi = gensim.utils.simple_preprocess(revi)\n",
        "      rati = jfk[\"rating\"]\n",
        "      if (not (user in gamerat[0])):\n",
        "        if len(revi) > 5 and len(revi) < 129:\n",
        "          gamerat[0].append(user)\n",
        "          reviews.append(revi)\n",
        "          gamerat[1].append(rati)\n",
        "        elif len(revi) > 128:\n",
        "          gamerat[0].append(user)\n",
        "          reviews.append(revi[:128])\n",
        "          gamerat[1].append(rati)\n",
        "    except:\n",
        "      erros += 1\n",
        "  print(reviews[-1])\n",
        "  print (\"Ha %i instancias\\nUm total de %i instancias ignoradas\"%(len(reviews),erros))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reviews coletadas para esse jogo 7274\n",
            "['simply', 'amazing', 'fun', 'to', 'play', 'insurgency', 'and', 'king', 'of', 'the', 'hill']\n",
            "Ha 881 instancias\n",
            "Um total de 135 instancias ignoradas\n",
            "reviews coletadas para esse jogo 6234\n",
            "['just', 'an', 'absolute', 'brilliant', 'game', 'you', 'can', 'play', 'on', 'any', 'server', 'you', 'want', 'and', 'you', 'will', 'have', 'lot', 'of', 'fun']\n",
            "Ha 2083 instancias\n",
            "Um total de 336 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7412\n",
            "['you', 'shoot', 'chickens', 'in', 'this', 'game']\n",
            "Ha 3001 instancias\n",
            "Um total de 691 instancias ignoradas\n",
            "reviews coletadas para esse jogo 9792\n",
            "['yeah', 'best', 'game', 'cant', 'imagine', 'if', 'this', 'game', 'if', 'rlly', 'closed']\n",
            "Ha 4550 instancias\n",
            "Um total de 774 instancias ignoradas\n",
            "reviews coletadas para esse jogo 1532\n",
            "['well', 'there', 'was', 'looking', 'to', 'enjoy', 'the', 'nexr', 'edition', 'off', 'fm', 'oh', 'dear', 'who', 'on', 'earth', 'made', 'this', 'one', 'must', 'be', 'someone', 'that', 'has', 'never', 'seen', 'game', 'of', 'football', 'in', 'their', 'life', 'goalkeepers', 'from', 'other', 'teams', 'play', 'like', 'gordan', 'banks', 'my', 'goalkeeper', 'is', 'making', 'all', 'kinds', 'of', 'blunders', 'agree', 'some', 'games', 'even', 'if', 'you', 'have', 'percent', 'possession', 'you', 'can', 'still', 'lose', 'to', 'counter', 'attack', 'however', 'not', 'every', 'game', 'there', 'is', 'too', 'many', 'times', 'that', 'you', 'have', 'shots', 'with', 'no', 'goal', 'and', 'the', 'other', 'team', 'have', 'shot', 'goal', 'highlights', 'still', 'look', 'like', 'we', 'have', 'graphics', 'engine', 'from', 'the', 'days', 'of', 'manic', 'miner', 'went', 'to', 'buy', 'player', 'at', 'man', 'united', 'and', 'asked', 'the', 'board', 'they', 'said', 'that', 'they', 'agree', 'however', 'cant', 'afford', 'lol', 'really', 'also', 'some', 'teams', 'are', 'way', 'overated']\n",
            "Ha 4730 instancias\n",
            "Um total de 785 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7281\n",
            "['you', 'can', 'kill', 'someone', 'with', 'water', 'melon', 'and', 'then', 'drop', 'nuke', 'do', 'yourself', 'favor', 'and', 'get', 'this', 'game']\n",
            "Ha 5592 instancias\n",
            "Um total de 923 instancias ignoradas\n",
            "reviews coletadas para esse jogo 13853\n",
            "['best', 'version', 'of', 'gta', 'out', 'there', 'played', 'xbox', 'version', 'but', 'the', 'pc', 'version', 'up', 'the', 'xbox', 'in', 'so', 'many', 'ways', 'worth', 'it']\n",
            "Ha 7224 instancias\n",
            "Um total de 1463 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7590\n",
            "['this', 'is', 'drugs', 'in', 'game', 'form']\n",
            "Ha 8130 instancias\n",
            "Um total de 1592 instancias ignoradas\n",
            "reviews coletadas para esse jogo 5760\n",
            "['the', 'game', 'is', 'amazing', 'other', 'poeple', 'in', 'the', 'game', 'are', 'usually', 'nice', 'and', 'fun', 'to', 'play', 'with', 'the', 'ommunity', 'for', 'this', 'game', 'is', 'huge', 'and', 'you', 'will', 'never', 'find', 'the', 'game', 'empty']\n",
            "Ha 8824 instancias\n",
            "Um total de 1684 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7441\n",
            "['enjoy', 'hundreds', 'upon', 'hundreds', 'of', 'copy', 'pasted', 'dungeons', 'boring', 'enemies', 'uninteresting', 'skills', 'basic', 'spells', 'fetch', 'quests', 'glitches', 'and', 'bugs', 'take', 'in', 'the', 'breath', 'takingly', 'small', 'skyrim', 'if', 'this', 'is', 'country', 'then', 'how', 'big', 'is', 'the', 'planet', 'as', 'you', 'click', 'on', 'draugrs', 'click', 'on', 'bandits', 'click', 'on', 'falmers', 'click', 'on', 'spiders', 'click', 'on', 'wizards', 'and', 'click', 'on', 'dragons', 'watch', 'as', 'your', 'hero', 'cinematically', 'kills', 'the', 'easiest', 'enemies', 'in', 'any', 'game', 'ever', 'and', 'when', 'you', 'turn', 'up', 'the', 'difficulty', 'the', 'game', 'lazily', 'only', 'increases', 'the', 'enemy', 'health', 'and', 'damage', 'feel', 'like', 'you', 'haven', 'gotten', 'any', 'stronger', 'due', 'to', 'the', 'amazing', 'scaling', 'enemies', 'but', 'people', 'keep', 'telling', 'me', 'that', 'this', 'is', 'the', 'best', 'game', 'ever', 'so', 'guess', 'they', 're', 'right', 'give', 'this', 'game']\n",
            "Ha 9660 instancias\n",
            "Um total de 1977 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7642\n",
            "['even', 'with', 'all', 'unusual', 'style', 'and', 'gameplay', 'this', 'game', 'is', 'terrible', 'because', 'it', 'requires', 'tons', 'of', 'your', 'time', 'to', 'grind', 'so', 'you', 'can', 'get', 'decent', 'items', 'mods', 'and', 'become', 'player', 'who', 'worth', 'something', 'my', 'favorite', 'weapons', 'was', 'nerfed', 'new', 'classes', 'overpowered', 'and', 'old', 'ones', 'was', 'nerfed', 'hard', 'this', 'game', 'was', 'made', 'to', 'suck', 'money', 'because', 'without', 'donation', 'you', 'will', 'waste', 'many', 'hours', 'of', 'trying', 'to', 'complete', 'missions', 'you', 'want', 'or', 'get', 'items', 'you', 'need', 'with', 'money', 'in', 'your', 'pocket', 'you', 'can', 'easily', 'get', 'everything', 'and', 'turn', 'on', 'easy', 'mode', 've', 'played', 'long', 'time', 'ago', 'and', 'it', 'was', 'decent', 'there', 'was', 'of', 'course', 'one', 'of', 'the', 'starting', 'classes', 'that', 'could', 'win', 'everything', 'in', 'solo', 'but', 'the', 'rest', 'of', 'them', 'was', 'useful', 'now', 'everything', 'changed', 'in', 'bad', 'way', 'am', 'very']\n",
            "Ha 10548 instancias\n",
            "Um total de 2523 instancias ignoradas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OxcNRE7OZSN",
        "colab_type": "text"
      },
      "source": [
        "## Criando o Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKe9poUcOe_D",
        "colab_type": "code",
        "outputId": "98f48ad5-aa53-4b17-c515-a85a8627cdb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dicionario = gensim.models.Word2Vec(\n",
        "        reviews,\n",
        "        size=128,\n",
        "        window=10,\n",
        "        min_count=2,\n",
        "        workers=100)\n",
        "dicionario.train(reviews, total_examples=len(reviews), epochs=20)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5923666, 8172540)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M8ThV2eRprN",
        "colab_type": "code",
        "outputId": "45c7fe70-b479-4423-963f-5f9f2552efd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "source": [
        "print(len(dicionario[\"good\"]))\n",
        "\n",
        "print(len(dicionario.wv.vocab))\n",
        "\n",
        "print(dicionario[\"good\"])\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "8669\n",
            "[-1.0366819   1.7281958  -0.01435874  1.365761    2.2397747   1.3678515\n",
            " -1.5958464  -0.07951249 -0.32666117 -2.3085115   0.52837896  2.81719\n",
            "  1.0934815  -0.98438483  1.0565808   0.87627274 -0.89064413 -0.2698659\n",
            "  0.66846484  0.32379597  1.0493536   1.3894998   0.821203    0.8563471\n",
            "  0.23984696 -0.76580286 -2.258044    0.60169435  0.03967942 -1.7248719\n",
            " -2.414108    1.1353825   0.7720462   0.18638857 -1.0958792   1.1752911\n",
            "  0.18452692  0.8037575   0.56207675 -1.0871601  -2.2735455   0.71231055\n",
            " -1.1988012   2.1716676  -0.01124087 -0.06599122 -0.4287716  -0.38062856\n",
            "  0.17497726  1.4387618   0.11828098 -1.885172    2.8813639   1.1856095\n",
            " -0.5044151  -0.5726096  -0.86201     0.25077507 -0.03870318  1.0886639\n",
            "  0.8256086  -0.16255307 -0.91170824  0.22801144  0.8682236   1.497828\n",
            "  0.8937345   2.6885464  -0.5009311  -1.6548415  -1.3247426  -0.7002078\n",
            "  0.80830264  1.1475677  -1.3051691  -0.730667   -1.0142473   0.76494163\n",
            "  1.9555123   2.0458713   1.1748871  -0.37760153  0.9916897   2.6045222\n",
            " -1.8836666   0.85766405 -1.0829216  -1.5099643  -1.3498294   0.82440674\n",
            "  1.6977782  -1.4743061   0.11036906 -0.07762798  1.1316943   0.41369656\n",
            " -1.6292242   1.2541126  -1.3969465   2.8028793  -0.43101746  0.63216615\n",
            "  1.1074277   1.8796544   1.3357335  -0.7643202  -0.01100642  1.5139126\n",
            "  0.13798839  0.3084361  -1.5998306   2.363643    0.45675015  0.66466975\n",
            "  1.5650593  -1.9101013   1.7460393   1.7972827   0.26290002 -1.2129598\n",
            " -0.9598427   0.88289905 -1.8793609   1.5154053  -0.08080035  0.22130385\n",
            " -2.1276357   2.0839458 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fedqmi7F34Pb",
        "colab_type": "text"
      },
      "source": [
        "## Filtrando as instancias\n",
        "\n",
        "Devido algumas pequenas dificuldades, o projeto sera simplificado com uma filtragem das instancias. Com uma base de dados equilibrada, 50% de instancias recomendadas e 50% de instancias não recomendadas, a estratégia de dizer que todas as entradas são recomendadas não funcionará."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yfY_5pL4YiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "e924aef4-17f2-4b2e-899f-ed97c92327c1"
      },
      "source": [
        "print(len(reviews))\n",
        "print(len(gamerat))\n",
        "print(len(gamerat[0]))\n",
        "\n",
        "reviewsold = reviews\n",
        "gameratold = gamerat\n",
        "\n",
        "reviews = []\n",
        "gamerat = [[],[]]\n",
        "\n",
        "print(len(gameratold))\n",
        "print(len(gameratold[1]))\n",
        "len(reviewsold)\n",
        "\n",
        "rm = 0\n",
        "nr = 0\n",
        "\n",
        "for i in gameratold[1]:\n",
        "  if i == 'Recommended':\n",
        "    rm += 1\n",
        "  else:\n",
        "    nr += 1\n",
        "\n",
        "print(rm, nr)\n",
        "\n",
        "rm = min(rm, nr)\n",
        "nr = rm\n",
        "\n",
        "for i in range(len(reviewsold)):\n",
        "  if rm > 0 and gameratold[1][i] == 'Recommended':\n",
        "    reviews.append(reviewsold[i])\n",
        "    gamerat[0].append(gameratold[0][i])\n",
        "    gamerat[1].append(gameratold[1][i])\n",
        "    rm -= 1\n",
        "  if rn > 0 and gameratold[1][i] == 'Not Recommended':\n",
        "    reviews.append(reviewsold[i])\n",
        "    gamerat[0].append(gameratold[0][i])\n",
        "    gamerat[1].append(gameratold[1][i])\n",
        "    nr -= 1\n",
        "\n",
        "print(len(reviews), len(gamerat[1]))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10548\n",
            "2\n",
            "10548\n",
            "2\n",
            "10548\n",
            "9072 1476\n",
            "2952 2952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOnVn0-YSf_I",
        "colab_type": "text"
      },
      "source": [
        "## Transformando cada review em uma matriz\n",
        "\n",
        "Como usado anteriormente, mas sem o bert, cada review sera transformada em uma matriz, onde cada linha é uma palavra com 128 valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-8359RVTcGo",
        "colab_type": "code",
        "outputId": "1cf71315-0f0d-40c6-ea78-fa248e3fc202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "reviewsmat = []\n",
        "\n",
        "for i in reviews:\n",
        "  mm = []\n",
        "  for j in i:\n",
        "    try:\n",
        "      mm.append(dicionario[j])\n",
        "    except:\n",
        "      #print(\"Faltou\")\n",
        "      pass\n",
        "  mm = np.array(mm)\n",
        "  reviewsmat.append(mm)\n",
        "\n",
        "\n",
        "\n",
        "print(len(reviews))\n",
        "print(len(reviewsmat))\n",
        "print(len(reviewsmat[0]))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2952\n",
            "2952\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyYI2A6OWPh_",
        "colab_type": "code",
        "outputId": "b51e8633-62a6-47a5-e12c-569a533f65f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#pading, para tudo ter o mesmo tamanho\n",
        "\n",
        "maxlen = 0\n",
        "\n",
        "revFiltradas = []\n",
        "\n",
        "for i in reviewsmat:\n",
        "  if i.shape[0] > maxlen:\n",
        "    maxlen = i.shape[0]\n",
        "\n",
        "erros = 0\n",
        "\n",
        "for i in range(len(reviewsmat)):\n",
        "  try:\n",
        "    pad = np.zeros((maxlen, 128))\n",
        "    pad[:reviewsmat[i].shape[0],:] = reviewsmat[i]\n",
        "    revFiltradas.append(pad)\n",
        "  except:\n",
        "    erros += 1\n",
        "\n",
        "print(maxlen, erros)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEdgHZdVbQLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "755754b0-6433-4e62-f8dc-ee93227a93c1"
      },
      "source": [
        "#Reshaping\n",
        "\n",
        "inst = len(revFiltradas)\n",
        "\n",
        "x = np.array(revFiltradas)\n",
        "\n",
        "x = x.reshape(inst, maxlen, 128, 1)\n",
        "\n",
        "len(x)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2952"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYOqRZRfePV",
        "colab_type": "text"
      },
      "source": [
        "## One hot encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gglvz7jidYKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "2d46efb0-9ccd-463d-d7ca-2f2fe25053c4"
      },
      "source": [
        "#Outputs\n",
        "\n",
        "ardata = np.array(gamerat[1])\n",
        "print(ardata)\n",
        "\n",
        "\n",
        "# https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(ardata)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([np.argmax(onehot_encoded[0, :])])\n",
        "print(inverted)\n",
        "\n",
        "\n",
        "y = keras.utils.to_categorical(onehot_encoded, 2)\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Recommended' 'Recommended' 'Recommended' ... 'Not Recommended'\n",
            " 'Not Recommended' 'Not Recommended']\n",
            "[1 1 1 ... 0 0 0]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "['Recommended']\n",
            "[[[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 1.]\n",
            "  [1. 0.]]\n",
            "\n",
            " [[0. 1.]\n",
            "  [1. 0.]]\n",
            "\n",
            " [[0. 1.]\n",
            "  [1. 0.]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS1vyNuIjbAz",
        "colab_type": "text"
      },
      "source": [
        "## Divisão treino/teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojDqhJMAjlnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72c703d1-0a54-4419-f25e-49fad19fb4cf"
      },
      "source": [
        "## divisao\n",
        "\n",
        "print (inst)\n",
        "\n",
        "x_tr = x[:2361] #80% da base de dados\n",
        "x_te = x[2361:] #20% da base de dados\n",
        "\n",
        "y_tr = onehot_encoded[:2361]\n",
        "y_te = onehot_encoded[2361:]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLepzjVqg7Ay",
        "colab_type": "text"
      },
      "source": [
        "## Classificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1dS_1ethDcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Flatten, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ4X5EfGzZdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Recall \n",
        "#### https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n34T8Kfhpgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "outputId": "aae3bea4-0cfe-4075-fa15-2d2f6e721f4a"
      },
      "source": [
        "cls = Sequential()\n",
        "cls.add(Conv2D(4, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Conv2D(8, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(Dropout(0.8))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Conv2D(16, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Conv2D(32, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Conv2D(64, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(Dropout(0.8))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Flatten())\n",
        "cls.add(Dense(8, activation = \"tanh\"))\n",
        "cls.add(Dropout(0.8))\n",
        "cls.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "print(cls.summary())\n",
        "print(cls.input_shape)\n",
        "print(cls.output_shape)\n",
        "\n",
        "\n",
        "cls.compile(\"adam\", \"mse\", [\"acc\", recall_m])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_54 (Conv2D)           (None, 128, 128, 4)       40        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 64, 64, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 64, 64, 8)         296       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64, 64, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 32, 32, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 8, 8, 64)          18496     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 8)                 8200      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 2)                 18        \n",
            "=================================================================\n",
            "Total params: 32,858\n",
            "Trainable params: 32,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "(None, 128, 128, 1)\n",
            "(None, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4GN29pUz9tO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "283488a7-16a9-4773-d7a2-9927ac7be69a"
      },
      "source": [
        "cls.fit(x_tr, y_tr, batch_size=160, epochs = 300, validation_split=0.1)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2124 samples, validate on 237 samples\n",
            "Epoch 1/300\n",
            "2124/2124 [==============================] - 2s 739us/step - loss: 0.2911 - acc: 0.6314 - recall_m: 0.6276 - val_loss: 0.6536 - val_acc: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 2/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2666 - acc: 0.6855 - recall_m: 0.6855 - val_loss: 0.6292 - val_acc: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 3/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2689 - acc: 0.6893 - recall_m: 0.6893 - val_loss: 0.5851 - val_acc: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 4/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.2501 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.4351 - val_acc: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 5/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.2476 - acc: 0.6808 - recall_m: 0.6808 - val_loss: 0.4171 - val_acc: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 6/300\n",
            "2124/2124 [==============================] - 0s 217us/step - loss: 0.2405 - acc: 0.6921 - recall_m: 0.6921 - val_loss: 0.4195 - val_acc: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 7/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2313 - acc: 0.6850 - recall_m: 0.6850 - val_loss: 0.3370 - val_acc: 0.0084 - val_recall_m: 0.0084\n",
            "Epoch 8/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2176 - acc: 0.6869 - recall_m: 0.6869 - val_loss: 0.3720 - val_acc: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 9/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2225 - acc: 0.6869 - recall_m: 0.6869 - val_loss: 0.3052 - val_acc: 0.2278 - val_recall_m: 0.2278\n",
            "Epoch 10/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2206 - acc: 0.6893 - recall_m: 0.6893 - val_loss: 0.2948 - val_acc: 0.3882 - val_recall_m: 0.3882\n",
            "Epoch 11/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2164 - acc: 0.6921 - recall_m: 0.6921 - val_loss: 0.2874 - val_acc: 0.4262 - val_recall_m: 0.4262\n",
            "Epoch 12/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.2135 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.2399 - val_acc: 0.6203 - val_recall_m: 0.6203\n",
            "Epoch 13/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.2129 - acc: 0.6883 - recall_m: 0.6883 - val_loss: 0.2780 - val_acc: 0.4430 - val_recall_m: 0.4430\n",
            "Epoch 14/300\n",
            "2124/2124 [==============================] - 0s 220us/step - loss: 0.2129 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.2393 - val_acc: 0.6245 - val_recall_m: 0.6245\n",
            "Epoch 15/300\n",
            "2124/2124 [==============================] - 0s 223us/step - loss: 0.2091 - acc: 0.6893 - recall_m: 0.6893 - val_loss: 0.2873 - val_acc: 0.4262 - val_recall_m: 0.4262\n",
            "Epoch 16/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.2105 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.2837 - val_acc: 0.4430 - val_recall_m: 0.4430\n",
            "Epoch 17/300\n",
            "2124/2124 [==============================] - 0s 222us/step - loss: 0.2121 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.2879 - val_acc: 0.4430 - val_recall_m: 0.4430\n",
            "Epoch 18/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.2111 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2580 - val_acc: 0.6118 - val_recall_m: 0.6118\n",
            "Epoch 19/300\n",
            "2124/2124 [==============================] - 0s 219us/step - loss: 0.2108 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.2431 - val_acc: 0.6329 - val_recall_m: 0.6329\n",
            "Epoch 20/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.2093 - acc: 0.6921 - recall_m: 0.6921 - val_loss: 0.2650 - val_acc: 0.6034 - val_recall_m: 0.6034\n",
            "Epoch 21/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2113 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2611 - val_acc: 0.5992 - val_recall_m: 0.5992\n",
            "Epoch 22/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2091 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.2697 - val_acc: 0.6034 - val_recall_m: 0.6034\n",
            "Epoch 23/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2081 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2592 - val_acc: 0.6287 - val_recall_m: 0.6287\n",
            "Epoch 24/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2090 - acc: 0.6926 - recall_m: 0.6926 - val_loss: 0.2569 - val_acc: 0.6287 - val_recall_m: 0.6287\n",
            "Epoch 25/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2080 - acc: 0.6940 - recall_m: 0.6940 - val_loss: 0.2716 - val_acc: 0.6287 - val_recall_m: 0.6287\n",
            "Epoch 26/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2079 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2712 - val_acc: 0.6287 - val_recall_m: 0.6287\n",
            "Epoch 27/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2070 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2355 - val_acc: 0.6582 - val_recall_m: 0.6582\n",
            "Epoch 28/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2065 - acc: 0.7001 - recall_m: 0.7001 - val_loss: 0.2326 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 29/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2088 - acc: 0.6888 - recall_m: 0.6888 - val_loss: 0.2303 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 30/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2099 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2262 - val_acc: 0.6624 - val_recall_m: 0.6624\n",
            "Epoch 31/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2063 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2270 - val_acc: 0.6624 - val_recall_m: 0.6624\n",
            "Epoch 32/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2068 - acc: 0.6973 - recall_m: 0.6973 - val_loss: 0.2268 - val_acc: 0.6624 - val_recall_m: 0.6624\n",
            "Epoch 33/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2084 - acc: 0.6902 - recall_m: 0.6902 - val_loss: 0.2186 - val_acc: 0.6667 - val_recall_m: 0.6667\n",
            "Epoch 34/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2054 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2086 - val_acc: 0.6793 - val_recall_m: 0.6793\n",
            "Epoch 35/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.2072 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2031 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 36/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2062 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.2297 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 37/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2078 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2102 - val_acc: 0.6709 - val_recall_m: 0.6709\n",
            "Epoch 38/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2076 - acc: 0.6921 - recall_m: 0.6921 - val_loss: 0.2077 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 39/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2064 - acc: 0.6977 - recall_m: 0.6977 - val_loss: 0.2247 - val_acc: 0.6667 - val_recall_m: 0.6667\n",
            "Epoch 40/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2049 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.1989 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 41/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2037 - acc: 0.6977 - recall_m: 0.6977 - val_loss: 0.1989 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 42/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2036 - acc: 0.6987 - recall_m: 0.6987 - val_loss: 0.2032 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 43/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2060 - acc: 0.6940 - recall_m: 0.6940 - val_loss: 0.1894 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 44/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2027 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2055 - val_acc: 0.6709 - val_recall_m: 0.6709\n",
            "Epoch 45/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2068 - acc: 0.6982 - recall_m: 0.6982 - val_loss: 0.1791 - val_acc: 0.6962 - val_recall_m: 0.6962\n",
            "Epoch 46/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2062 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.2025 - val_acc: 0.6751 - val_recall_m: 0.6751\n",
            "Epoch 47/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2060 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.2027 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 48/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2047 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.1890 - val_acc: 0.6962 - val_recall_m: 0.6962\n",
            "Epoch 49/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2075 - acc: 0.6879 - recall_m: 0.6879 - val_loss: 0.2152 - val_acc: 0.6709 - val_recall_m: 0.6709\n",
            "Epoch 50/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2063 - acc: 0.6940 - recall_m: 0.6940 - val_loss: 0.2177 - val_acc: 0.6751 - val_recall_m: 0.6751\n",
            "Epoch 51/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2070 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2271 - val_acc: 0.6709 - val_recall_m: 0.6709\n",
            "Epoch 52/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2049 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.2074 - val_acc: 0.6793 - val_recall_m: 0.6793\n",
            "Epoch 53/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2031 - acc: 0.6973 - recall_m: 0.6973 - val_loss: 0.2432 - val_acc: 0.6414 - val_recall_m: 0.6414\n",
            "Epoch 54/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2064 - acc: 0.6940 - recall_m: 0.6940 - val_loss: 0.2361 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 55/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2039 - acc: 0.6940 - recall_m: 0.6940 - val_loss: 0.2558 - val_acc: 0.6329 - val_recall_m: 0.6329\n",
            "Epoch 56/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2056 - acc: 0.6907 - recall_m: 0.6907 - val_loss: 0.2332 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 57/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2061 - acc: 0.6992 - recall_m: 0.6992 - val_loss: 0.2224 - val_acc: 0.6624 - val_recall_m: 0.6624\n",
            "Epoch 58/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2070 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.2616 - val_acc: 0.5148 - val_recall_m: 0.5148\n",
            "Epoch 59/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2062 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2652 - val_acc: 0.5190 - val_recall_m: 0.5190\n",
            "Epoch 60/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2049 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.2744 - val_acc: 0.4937 - val_recall_m: 0.4937\n",
            "Epoch 61/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2061 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2434 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 62/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2052 - acc: 0.6977 - recall_m: 0.6977 - val_loss: 0.2296 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 63/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2053 - acc: 0.6982 - recall_m: 0.6982 - val_loss: 0.2285 - val_acc: 0.6624 - val_recall_m: 0.6624\n",
            "Epoch 64/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2044 - acc: 0.6916 - recall_m: 0.6916 - val_loss: 0.2632 - val_acc: 0.5190 - val_recall_m: 0.5190\n",
            "Epoch 65/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2037 - acc: 0.6954 - recall_m: 0.6954 - val_loss: 0.2392 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 66/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.2066 - acc: 0.6916 - recall_m: 0.6916 - val_loss: 0.2415 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 67/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.2029 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2481 - val_acc: 0.6414 - val_recall_m: 0.6414\n",
            "Epoch 68/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2046 - acc: 0.6940 - recall_m: 0.6940 - val_loss: 0.2294 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 69/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2046 - acc: 0.6954 - recall_m: 0.6954 - val_loss: 0.2251 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 70/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2053 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2235 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 71/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2026 - acc: 0.6973 - recall_m: 0.6973 - val_loss: 0.2166 - val_acc: 0.6624 - val_recall_m: 0.6624\n",
            "Epoch 72/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2064 - acc: 0.6864 - recall_m: 0.6864 - val_loss: 0.2064 - val_acc: 0.6624 - val_recall_m: 0.6624\n",
            "Epoch 73/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2036 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2077 - val_acc: 0.6667 - val_recall_m: 0.6667\n",
            "Epoch 74/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2045 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2171 - val_acc: 0.6667 - val_recall_m: 0.6667\n",
            "Epoch 75/300\n",
            "2124/2124 [==============================] - 0s 206us/step - loss: 0.2028 - acc: 0.6916 - recall_m: 0.6916 - val_loss: 0.2149 - val_acc: 0.6667 - val_recall_m: 0.6667\n",
            "Epoch 76/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2038 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.2135 - val_acc: 0.6667 - val_recall_m: 0.6667\n",
            "Epoch 77/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2038 - acc: 0.6996 - recall_m: 0.6996 - val_loss: 0.2009 - val_acc: 0.6751 - val_recall_m: 0.6751\n",
            "Epoch 78/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2052 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2128 - val_acc: 0.6667 - val_recall_m: 0.6667\n",
            "Epoch 79/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2046 - acc: 0.6926 - recall_m: 0.6926 - val_loss: 0.2036 - val_acc: 0.6751 - val_recall_m: 0.6751\n",
            "Epoch 80/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2028 - acc: 0.6996 - recall_m: 0.6996 - val_loss: 0.1883 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 81/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2065 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.1923 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 82/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2028 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.1701 - val_acc: 0.7089 - val_recall_m: 0.7089\n",
            "Epoch 83/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2017 - acc: 0.7001 - recall_m: 0.7001 - val_loss: 0.1912 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 84/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2033 - acc: 0.6926 - recall_m: 0.6926 - val_loss: 0.2005 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 85/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2042 - acc: 0.6916 - recall_m: 0.6916 - val_loss: 0.2164 - val_acc: 0.6793 - val_recall_m: 0.6793\n",
            "Epoch 86/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.2057 - acc: 0.6926 - recall_m: 0.6926 - val_loss: 0.2012 - val_acc: 0.6962 - val_recall_m: 0.6962\n",
            "Epoch 87/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.2050 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.1843 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 88/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2010 - acc: 0.7015 - recall_m: 0.7015 - val_loss: 0.2360 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 89/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2049 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.1997 - val_acc: 0.6878 - val_recall_m: 0.6878\n",
            "Epoch 90/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2028 - acc: 0.6897 - recall_m: 0.6897 - val_loss: 0.2081 - val_acc: 0.6793 - val_recall_m: 0.6793\n",
            "Epoch 91/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2033 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.1821 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 92/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2038 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.1871 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 93/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2026 - acc: 0.6992 - recall_m: 0.6992 - val_loss: 0.1719 - val_acc: 0.7089 - val_recall_m: 0.7089\n",
            "Epoch 94/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2033 - acc: 0.7006 - recall_m: 0.7006 - val_loss: 0.1676 - val_acc: 0.7257 - val_recall_m: 0.7257\n",
            "Epoch 95/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2007 - acc: 0.7015 - recall_m: 0.7015 - val_loss: 0.1435 - val_acc: 0.7848 - val_recall_m: 0.7848\n",
            "Epoch 96/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2029 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.1269 - val_acc: 0.7975 - val_recall_m: 0.7975\n",
            "Epoch 97/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2035 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.1163 - val_acc: 0.8017 - val_recall_m: 0.8017\n",
            "Epoch 98/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.2020 - acc: 0.6982 - recall_m: 0.6982 - val_loss: 0.1047 - val_acc: 0.8481 - val_recall_m: 0.8481\n",
            "Epoch 99/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2005 - acc: 0.6982 - recall_m: 0.6982 - val_loss: 0.0857 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 100/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1994 - acc: 0.7053 - recall_m: 0.7053 - val_loss: 0.0897 - val_acc: 0.9662 - val_recall_m: 0.9662\n",
            "Epoch 101/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2032 - acc: 0.6987 - recall_m: 0.6987 - val_loss: 0.0822 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 102/300\n",
            "2124/2124 [==============================] - 0s 206us/step - loss: 0.2026 - acc: 0.6977 - recall_m: 0.6977 - val_loss: 0.0803 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 103/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.2017 - acc: 0.7001 - recall_m: 0.7001 - val_loss: 0.0774 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 104/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2020 - acc: 0.6992 - recall_m: 0.6992 - val_loss: 0.0642 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 105/300\n",
            "2124/2124 [==============================] - 0s 205us/step - loss: 0.2025 - acc: 0.6968 - recall_m: 0.6968 - val_loss: 0.0730 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 106/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2026 - acc: 0.6992 - recall_m: 0.6992 - val_loss: 0.0787 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 107/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2032 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.0837 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 108/300\n",
            "2124/2124 [==============================] - 0s 219us/step - loss: 0.2016 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.0732 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 109/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.1996 - acc: 0.6977 - recall_m: 0.6977 - val_loss: 0.0724 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 110/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2015 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.0620 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 111/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1998 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.0538 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 112/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2007 - acc: 0.7010 - recall_m: 0.7010 - val_loss: 0.0383 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 113/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2022 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.0380 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 114/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2002 - acc: 0.6902 - recall_m: 0.6902 - val_loss: 0.0437 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 115/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2007 - acc: 0.6968 - recall_m: 0.6968 - val_loss: 0.0469 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 116/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1952 - acc: 0.7109 - recall_m: 0.7109 - val_loss: 0.0546 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 117/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1982 - acc: 0.7029 - recall_m: 0.7029 - val_loss: 0.0760 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 118/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1986 - acc: 0.7006 - recall_m: 0.7006 - val_loss: 0.0957 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 119/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1929 - acc: 0.7161 - recall_m: 0.7161 - val_loss: 0.0955 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 120/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1946 - acc: 0.7029 - recall_m: 0.7029 - val_loss: 0.0901 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 121/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1922 - acc: 0.7062 - recall_m: 0.7062 - val_loss: 0.0827 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 122/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1923 - acc: 0.7133 - recall_m: 0.7133 - val_loss: 0.0793 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 123/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1962 - acc: 0.7105 - recall_m: 0.7105 - val_loss: 0.0913 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 124/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1888 - acc: 0.7147 - recall_m: 0.7147 - val_loss: 0.1175 - val_acc: 0.9831 - val_recall_m: 0.9831\n",
            "Epoch 125/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1913 - acc: 0.7246 - recall_m: 0.7246 - val_loss: 0.0725 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 126/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1847 - acc: 0.7345 - recall_m: 0.7345 - val_loss: 0.0781 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 127/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1858 - acc: 0.7232 - recall_m: 0.7232 - val_loss: 0.0600 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 128/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1811 - acc: 0.7340 - recall_m: 0.7340 - val_loss: 0.0662 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 129/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1826 - acc: 0.7359 - recall_m: 0.7359 - val_loss: 0.0887 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 130/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1797 - acc: 0.7486 - recall_m: 0.7486 - val_loss: 0.0877 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 131/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1791 - acc: 0.7396 - recall_m: 0.7396 - val_loss: 0.0891 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 132/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1821 - acc: 0.7387 - recall_m: 0.7387 - val_loss: 0.1176 - val_acc: 0.9367 - val_recall_m: 0.9367\n",
            "Epoch 133/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1779 - acc: 0.7467 - recall_m: 0.7467 - val_loss: 0.1010 - val_acc: 0.9578 - val_recall_m: 0.9578\n",
            "Epoch 134/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1847 - acc: 0.7392 - recall_m: 0.7392 - val_loss: 0.1017 - val_acc: 0.9536 - val_recall_m: 0.9536\n",
            "Epoch 135/300\n",
            "2124/2124 [==============================] - 0s 217us/step - loss: 0.1774 - acc: 0.7524 - recall_m: 0.7524 - val_loss: 0.1846 - val_acc: 0.7257 - val_recall_m: 0.7257\n",
            "Epoch 136/300\n",
            "2124/2124 [==============================] - 0s 206us/step - loss: 0.1851 - acc: 0.7354 - recall_m: 0.7354 - val_loss: 0.1911 - val_acc: 0.6793 - val_recall_m: 0.6793\n",
            "Epoch 137/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1814 - acc: 0.7326 - recall_m: 0.7326 - val_loss: 0.2014 - val_acc: 0.6245 - val_recall_m: 0.6245\n",
            "Epoch 138/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1762 - acc: 0.7392 - recall_m: 0.7392 - val_loss: 0.1933 - val_acc: 0.6540 - val_recall_m: 0.6540\n",
            "Epoch 139/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1711 - acc: 0.7604 - recall_m: 0.7604 - val_loss: 0.1722 - val_acc: 0.7215 - val_recall_m: 0.7215\n",
            "Epoch 140/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1798 - acc: 0.7378 - recall_m: 0.7378 - val_loss: 0.1499 - val_acc: 0.7848 - val_recall_m: 0.7848\n",
            "Epoch 141/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1759 - acc: 0.7505 - recall_m: 0.7505 - val_loss: 0.1468 - val_acc: 0.8186 - val_recall_m: 0.8186\n",
            "Epoch 142/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1746 - acc: 0.7500 - recall_m: 0.7500 - val_loss: 0.1527 - val_acc: 0.8017 - val_recall_m: 0.8017\n",
            "Epoch 143/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1753 - acc: 0.7458 - recall_m: 0.7458 - val_loss: 0.1440 - val_acc: 0.8312 - val_recall_m: 0.8312\n",
            "Epoch 144/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1723 - acc: 0.7556 - recall_m: 0.7556 - val_loss: 0.1308 - val_acc: 0.8903 - val_recall_m: 0.8903\n",
            "Epoch 145/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1722 - acc: 0.7533 - recall_m: 0.7533 - val_loss: 0.1322 - val_acc: 0.8439 - val_recall_m: 0.8439\n",
            "Epoch 146/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1713 - acc: 0.7533 - recall_m: 0.7533 - val_loss: 0.1102 - val_acc: 0.8987 - val_recall_m: 0.8987\n",
            "Epoch 147/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1772 - acc: 0.7505 - recall_m: 0.7505 - val_loss: 0.1136 - val_acc: 0.8776 - val_recall_m: 0.8776\n",
            "Epoch 148/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1705 - acc: 0.7599 - recall_m: 0.7599 - val_loss: 0.0926 - val_acc: 0.9789 - val_recall_m: 0.9789\n",
            "Epoch 149/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1735 - acc: 0.7444 - recall_m: 0.7444 - val_loss: 0.1130 - val_acc: 0.8861 - val_recall_m: 0.8861\n",
            "Epoch 150/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1702 - acc: 0.7580 - recall_m: 0.7580 - val_loss: 0.1089 - val_acc: 0.8945 - val_recall_m: 0.8945\n",
            "Epoch 151/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1709 - acc: 0.7622 - recall_m: 0.7622 - val_loss: 0.1019 - val_acc: 0.9114 - val_recall_m: 0.9114\n",
            "Epoch 152/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1731 - acc: 0.7509 - recall_m: 0.7509 - val_loss: 0.0927 - val_acc: 0.9283 - val_recall_m: 0.9283\n",
            "Epoch 153/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1669 - acc: 0.7622 - recall_m: 0.7622 - val_loss: 0.0861 - val_acc: 0.9705 - val_recall_m: 0.9705\n",
            "Epoch 154/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1699 - acc: 0.7669 - recall_m: 0.7669 - val_loss: 0.0984 - val_acc: 0.9156 - val_recall_m: 0.9156\n",
            "Epoch 155/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1707 - acc: 0.7556 - recall_m: 0.7556 - val_loss: 0.0884 - val_acc: 0.9789 - val_recall_m: 0.9789\n",
            "Epoch 156/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1676 - acc: 0.7589 - recall_m: 0.7589 - val_loss: 0.0769 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 157/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1660 - acc: 0.7651 - recall_m: 0.7651 - val_loss: 0.0733 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 158/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1659 - acc: 0.7679 - recall_m: 0.7679 - val_loss: 0.0750 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 159/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1681 - acc: 0.7655 - recall_m: 0.7655 - val_loss: 0.0708 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 160/300\n",
            "2124/2124 [==============================] - 0s 206us/step - loss: 0.1667 - acc: 0.7604 - recall_m: 0.7604 - val_loss: 0.0652 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 161/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1718 - acc: 0.7566 - recall_m: 0.7566 - val_loss: 0.0674 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 162/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1679 - acc: 0.7618 - recall_m: 0.7618 - val_loss: 0.0669 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 163/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1656 - acc: 0.7679 - recall_m: 0.7679 - val_loss: 0.0603 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 164/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1647 - acc: 0.7585 - recall_m: 0.7585 - val_loss: 0.0599 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 165/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1642 - acc: 0.7745 - recall_m: 0.7745 - val_loss: 0.0578 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 166/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1673 - acc: 0.7698 - recall_m: 0.7698 - val_loss: 0.0576 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 167/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1592 - acc: 0.7830 - recall_m: 0.7830 - val_loss: 0.0546 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 168/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.1673 - acc: 0.7660 - recall_m: 0.7660 - val_loss: 0.0503 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 169/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1645 - acc: 0.7669 - recall_m: 0.7669 - val_loss: 0.0422 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 170/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1629 - acc: 0.7707 - recall_m: 0.7707 - val_loss: 0.0501 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 171/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1642 - acc: 0.7717 - recall_m: 0.7717 - val_loss: 0.0440 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 172/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1568 - acc: 0.7815 - recall_m: 0.7815 - val_loss: 0.0496 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 173/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1588 - acc: 0.7806 - recall_m: 0.7806 - val_loss: 0.0450 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 174/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1572 - acc: 0.7797 - recall_m: 0.7797 - val_loss: 0.0475 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 175/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1646 - acc: 0.7717 - recall_m: 0.7717 - val_loss: 0.0570 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 176/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1566 - acc: 0.7839 - recall_m: 0.7839 - val_loss: 0.0520 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 177/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1567 - acc: 0.7848 - recall_m: 0.7848 - val_loss: 0.0542 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 178/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1638 - acc: 0.7745 - recall_m: 0.7745 - val_loss: 0.0628 - val_acc: 0.9789 - val_recall_m: 0.9789\n",
            "Epoch 179/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1540 - acc: 0.7900 - recall_m: 0.7900 - val_loss: 0.0511 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 180/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1631 - acc: 0.7674 - recall_m: 0.7674 - val_loss: 0.0531 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 181/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1644 - acc: 0.7702 - recall_m: 0.7702 - val_loss: 0.0537 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 182/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1576 - acc: 0.7792 - recall_m: 0.7792 - val_loss: 0.0479 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 183/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1565 - acc: 0.7844 - recall_m: 0.7844 - val_loss: 0.0465 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 184/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1542 - acc: 0.7919 - recall_m: 0.7919 - val_loss: 0.0452 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 185/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1547 - acc: 0.7891 - recall_m: 0.7891 - val_loss: 0.0446 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 186/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1533 - acc: 0.7895 - recall_m: 0.7895 - val_loss: 0.0448 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 187/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1551 - acc: 0.7811 - recall_m: 0.7811 - val_loss: 0.0428 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 188/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1589 - acc: 0.7815 - recall_m: 0.7815 - val_loss: 0.0535 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 189/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1611 - acc: 0.7848 - recall_m: 0.7848 - val_loss: 0.0448 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 190/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1575 - acc: 0.7853 - recall_m: 0.7853 - val_loss: 0.0409 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 191/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1561 - acc: 0.7815 - recall_m: 0.7815 - val_loss: 0.0374 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 192/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1562 - acc: 0.7886 - recall_m: 0.7886 - val_loss: 0.0377 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 193/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1537 - acc: 0.7834 - recall_m: 0.7834 - val_loss: 0.0457 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 194/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1521 - acc: 0.7933 - recall_m: 0.7933 - val_loss: 0.0585 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 195/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1566 - acc: 0.7895 - recall_m: 0.7895 - val_loss: 0.0473 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 196/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1533 - acc: 0.7952 - recall_m: 0.7952 - val_loss: 0.0450 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 197/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1550 - acc: 0.7839 - recall_m: 0.7839 - val_loss: 0.0445 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 198/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1549 - acc: 0.7853 - recall_m: 0.7853 - val_loss: 0.0362 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 199/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1543 - acc: 0.7924 - recall_m: 0.7924 - val_loss: 0.0371 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 200/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1593 - acc: 0.7797 - recall_m: 0.7797 - val_loss: 0.0322 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 201/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1543 - acc: 0.7839 - recall_m: 0.7839 - val_loss: 0.0276 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 202/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1535 - acc: 0.7938 - recall_m: 0.7938 - val_loss: 0.0340 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 203/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1521 - acc: 0.7877 - recall_m: 0.7877 - val_loss: 0.0318 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 204/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1542 - acc: 0.7834 - recall_m: 0.7834 - val_loss: 0.0342 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 205/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1498 - acc: 0.7957 - recall_m: 0.7957 - val_loss: 0.0334 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 206/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1506 - acc: 0.7848 - recall_m: 0.7848 - val_loss: 0.0376 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 207/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1529 - acc: 0.7872 - recall_m: 0.7872 - val_loss: 0.0406 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 208/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1581 - acc: 0.7815 - recall_m: 0.7815 - val_loss: 0.0354 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 209/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1541 - acc: 0.7778 - recall_m: 0.7778 - val_loss: 0.0337 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 210/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1507 - acc: 0.7895 - recall_m: 0.7895 - val_loss: 0.0378 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 211/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1579 - acc: 0.7806 - recall_m: 0.7806 - val_loss: 0.0398 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 212/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1486 - acc: 0.8018 - recall_m: 0.8018 - val_loss: 0.0357 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 213/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1491 - acc: 0.7919 - recall_m: 0.7919 - val_loss: 0.0316 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 214/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1519 - acc: 0.7900 - recall_m: 0.7900 - val_loss: 0.0344 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 215/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1487 - acc: 0.8037 - recall_m: 0.8037 - val_loss: 0.0319 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 216/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1519 - acc: 0.7905 - recall_m: 0.7905 - val_loss: 0.0300 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 217/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.1463 - acc: 0.8027 - recall_m: 0.8027 - val_loss: 0.0290 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 218/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1499 - acc: 0.7947 - recall_m: 0.7947 - val_loss: 0.0292 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 219/300\n",
            "2124/2124 [==============================] - 0s 219us/step - loss: 0.1541 - acc: 0.7867 - recall_m: 0.7867 - val_loss: 0.0274 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 220/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1465 - acc: 0.8056 - recall_m: 0.8056 - val_loss: 0.0256 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 221/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1483 - acc: 0.7952 - recall_m: 0.7952 - val_loss: 0.0271 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 222/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1447 - acc: 0.8098 - recall_m: 0.8098 - val_loss: 0.0293 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 223/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1399 - acc: 0.8089 - recall_m: 0.8089 - val_loss: 0.0272 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 224/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1510 - acc: 0.8004 - recall_m: 0.8004 - val_loss: 0.0249 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 225/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1448 - acc: 0.8107 - recall_m: 0.8107 - val_loss: 0.0273 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 226/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1463 - acc: 0.7990 - recall_m: 0.7990 - val_loss: 0.0259 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 227/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1471 - acc: 0.8051 - recall_m: 0.8051 - val_loss: 0.0272 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 228/300\n",
            "2124/2124 [==============================] - 0s 217us/step - loss: 0.1515 - acc: 0.7928 - recall_m: 0.7928 - val_loss: 0.0233 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 229/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1460 - acc: 0.8041 - recall_m: 0.8041 - val_loss: 0.0201 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 230/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1459 - acc: 0.7985 - recall_m: 0.7985 - val_loss: 0.0222 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 231/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1448 - acc: 0.8037 - recall_m: 0.8037 - val_loss: 0.0192 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 232/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1498 - acc: 0.7933 - recall_m: 0.7933 - val_loss: 0.0190 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 233/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1470 - acc: 0.7994 - recall_m: 0.7994 - val_loss: 0.0183 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 234/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1503 - acc: 0.7957 - recall_m: 0.7957 - val_loss: 0.0196 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 235/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1517 - acc: 0.7933 - recall_m: 0.7933 - val_loss: 0.0211 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 236/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1498 - acc: 0.7910 - recall_m: 0.7910 - val_loss: 0.0211 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 237/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1437 - acc: 0.8093 - recall_m: 0.8093 - val_loss: 0.0221 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 238/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1416 - acc: 0.8074 - recall_m: 0.8074 - val_loss: 0.0199 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 239/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1462 - acc: 0.8056 - recall_m: 0.8056 - val_loss: 0.0249 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 240/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1464 - acc: 0.7980 - recall_m: 0.7980 - val_loss: 0.0247 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 241/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1441 - acc: 0.8046 - recall_m: 0.8046 - val_loss: 0.0288 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 242/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1381 - acc: 0.8150 - recall_m: 0.8150 - val_loss: 0.0284 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 243/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1416 - acc: 0.8107 - recall_m: 0.8107 - val_loss: 0.0250 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 244/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1422 - acc: 0.8093 - recall_m: 0.8093 - val_loss: 0.0220 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 245/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1418 - acc: 0.8126 - recall_m: 0.8126 - val_loss: 0.0265 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 246/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.1478 - acc: 0.7928 - recall_m: 0.7928 - val_loss: 0.0199 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 247/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1418 - acc: 0.8079 - recall_m: 0.8079 - val_loss: 0.0212 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 248/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1422 - acc: 0.8023 - recall_m: 0.8023 - val_loss: 0.0296 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 249/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1435 - acc: 0.8065 - recall_m: 0.8065 - val_loss: 0.0254 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 250/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1435 - acc: 0.8065 - recall_m: 0.8065 - val_loss: 0.0259 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 251/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1390 - acc: 0.8121 - recall_m: 0.8121 - val_loss: 0.0332 - val_acc: 0.9831 - val_recall_m: 0.9831\n",
            "Epoch 252/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1383 - acc: 0.8202 - recall_m: 0.8202 - val_loss: 0.0246 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 253/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1371 - acc: 0.8154 - recall_m: 0.8154 - val_loss: 0.0271 - val_acc: 0.9831 - val_recall_m: 0.9831\n",
            "Epoch 254/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1436 - acc: 0.8093 - recall_m: 0.8093 - val_loss: 0.0445 - val_acc: 0.9578 - val_recall_m: 0.9578\n",
            "Epoch 255/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1483 - acc: 0.8060 - recall_m: 0.8060 - val_loss: 0.0335 - val_acc: 0.9705 - val_recall_m: 0.9705\n",
            "Epoch 256/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1409 - acc: 0.8159 - recall_m: 0.8159 - val_loss: 0.0232 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 257/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1433 - acc: 0.8136 - recall_m: 0.8136 - val_loss: 0.0330 - val_acc: 0.9831 - val_recall_m: 0.9831\n",
            "Epoch 258/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1450 - acc: 0.8046 - recall_m: 0.8046 - val_loss: 0.0316 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 259/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1403 - acc: 0.8051 - recall_m: 0.8051 - val_loss: 0.0542 - val_acc: 0.9241 - val_recall_m: 0.9241\n",
            "Epoch 260/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1385 - acc: 0.8145 - recall_m: 0.8145 - val_loss: 0.0379 - val_acc: 0.9747 - val_recall_m: 0.9747\n",
            "Epoch 261/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1364 - acc: 0.8187 - recall_m: 0.8187 - val_loss: 0.0521 - val_acc: 0.9451 - val_recall_m: 0.9451\n",
            "Epoch 262/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1410 - acc: 0.8060 - recall_m: 0.8060 - val_loss: 0.0433 - val_acc: 0.9662 - val_recall_m: 0.9662\n",
            "Epoch 263/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1443 - acc: 0.8098 - recall_m: 0.8098 - val_loss: 0.0336 - val_acc: 0.9789 - val_recall_m: 0.9789\n",
            "Epoch 264/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1399 - acc: 0.8169 - recall_m: 0.8169 - val_loss: 0.0256 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 265/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1445 - acc: 0.8089 - recall_m: 0.8089 - val_loss: 0.0211 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 266/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1330 - acc: 0.8272 - recall_m: 0.8272 - val_loss: 0.0164 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 267/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1471 - acc: 0.7990 - recall_m: 0.7990 - val_loss: 0.0150 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 268/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1408 - acc: 0.8192 - recall_m: 0.8192 - val_loss: 0.0214 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 269/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1462 - acc: 0.7994 - recall_m: 0.7994 - val_loss: 0.0191 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 270/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1380 - acc: 0.8126 - recall_m: 0.8126 - val_loss: 0.0283 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 271/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1343 - acc: 0.8225 - recall_m: 0.8225 - val_loss: 0.0305 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 272/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1405 - acc: 0.8136 - recall_m: 0.8136 - val_loss: 0.0460 - val_acc: 0.9578 - val_recall_m: 0.9578\n",
            "Epoch 273/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1421 - acc: 0.8070 - recall_m: 0.8070 - val_loss: 0.0501 - val_acc: 0.9620 - val_recall_m: 0.9620\n",
            "Epoch 274/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1445 - acc: 0.8008 - recall_m: 0.8008 - val_loss: 0.0423 - val_acc: 0.9620 - val_recall_m: 0.9620\n",
            "Epoch 275/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1404 - acc: 0.8173 - recall_m: 0.8173 - val_loss: 0.0381 - val_acc: 0.9747 - val_recall_m: 0.9747\n",
            "Epoch 276/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1385 - acc: 0.8150 - recall_m: 0.8150 - val_loss: 0.0370 - val_acc: 0.9747 - val_recall_m: 0.9747\n",
            "Epoch 277/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1418 - acc: 0.8060 - recall_m: 0.8060 - val_loss: 0.0367 - val_acc: 0.9747 - val_recall_m: 0.9747\n",
            "Epoch 278/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1369 - acc: 0.8164 - recall_m: 0.8164 - val_loss: 0.0280 - val_acc: 0.9831 - val_recall_m: 0.9831\n",
            "Epoch 279/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1337 - acc: 0.8206 - recall_m: 0.8206 - val_loss: 0.0270 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 280/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1316 - acc: 0.8267 - recall_m: 0.8267 - val_loss: 0.0177 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 281/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1373 - acc: 0.8206 - recall_m: 0.8206 - val_loss: 0.0203 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 282/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1360 - acc: 0.8202 - recall_m: 0.8202 - val_loss: 0.0234 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 283/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1408 - acc: 0.8084 - recall_m: 0.8084 - val_loss: 0.0204 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 284/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1417 - acc: 0.8107 - recall_m: 0.8107 - val_loss: 0.0182 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 285/300\n",
            "2124/2124 [==============================] - 0s 206us/step - loss: 0.1396 - acc: 0.8098 - recall_m: 0.8098 - val_loss: 0.0176 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 286/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1345 - acc: 0.8183 - recall_m: 0.8183 - val_loss: 0.0214 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 287/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1363 - acc: 0.8192 - recall_m: 0.8192 - val_loss: 0.0163 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 288/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1407 - acc: 0.8126 - recall_m: 0.8126 - val_loss: 0.0169 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 289/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1387 - acc: 0.8051 - recall_m: 0.8051 - val_loss: 0.0232 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 290/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1383 - acc: 0.8112 - recall_m: 0.8112 - val_loss: 0.0170 - val_acc: 1.0000 - val_recall_m: 1.0000\n",
            "Epoch 291/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1441 - acc: 0.8107 - recall_m: 0.8107 - val_loss: 0.0204 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 292/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1368 - acc: 0.8169 - recall_m: 0.8169 - val_loss: 0.0165 - val_acc: 0.9958 - val_recall_m: 0.9958\n",
            "Epoch 293/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1379 - acc: 0.8145 - recall_m: 0.8145 - val_loss: 0.0229 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 294/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1340 - acc: 0.8216 - recall_m: 0.8216 - val_loss: 0.0248 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 295/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1395 - acc: 0.8192 - recall_m: 0.8192 - val_loss: 0.0264 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 296/300\n",
            "2124/2124 [==============================] - 0s 204us/step - loss: 0.1347 - acc: 0.8225 - recall_m: 0.8225 - val_loss: 0.0241 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 297/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1331 - acc: 0.8192 - recall_m: 0.8192 - val_loss: 0.0217 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 298/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1343 - acc: 0.8178 - recall_m: 0.8178 - val_loss: 0.0251 - val_acc: 0.9873 - val_recall_m: 0.9873\n",
            "Epoch 299/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1310 - acc: 0.8249 - recall_m: 0.8249 - val_loss: 0.0225 - val_acc: 0.9916 - val_recall_m: 0.9916\n",
            "Epoch 300/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1327 - acc: 0.8216 - recall_m: 0.8216 - val_loss: 0.0247 - val_acc: 0.9831 - val_recall_m: 0.9831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3cf40b9d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1FdGFad9kyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "048e5d3c-d069-4abe-affb-ac1db848ab42"
      },
      "source": [
        "cls.evaluate(x_te, y_te)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "591/591 [==============================] - 0s 134us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06321612113926012, 0.9204737735682131, 0.9204737735682131]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QYKIsSgHvqh",
        "colab_type": "text"
      },
      "source": [
        "## Os erros metodológicos\n",
        "\n",
        "1. Os parâmetros não tem referências, foram feitos no teste.\n",
        "\n",
        "2. O Word2Vec computa todos os valores do banco de dados, o que pode enviezar os valores do dicionário. Como Rosa Weber \"Pelo principio do colegiado, darei meu voto para seguir a maioria que será composta por mim\".\n",
        "\n",
        "3. Não há outro classificador para comparar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK4CtNKfAFwv",
        "colab_type": "text"
      },
      "source": [
        "## Referencias\n",
        "\n"
      ]
    }
  ]
}