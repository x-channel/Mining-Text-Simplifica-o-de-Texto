{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projeto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/projeto2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP583IXGNeHC",
        "colab_type": "text"
      },
      "source": [
        "# Projeto de Simplificação de Texto\n",
        "\n",
        "Nas primeiras abordagens, houve uma tentativa de produzir uma rede neural que tivesse como entrada o *token frequence* e saida outro *token frequence*.\n",
        " Apesar disso poder ser considerado um resultado válido para a tentativa de melhorar a classificação de texto, não podemos considerar uma frase como um conjunto de palavras com a propriedade da comutatividade.\n",
        "  A ordem das palavras acaba importando muito para os humanos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptDnWb-pbJUb",
        "colab_type": "text"
      },
      "source": [
        "## importando bugingangas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh5apxspbJ0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import random\n",
        "#import pandas as pd\n",
        "from urllib import request as req\n",
        "from gensim.models import keyedvectors as kv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQFno4IJOzW3",
        "colab_type": "text"
      },
      "source": [
        "## Paper With Code\n",
        "\n",
        "~~Após um gole de sorte, eu acabo por encontrar essa maravilha~~ chamado de [Paper With Code](https://paperswithcode.com/sota/document-summarization-on-cnn-daily-mail), é um ~~bom~~ compilado de resultados cientificos sobre determinados problemas da computação. O primeiro artigo do link de cima, mostra uma solução com ROGUE-1 de 43.83 para o problema de sumarização de documentos como o *state of the art*.\n",
        "\n",
        "![paper with code](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/paperwithcode.png?raw=true)\n",
        "<center>paper with code</center>\n",
        "\n",
        "No artigo *Text Summarization with Pretrained Encoders* (LIU e LAPATA, 2019), os autores representam o texto como *Bert*, que é gerado por uma rede neural e é um caso especial do *word2vec*.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npzGa9dI5viX",
        "colab_type": "text"
      },
      "source": [
        "## Representação do Bert word2vec\n",
        "\n",
        "*Kyubyong* criou um preset do Bert, um dicionário onde cada palavra é representada por um vetor de 768 valores decimais.\n",
        "Visto algumas limitações das plataformas *Google Colab* e do *Github*, serão usadas apenas 300 instâncias do CNN, que gerou um dicionário reduzido de apenas 25mb.\n",
        "\n",
        "![Bert is Evil](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/audio-banner.jpg?raw=true)\n",
        "<center>Bert is Evil</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iap7h5R65zWn",
        "colab_type": "text"
      },
      "source": [
        "## Base de dados da Cable News Network\n",
        "\n",
        "A base de dados pode ser encontrado [nesse github da google](https://github.com/google-research-datasets/sentence-compression), no formato *Json*. Essa base de dados é formada com notícias da CNN com a primeira linha da noticia, com o título, com todos os bigramas possíveis e com informações do TAG. Porém no trabalho apenas será usado a primeira linha como entrada e o título como saída.\n",
        "\n",
        "![Json](https://github.com/x-channel/Mining-Text-Simplifica-o-de-Texto/blob/master/imagens/Jasonf.jpg?raw=true)\n",
        "<center>Json</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Nkg503WqUi",
        "colab_type": "text"
      },
      "source": [
        "## Mesclar o bert com o json.\n",
        "\n",
        "Basicamente esse script carrega o vocabulário do dicionário bert, onde a partir da segunda linha, cada linha é uma palavra, seguida de sua representação vetorial com 768 valores.\n",
        "Eventualmente aparecem algumas palavras estranhas como \"##,\".\n",
        "Essa palavra significa somente que a palavra anterior termina com uma virgula.\n",
        "\n",
        "Depois de carregar o vocabulário, ele começa a ler as noticias do json.\n",
        "Ele segmenta uma noticia, a transformando em um dicionário do python, procura os textos alvos\n",
        "### jfk['graph']['sentence'] e jfk['headline'].\n",
        "\n",
        "Com os textos em mãos, ele cata as palavras de cada texto, criando uma matriz de tamanho 768*2 pela quantidade de linhas do subtitulo da noticia.\n",
        "\n",
        "Observar que para esse código rodar ele deve estar na seguinte pasta ~~por isso está comentado~~. Com o json nomeado *in.json*, com o bert nomeado *dicionariolongo.vec* e uma pasta vazia chamada de *instancias*. O script vai gerar um *dicionario.csv* e varias noticias dentro da pasta instancias. Infelizmente algumas noticias tem caracters que não permitem seu uso como nome do arquivo, por isso todas as noticias foram nomeadas de *arquivo_n.csv* ~~Outro motivo para você guardar seus dados em um único arquivo json~~.\n",
        "\n",
        ">O diretório do arquivo.\n",
        ">>in.json \\n\n",
        "dicionariolongo.vec \\n\n",
        "preprobert.py\n",
        ">>> instancias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Uesl-rWdP1",
        "colab_type": "code",
        "outputId": "992284cb-1f01-42e1-ecaf-3903ce2a2496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "#texto para matriz Bert\n",
        "\n",
        "#!/usr/bin/python\n",
        "# -*- coding: UTF-8 -*-\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "import fileinput\n",
        "\n",
        "import codecs\n",
        "\n",
        "import os\n",
        "\n",
        "dici = {}\n",
        "fins = {}\n",
        "dico = {} #dicionario reduzido\n",
        "\n",
        "\n",
        "#carrega o dicionario bert\n",
        "with open(\"dicionariolongo.vec\", \"r\", encoding=\"utf-8\") as d:\n",
        "    for i in d:\n",
        "        if len(i) > 200: #isso aqui eh para tirar a primeira linha, altura x largura\n",
        "            try:\n",
        "                a = i.split()\n",
        "                if '##' in a[0]:\n",
        "                    fins[a[0][2:].lower()] = []\n",
        "                    for j in a[1:]:\n",
        "                        fins[a[0][2:].lower()].append(float(j))\n",
        "                elif (not a[0].lower() in dici) or a[0].islower():\n",
        "                    dici[a[0].lower()] = []\n",
        "                    for j in a[1:]:\n",
        "                        dici[a[0].lower()].append(float(j))\n",
        "            except ValueError:\n",
        "                print(\"problema com uma palavra\")\n",
        "\n",
        "\n",
        "\n",
        "with open(\"in.json\", 'rb') as f:\n",
        "    data = f.read()\n",
        "\n",
        "data = str(data)[2:-1]\n",
        "data = data.replace('\\\\n}', '\\\\n}-----')\n",
        "data = data.split('-----')\n",
        "\n",
        "blanckl = []\n",
        "for i in range(768):\n",
        "    blanckl.append('')\n",
        "\n",
        "instancias = 0\n",
        "for p in data[0:-1]:\n",
        "    entrada = []\n",
        "    saida = []\n",
        "    try:\n",
        "        jfk = json.loads(codecs.decode(p, 'unicode_escape'))\n",
        "        arquivo = jfk['graph']['sentence'].lower().replace(\"/\",\"\").replace(\"\\\\\",\"\")\n",
        "        lg = jfk['graph']['sentence'].lower().split()\n",
        "        st = jfk['headline'].lower().split()\n",
        "\n",
        "        for i in lg: #isso deveria ser uma funcao, addlist() #semTempo\n",
        "            if i in dico: #dicionario reduzido\n",
        "                entrada.append(dico[i])\n",
        "            elif i in dici:\n",
        "                dico[i] = dici[i]\n",
        "                entrada.append(dico[i])\n",
        "            else:\n",
        "                for j, jj in fins.items():\n",
        "                    if j in i[-len(j):]:\n",
        "                        i = i[:-len(j)]\n",
        "                        if i in dico: #assim ela poderia ser chamada aqui\n",
        "                            entrada.append(dico[i])\n",
        "                        elif i in dici:\n",
        "                            dico[i] = dici[i]\n",
        "                            entrada.append(dico[i])\n",
        "                        if j in dico:\n",
        "                            entrada.append(dico[j])\n",
        "                        else:\n",
        "                            dico[j] = fins[j]\n",
        "                            entrada.append(dico[j])\n",
        "                        break\n",
        "        for i in st: #isso deveria ser uma funcao, addlist() #semTempo\n",
        "            if i in dico: #dicionario reduzido\n",
        "                saida.append(dico[i])\n",
        "            elif i in dici:\n",
        "                dico[i] = dici[i]\n",
        "                saida.append(dico[i])\n",
        "            else:\n",
        "                for j, jj in fins.items():\n",
        "                    if j in i[-len(j):]:\n",
        "                        i = i[:-len(j)]\n",
        "                        if i in dico: #assim ela poderia ser chamada aqui\n",
        "                            saida.append(dico[i])\n",
        "                        elif i in dici:\n",
        "                            dico[i] = dici[i]\n",
        "                            saida.append(dico[i])\n",
        "                        if j in dico:\n",
        "                            saida.append(dico[j])\n",
        "                        else:\n",
        "                            dico[j] = fins[j]\n",
        "                            saida.append(dico[j])\n",
        "                        break\n",
        "    except ValueError:\n",
        "        print(\"Houve um Erro\")\n",
        "\n",
        "        \n",
        "    sv = os.getcwd() + '\\\\instancias\\\\arquivo_%i'%instancias + '.csv'\n",
        "    instancias += 1\n",
        "    try:\n",
        "        with open(sv, 'w', newline = '') as file:\n",
        "            writer = csv.writer(file)\n",
        "            tam = 0\n",
        "            while tam < len(entrada):\n",
        "                tm = []\n",
        "                #print(type(tm))\n",
        "                tm.extend(entrada[tam])\n",
        "                if tam < len(saida):\n",
        "                    tm.extend(saida[tam])\n",
        "                else:\n",
        "                    tm.extend(blanckl)\n",
        "                tam += 1\n",
        "                writer.writerow(tm)\n",
        "    except ValueError:\n",
        "        print(\"erro no json\")\n",
        "\n",
        "with open(\"dicionario.csv\", \"w\", newline = '') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for i, ii in dico.items():\n",
        "\ttm = []\n",
        "\ttm.append(i)\n",
        "\ttm.extend(ii)\n",
        "        writer.writerow(tm)\n",
        "\"\"\""
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#texto para matriz Bert\\n\\n#!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\n\\nimport pandas as pd\\nimport csv\\n\\nimport nltk\\nimport numpy as np\\n\\nimport json\\nimport fileinput\\n\\nimport codecs\\n\\nimport os\\n\\ndici = {}\\nfins = {}\\ndico = {} #dicionario reduzido\\n\\n\\n#carrega o dicionario bert\\nwith open(\"dicionariolongo.vec\", \"r\", encoding=\"utf-8\") as d:\\n    for i in d:\\n        if len(i) > 200: #isso aqui eh para tirar a primeira linha, altura x largura\\n            try:\\n                a = i.split()\\n                if \\'##\\' in a[0]:\\n                    fins[a[0][2:].lower()] = []\\n                    for j in a[1:]:\\n                        fins[a[0][2:].lower()].append(float(j))\\n                elif (not a[0].lower() in dici) or a[0].islower():\\n                    dici[a[0].lower()] = []\\n                    for j in a[1:]:\\n                        dici[a[0].lower()].append(float(j))\\n            except ValueError:\\n                print(\"problema com uma palavra\")\\n\\n\\n\\nwith open(\"in.json\", \\'rb\\') as f:\\n    data = f.read()\\n\\ndata = str(data)[2:-1]\\ndata = data.replace(\\'\\\\n}\\', \\'\\\\n}-----\\')\\ndata = data.split(\\'-----\\')\\n\\nblanckl = []\\nfor i in range(768):\\n    blanckl.append(\\'\\')\\n\\ninstancias = 0\\nfor p in data[0:-1]:\\n    entrada = []\\n    saida = []\\n    try:\\n        jfk = json.loads(codecs.decode(p, \\'unicode_escape\\'))\\n        arquivo = jfk[\\'graph\\'][\\'sentence\\'].lower().replace(\"/\",\"\").replace(\"\\\\\",\"\")\\n        lg = jfk[\\'graph\\'][\\'sentence\\'].lower().split()\\n        st = jfk[\\'headline\\'].lower().split()\\n\\n        for i in lg: #isso deveria ser uma funcao, addlist() #semTempo\\n            if i in dico: #dicionario reduzido\\n                entrada.append(dico[i])\\n            elif i in dici:\\n                dico[i] = dici[i]\\n                entrada.append(dico[i])\\n            else:\\n                for j, jj in fins.items():\\n                    if j in i[-len(j):]:\\n                        i = i[:-len(j)]\\n                        if i in dico: #assim ela poderia ser chamada aqui\\n                            entrada.append(dico[i])\\n                        elif i in dici:\\n                            dico[i] = dici[i]\\n                            entrada.append(dico[i])\\n                        if j in dico:\\n                            entrada.append(dico[j])\\n                        else:\\n                            dico[j] = fins[j]\\n                            entrada.append(dico[j])\\n                        break\\n        for i in st: #isso deveria ser uma funcao, addlist() #semTempo\\n            if i in dico: #dicionario reduzido\\n                saida.append(dico[i])\\n            elif i in dici:\\n                dico[i] = dici[i]\\n                saida.append(dico[i])\\n            else:\\n                for j, jj in fins.items():\\n                    if j in i[-len(j):]:\\n                        i = i[:-len(j)]\\n                        if i in dico: #assim ela poderia ser chamada aqui\\n                            saida.append(dico[i])\\n                        elif i in dici:\\n                            dico[i] = dici[i]\\n                            saida.append(dico[i])\\n                        if j in dico:\\n                            saida.append(dico[j])\\n                        else:\\n                            dico[j] = fins[j]\\n                            saida.append(dico[j])\\n                        break\\n    except ValueError:\\n        print(\"Houve um Erro\")\\n\\n        \\n    sv = os.getcwd() + \\'\\\\instancias\\\\arquivo_%i\\'%instancias + \\'.csv\\'\\n    instancias += 1\\n    try:\\n        with open(sv, \\'w\\', newline = \\'\\') as file:\\n            writer = csv.writer(file)\\n            tam = 0\\n            while tam < len(entrada):\\n                tm = []\\n                #print(type(tm))\\n                tm.extend(entrada[tam])\\n                if tam < len(saida):\\n                    tm.extend(saida[tam])\\n                else:\\n                    tm.extend(blanckl)\\n                tam += 1\\n                writer.writerow(tm)\\n    except ValueError:\\n        print(\"erro no json\")\\n\\nwith open(\"dicionario.csv\", \"w\", newline = \\'\\') as file:\\n    writer = csv.writer(file)\\n    for i, ii in dico.items():\\n\\ttm = []\\n\\ttm.append(i)\\n\\ttm.extend(ii)\\n        writer.writerow(tm)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKjJH3pbaixJ",
        "colab_type": "text"
      },
      "source": [
        "## Abrindo uma noticia (bert) e convertendo para texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6WEsqOPajg1",
        "colab_type": "code",
        "outputId": "2aa115cb-b443-4bdc-d94c-d6af37f6a12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# Abrindo o dicionario criado com o outro script\n",
        "dicurl = 'https://raw.githubusercontent.com/x-channel/Mining-Text-Simplifica-o-de-Texto/master/dataset/dicionario.csv'\n",
        "#dicloader = req.urlopen(dicurl)\n",
        "vetores = []\n",
        "palavras = []\n",
        "\n",
        "with req.urlopen(dicurl) as f:\n",
        "  meucsv = f.read().decode('charmap')\n",
        "  meucsv = meucsv.split('\\n')[:-1]\n",
        "  for i in meucsv:\n",
        "    j = i.replace('\\r','').split(',')\n",
        "    palavras.append(j[0])\n",
        "    vetores.append(j[1:])\n",
        "\n",
        "# colocando o dicionario no gensim.\n",
        "dicio = kv.Word2VecKeyedVectors(768)\n",
        "dicio.add(palavras, np.array(vetores).astype(float))\n",
        "\n",
        "#busca por um vetor parecido\n",
        "five = dicio.get_vector('five')\n",
        "friends = dicio.get_vector('friends')\n",
        "\n",
        "print(dicio.similar_by_vector(five, 1), dicio.similar_by_vector(friends, 1))\n",
        "\n",
        "#abrindo a noticia\n",
        "#nn = input(\"digite um numero entre 0 e 199: \")\n",
        "nn = 1\n",
        "noticia = 'https://raw.githubusercontent.com/x-channel/Mining-Text-Simplifica-o-de-Texto/master/dataset/noticias/arquivo_%i.csv'%nn\n",
        "\n",
        "pastaNoticias = 'https://raw.githubusercontent.com/x-channel/Mining-Text-Simplifica-o-de-Texto/master/dataset/noticias/%s_%i.csv'\n",
        "\n",
        "def abrirNoticia(urlnoticia):\n",
        "  sentence = []\n",
        "  head = []\n",
        "  with req.urlopen(urlnoticia) as f:\n",
        "    meucsv = f.read().decode('charmap')\n",
        "    meucsv = meucsv.split('\\n')[:-1]\n",
        "    for i in meucsv:\n",
        "      j = i.replace('\\r',',').replace(',,', ',0.0,').replace(',,', ',0.0,')[:-1]\n",
        "      j = j.split(',')\n",
        "      sentence.append(j[:768])\n",
        "      head.append(j[768:])\n",
        "  sentence = np.array(sentence).astype(float)\n",
        "  head = np.array(head).astype(float)\n",
        "  return sentence, head\n",
        "\n",
        "def abrirNoticias(urlfolder, total, nome = 'arquivo'):\n",
        "  primeiro = []\n",
        "  cabecalh = []\n",
        "  for i in range(total):\n",
        "    par = abrirNoticia(urlfolder%(nome,i))\n",
        "    primeiro.append(par[0])\n",
        "    cabecalh.append(par[1])\n",
        "  return np.array(primeiro),np.array(cabecalh)\n",
        "\n",
        "\n",
        "def vec2head(matriz, model, li):\n",
        "  head = []\n",
        "  for i in matriz:\n",
        "    j = model.similar_by_vector(i,1)\n",
        "    if j[0][1] > li:\n",
        "      head.append(j)\n",
        "  return head\n",
        "\n",
        "s, h = abrirNoticia(noticia)\n",
        "\n",
        "titulo = vec2head(h, dicio, 0.5)\n",
        "print (titulo)\n",
        "\n",
        "noticias,cabecalhos = abrirNoticias(pastaNoticias, 200)\n",
        "print(vec2head(noticias[1], dicio, 0.5))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('five', 1.0)] [('friends', 1.0)]\n",
            "[[('several', 1.0)], [('school', 1.0)], [('districts', 1.0)], [('hold', 1.0)], [('classes', 1.0)], [('on', 1.0)], [('president', 0.6351367831230164)], [(\"##'\", 0.9999998807907104)], [('day', 1.0000001192092896)], [('to', 1.0)], [('make', 1.0)], [('up', 1.0000001192092896)], [('for', 1.0)], [('days', 1.0)], [('missed', 1.0)]]\n",
            "[[('several', 1.0)], [('school', 1.0)], [('districts', 1.0)], [('in', 1.0)], [('hampton', 1.0)], [('roads', 1.0)], [('are', 0.9999999403953552)], [('holding', 1.0)], [('classes', 1.0)], [('this', 1.0000001192092896)], [('president', 0.6351367831230164)], [(\"##'\", 0.9999998807907104)], [('day', 1.0000001192092896)], [('to', 1.0)], [('make', 1.0)], [('up', 1.0000001192092896)], [('for', 1.0)], [('days', 1.0)], [('missed', 1.0)], [('because', 1.0)], [('of', 1.0)], [('the', 1.0)], [(\"##'\", 0.696808934211731)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNJpRDlg4kQW",
        "colab_type": "text"
      },
      "source": [
        "## Dividindo a base de dados\n",
        "\n",
        "Aqui a base de dados é dividida em: Treinamento, validação e teste.\n",
        "\n",
        "OBS: não encontrei isso implementado nem no scikit learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AorJ_zzpsZIO",
        "colab_type": "code",
        "outputId": "5b927230-d0dd-40c5-bc06-16e2d35a536b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#pading, para tudo ter o mesmo tamanho\n",
        "\n",
        "maxlen = 0\n",
        "\n",
        "for i in noticias:\n",
        "  if i.shape[0] > maxlen:\n",
        "    maxlen = i.shape[0]\n",
        "\n",
        "for i in range(len(noticias)):\n",
        "  pad = np.zeros((maxlen, 768))\n",
        "  pad[:noticias[i].shape[0],:] = noticias[i]\n",
        "  noticias[i] = pad\n",
        "  pad = np.zeros((maxlen, 768))\n",
        "  pad[:cabecalhos[i].shape[0],:] = cabecalhos[i]\n",
        "  cabecalhos[i] = pad\n",
        "\n",
        "print(maxlen)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9psE79f5CmX",
        "colab_type": "code",
        "outputId": "7e959f69-8b53-4423-d871-caed60ce030c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "treinamento = []\n",
        "#validacao = []\n",
        "teste = []\n",
        "\n",
        "xt = []\n",
        "yt = []\n",
        "\n",
        "xr = []\n",
        "yr = []\n",
        "\n",
        "atreino = 0.9\n",
        "#avalidacao = 0.3\n",
        "\n",
        "d = []\n",
        "for i in range(len(noticias)):\n",
        "  d.append(i)\n",
        "\n",
        "random.shuffle(d)\n",
        "\n",
        "# deixar essa linha para validar os parametros dos primeiros testes\n",
        "d = [117, 135, 181, 2, 129, 167, 65, 183, 107, 104, 158, 111, 69, 194, 8, 101, 21, 35, 31, 188, 106, 196, 148, 198, 67, 60, 102, 82, 16, 88, 119, 61, 11, 115, 113, 56, 169, 98, 64, 40, 49, 162, 36, 127, 157, 66, 164, 180, 41, 138, 62, 34, 72, 178, 27, 189, 121, 154, 96, 14, 133, 145, 97, 43, 199, 51, 25, 163, 155, 47, 70, 150, 12, 30, 123, 195, 32, 55, 18, 176, 171, 68, 175, 120, 110, 59, 141, 6, 23, 44, 103, 151, 125, 130, 79, 73, 173, 1, 58, 165, 118, 46, 39, 191, 10, 74, 166, 24, 147, 131, 190, 20, 156, 26, 22, 187, 182, 75, 63, 52, 9, 132, 87, 5, 144, 192, 42, 142, 90, 85, 143, 13, 153, 174, 122, 139, 184, 128, 19, 50, 161, 172, 168, 83, 48, 71, 185, 53, 126, 4, 29, 86, 15, 7, 92, 45, 197, 76, 134, 37, 54, 152, 57, 84, 112, 3, 28, 93, 0, 109, 136, 177, 77, 170, 100, 146, 137, 179, 80, 33, 17, 124, 89, 193, 38, 160, 78, 95, 140, 114, 159, 81, 186, 99, 108, 105, 116, 94, 149, 91]\n",
        "\n",
        "for i in range(len(noticias)):\n",
        "  if i < atreino*len(noticias):\n",
        "    xt.append(noticias[d[i]])\n",
        "    yt.append(cabecalhos[d[i]])\n",
        "  else:\n",
        "    xr.append(noticias[d[i]])\n",
        "    yr.append(cabecalhos[d[i]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "xt = np.array(xt)\n",
        "yt = np.array(yt)\n",
        "\n",
        "xr = np.array(xr)\n",
        "yr = np.array(yr)\n",
        "\n",
        "xt = xt.reshape(xt.shape[0], maxlen, 768, 1)\n",
        "yt = yt.reshape(yt.shape[0], maxlen, 768, 1)\n",
        "\n",
        "xr = xr.reshape(xr.shape[0], maxlen, 768, 1)\n",
        "yr = yr.reshape(yr.shape[0], maxlen, 768, 1)\n",
        "\n",
        "print(len(xt), len(yt))\n",
        "print(len(xr), len(xr[1]), len(xr[1][1]))\n",
        "\n",
        "'''\n",
        "for i in range(len(noticias)):\n",
        "  if i < atreino*len(noticias):\n",
        "    treinamento.append(noticias[d[i]])\n",
        "  elif i < (atreino+avaliacao)*len(noticias):\n",
        "    validacao.append(noticias[d[i]])\n",
        "  else:\n",
        "    teste.append(noticias[d[i]])'''\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180 180\n",
            "20 56 768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor i in range(len(noticias)):\\n  if i < atreino*len(noticias):\\n    treinamento.append(noticias[d[i]])\\n  elif i < (atreino+avaliacao)*len(noticias):\\n    validacao.append(noticias[d[i]])\\n  else:\\n    teste.append(noticias[d[i]])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7aMectc4YIn",
        "colab_type": "text"
      },
      "source": [
        "## Construindo a Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx1l-6QCQCSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando o keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Deconvolution2D, Reshape, Dropout\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thAFO7kN4eFU",
        "colab_type": "code",
        "outputId": "4ba11e2a-0b50-4663-f4ea-c91a1dfabbc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "source": [
        "model = Sequential()\n",
        "#model.add(Conv2D(2, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,768,1)))\n",
        "model.add(Conv2D(2, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,768,1),padding=\"same\"))\n",
        "model.add(Conv2D(4, (2,2), activation = \"tanh\",padding=\"same\"))\n",
        "print(model.input_shape)\n",
        "print(model.output_shape)\n",
        "#model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "#print(model.output_shape)\n",
        "\n",
        "model.add(Conv2D(8, (2,2), activation = \"tanh\",padding=\"same\"))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Conv2D(16, (2,2), activation = \"tanh\",padding=\"same\"))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Conv2D(32, (2,2), activation = \"tanh\",padding=\"same\"))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Conv2D(64, (2,2), activation = \"tanh\",padding=\"same\"))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Conv2D(128, (2,2), activation = \"tanh\",padding=\"same\"))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "print()\n",
        "model.add(Deconvolution2D(1, (2,2),padding=\"same\", dilation_rate =2))\n",
        "print(model.output_shape)\n",
        "print(model.summary())\n",
        "\n",
        "#model.add(Reshape((maxlen,768,1)))\n",
        "#print(model.output_shape)\n",
        "\n",
        "#model.add(Conv2DTranspose(1,(2,2),output_shape=(768,), activation=\"tanh\"))\n",
        "#print(model.output_shape)\n",
        "#rs = Reshape((maxlen,768,1))\n",
        "#print(rs.output_shape)\n",
        "#print(rs.input_shape)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse',metrics=[\"acc\"])\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 56, 768, 1)\n",
            "(None, 56, 768, 4)\n",
            "\n",
            "(None, 56, 768, 1)\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_75 (Conv2D)           (None, 56, 768, 2)        20        \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 56, 768, 4)        36        \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 56, 768, 8)        136       \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 56, 768, 8)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 56, 768, 16)       528       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 56, 768, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 56, 768, 32)       2080      \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 56, 768, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 56, 768, 64)       8256      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 56, 768, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 56, 768, 128)      32896     \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 56, 768, 128)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 56, 768, 1)        513       \n",
            "=================================================================\n",
            "Total params: 44,465\n",
            "Trainable params: 44,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnC1bMvV4eme",
        "colab_type": "text"
      },
      "source": [
        "## Treinando a rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyMsp1u95Jo2",
        "colab_type": "code",
        "outputId": "859d724d-d051-489f-e8dc-be7767dceead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(xt,yt,epochs=100)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "180/180 [==============================] - 4s 20ms/step - loss: 0.0402 - acc: 0.8319\n",
            "Epoch 2/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0167 - acc: 0.8528\n",
            "Epoch 3/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0082 - acc: 0.8572\n",
            "Epoch 4/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0046 - acc: 0.8577\n",
            "Epoch 5/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0030 - acc: 0.8577\n",
            "Epoch 6/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.8577\n",
            "Epoch 7/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.8577\n",
            "Epoch 8/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0014 - acc: 0.8577\n",
            "Epoch 9/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.8577\n",
            "Epoch 10/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.0011 - acc: 0.8577\n",
            "Epoch 11/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 9.7401e-04 - acc: 0.8577\n",
            "Epoch 12/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 8.9357e-04 - acc: 0.8577\n",
            "Epoch 13/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 8.2926e-04 - acc: 0.8577\n",
            "Epoch 14/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 7.7641e-04 - acc: 0.8577\n",
            "Epoch 15/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 7.3075e-04 - acc: 0.8577\n",
            "Epoch 16/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 6.9279e-04 - acc: 0.8577\n",
            "Epoch 17/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 6.5682e-04 - acc: 0.8577\n",
            "Epoch 18/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 6.2494e-04 - acc: 0.8577\n",
            "Epoch 19/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 5.9832e-04 - acc: 0.8577\n",
            "Epoch 20/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 5.7206e-04 - acc: 0.8577\n",
            "Epoch 21/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 5.4999e-04 - acc: 0.8577\n",
            "Epoch 22/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 5.3037e-04 - acc: 0.8577\n",
            "Epoch 23/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 5.1182e-04 - acc: 0.8577\n",
            "Epoch 24/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.9378e-04 - acc: 0.8577\n",
            "Epoch 25/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.7974e-04 - acc: 0.8577\n",
            "Epoch 26/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.6527e-04 - acc: 0.8577\n",
            "Epoch 27/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.5148e-04 - acc: 0.8577\n",
            "Epoch 28/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.4057e-04 - acc: 0.8577\n",
            "Epoch 29/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.2944e-04 - acc: 0.8577\n",
            "Epoch 30/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.1939e-04 - acc: 0.8577\n",
            "Epoch 31/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.1005e-04 - acc: 0.8577\n",
            "Epoch 32/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 4.0114e-04 - acc: 0.8577\n",
            "Epoch 33/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.9321e-04 - acc: 0.8577\n",
            "Epoch 34/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.8570e-04 - acc: 0.8577\n",
            "Epoch 35/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.7845e-04 - acc: 0.8577\n",
            "Epoch 36/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.7184e-04 - acc: 0.8577\n",
            "Epoch 37/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.6577e-04 - acc: 0.8577\n",
            "Epoch 38/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.5955e-04 - acc: 0.8577\n",
            "Epoch 39/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.5448e-04 - acc: 0.8577\n",
            "Epoch 40/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.4941e-04 - acc: 0.8577\n",
            "Epoch 41/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.4442e-04 - acc: 0.8577\n",
            "Epoch 42/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.3976e-04 - acc: 0.8577\n",
            "Epoch 43/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.3559e-04 - acc: 0.8577\n",
            "Epoch 44/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.3175e-04 - acc: 0.8577\n",
            "Epoch 45/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.2756e-04 - acc: 0.8577\n",
            "Epoch 46/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.2411e-04 - acc: 0.8577\n",
            "Epoch 47/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.2077e-04 - acc: 0.8577\n",
            "Epoch 48/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.1758e-04 - acc: 0.8577\n",
            "Epoch 49/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.1434e-04 - acc: 0.8577\n",
            "Epoch 50/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.1098e-04 - acc: 0.8577\n",
            "Epoch 51/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.0829e-04 - acc: 0.8577\n",
            "Epoch 52/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.0607e-04 - acc: 0.8577\n",
            "Epoch 53/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.0323e-04 - acc: 0.8577\n",
            "Epoch 54/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 3.0101e-04 - acc: 0.8577\n",
            "Epoch 55/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.9877e-04 - acc: 0.8577\n",
            "Epoch 56/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.9612e-04 - acc: 0.8577\n",
            "Epoch 57/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.9419e-04 - acc: 0.8577\n",
            "Epoch 58/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.9244e-04 - acc: 0.8577\n",
            "Epoch 59/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.9027e-04 - acc: 0.8577\n",
            "Epoch 60/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.8849e-04 - acc: 0.8577\n",
            "Epoch 61/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.8699e-04 - acc: 0.8577\n",
            "Epoch 62/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.8528e-04 - acc: 0.8577\n",
            "Epoch 63/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.8341e-04 - acc: 0.8577\n",
            "Epoch 64/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.8184e-04 - acc: 0.8577\n",
            "Epoch 65/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.8020e-04 - acc: 0.8577\n",
            "Epoch 66/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.7887e-04 - acc: 0.8577\n",
            "Epoch 67/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.7753e-04 - acc: 0.8577\n",
            "Epoch 68/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.7601e-04 - acc: 0.8577\n",
            "Epoch 69/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.7491e-04 - acc: 0.8577\n",
            "Epoch 70/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.7376e-04 - acc: 0.8577\n",
            "Epoch 71/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.7275e-04 - acc: 0.8577\n",
            "Epoch 72/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.7141e-04 - acc: 0.8577\n",
            "Epoch 73/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.7042e-04 - acc: 0.8577\n",
            "Epoch 74/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6928e-04 - acc: 0.8577\n",
            "Epoch 75/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6825e-04 - acc: 0.8577\n",
            "Epoch 76/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6735e-04 - acc: 0.8577\n",
            "Epoch 77/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6626e-04 - acc: 0.8577\n",
            "Epoch 78/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6540e-04 - acc: 0.8577\n",
            "Epoch 79/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6450e-04 - acc: 0.8577\n",
            "Epoch 80/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6373e-04 - acc: 0.8577\n",
            "Epoch 81/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6274e-04 - acc: 0.8577\n",
            "Epoch 82/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6202e-04 - acc: 0.8577\n",
            "Epoch 83/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6123e-04 - acc: 0.8577\n",
            "Epoch 84/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.6040e-04 - acc: 0.8577\n",
            "Epoch 85/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5988e-04 - acc: 0.8577\n",
            "Epoch 86/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5905e-04 - acc: 0.8577\n",
            "Epoch 87/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5816e-04 - acc: 0.8577\n",
            "Epoch 88/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5766e-04 - acc: 0.8577\n",
            "Epoch 89/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5691e-04 - acc: 0.8577\n",
            "Epoch 90/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5644e-04 - acc: 0.8577\n",
            "Epoch 91/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5587e-04 - acc: 0.8577\n",
            "Epoch 92/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5523e-04 - acc: 0.8577\n",
            "Epoch 93/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5449e-04 - acc: 0.8577\n",
            "Epoch 94/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5416e-04 - acc: 0.8577\n",
            "Epoch 95/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5335e-04 - acc: 0.8577\n",
            "Epoch 96/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5297e-04 - acc: 0.8577\n",
            "Epoch 97/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5233e-04 - acc: 0.8577\n",
            "Epoch 98/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5192e-04 - acc: 0.8577\n",
            "Epoch 99/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5146e-04 - acc: 0.8577\n",
            "Epoch 100/100\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 2.5094e-04 - acc: 0.8577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3cf3d71390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYJKsJ5ckLT",
        "colab_type": "text"
      },
      "source": [
        "##Teste da rede\n",
        "\n",
        "Aqui a rede é testada, sem produzir de fato saidas legíveis, mas apenas mostrando uma acurácia da rede em relação ao vetor bert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QS0KNZscwX3",
        "colab_type": "code",
        "outputId": "6da19698-bc7d-46a6-80f5-6091c553ec56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(xt.shape)\n",
        "\n",
        "aaaaa = xr[0].reshape(1, 56, 768, 1)\n",
        "bbbbb = yr[0].reshape(56,768)\n",
        "\n",
        "ttttt = model.predict(aaaaa)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(180, 56, 768, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fii8I_hiMzqS",
        "colab_type": "code",
        "outputId": "e9d79b30-68b3-42fd-f7f9-f526e41da36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "ttttt = ttttt.reshape(56,768)\n",
        "print(ttttt.shape)\n",
        "\n",
        "asdf = vec2head(ttttt,dicio,0.5)\n",
        "print(asdf)\n",
        "\n",
        "fdsa = vec2head(bbbbb,dicio,0.5)\n",
        "print(fdsa)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56, 768)\n",
            "[[('201', 0.6859637498855591)], [('201', 0.6856739521026611)], [('201', 0.688129186630249)], [('201', 0.6882786750793457)], [('201', 0.687862753868103)], [('201', 0.6877453923225403)], [('201', 0.6847168207168579)], [('201', 0.6844584941864014)], [('201', 0.684297502040863)], [('201', 0.6865218281745911)], [('201', 0.6867110729217529)], [('201', 0.6875910758972168)], [('201', 0.6872336864471436)], [('201', 0.6859800219535828)], [('201', 0.6853822469711304)], [('201', 0.6861602663993835)], [('201', 0.6865890026092529)], [('201', 0.6845738887786865)], [('201', 0.6838492155075073)], [('201', 0.6844849586486816)], [('201', 0.6845182180404663)], [('201', 0.6833680868148804)], [('201', 0.6863068342208862)], [('201', 0.6868082284927368)], [('201', 0.6873829364776611)], [('201', 0.6882473230361938)], [('201', 0.6862123012542725)], [('201', 0.6848485469818115)], [('201', 0.683991014957428)], [('201', 0.6828604936599731)], [('201', 0.6811395287513733)], [('201', 0.683478593826294)], [('201', 0.6827186346054077)], [('201', 0.6832477450370789)], [('201', 0.6841217279434204)], [('201', 0.6841475963592529)], [('201', 0.683882474899292)], [('201', 0.6845684051513672)], [('201', 0.6851977109909058)], [('201', 0.6859245300292969)], [('201', 0.6848992705345154)], [('201', 0.6860541105270386)], [('201', 0.6851447820663452)], [('201', 0.6857098937034607)], [('201', 0.6852468252182007)], [('201', 0.6837091445922852)], [('201', 0.6825360655784607)], [('201', 0.6840977668762207)], [('201', 0.6851229071617126)], [('201', 0.6858126521110535)], [('201', 0.6858925819396973)], [('201', 0.6862917542457581)], [('201', 0.6866559982299805)], [('201', 0.6869364380836487)], [('201', 0.6849305629730225)], [('201', 0.6844301223754883)]]\n",
            "[[('##t', 1.0)], [('completed', 0.5599807500839233)], [('##s', 0.9999998807907104)], [('acquisition', 1.0)], [('of', 1.0)], [('bel', 1.0)], [('##o', 1.0)]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZGIJBRi5J7m",
        "colab_type": "text"
      },
      "source": [
        "## Teste de predição\n",
        "\n",
        "Aqui a rede é rodada como teste. A metrica mais usada para esse teste é o ROUGE-1, que conta quantas palavras da saída do sistema está dentro do texto de referência, depois divide pelo número de palavras no texto de referência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFw4uRsm5Kuu",
        "colab_type": "code",
        "outputId": "2d1323dd-0e91-4cf4-cbb3-f41400404d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "\n",
        "#rouge-1\n",
        "def rouge(src, ref):\n",
        "  acertos = 0\n",
        "  for i in src:\n",
        "    if i in ref:\n",
        "      acertos += 1\n",
        "  return acertos/float(len(ref))\n",
        "\n",
        "sistem = ['five', 'plane']\n",
        "refere = ['five', 'in', 'plane']\n",
        "\n",
        "si = []\n",
        "re = []\n",
        "\n",
        "for i in asdf:\n",
        "  si.append(i[0])\n",
        "\n",
        "for i in fdsa:\n",
        "  re.append(i[0])\n",
        "\n",
        "print(rouge(sistem, refere))\n",
        "print(rouge(si,re))\n",
        "\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666666\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE9N8xIG5tBd",
        "colab_type": "text"
      },
      "source": [
        "# SHAME!\n",
        "\n",
        "Certo, o resultado de 85% de precisão da rede neural não produziu nenhuma sentença compatível com a sua referência. Vamos tentar outra coisa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0so6Iax2wMQ",
        "colab_type": "text"
      },
      "source": [
        "## Classificação\n",
        "\n",
        "Há uma base de dados que compreende recomendações dos jogos da steam. https://github.com/mulhod/steam_reviews\n",
        "\n",
        "\n",
        "Porém aqui será usado somente o word2vec, visto que a base de dados é outra e não é possível somente importar o dicionário do bert.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJri0htt2vT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To reimportando para nao precisar rodar tudo.\n",
        "import gensim\n",
        "import numpy as np\n",
        "import json\n",
        "import keras\n",
        "\n",
        "from urllib import request as req\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7htR7oL9tX3",
        "colab_type": "text"
      },
      "source": [
        "## importando a base de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbidOvKs9si3",
        "colab_type": "code",
        "outputId": "68249889-26ab-40fe-be32-ed3ac10e7cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "source": [
        "#urlpastareviews = \"https://github.com/mulhod/steam_reviews/tree/master/data\"\n",
        "vetorarqui = [\"Arma_3.jsonlines\",\"Counter_Strike.jsonlines\",\"Counter_Strike_Global_Offensive.jsonlines\",\"Dota_2.jsonlines\",\"Football_Manager_2015.jsonlines\",\"Garrys_Mod.jsonlines\",\"Grand_Theft_Auto_V.jsonlines\",\"Sid_Meiers_Civilization_5.jsonlines\",\"Team_Fortress_2.jsonlines\",\"The_Elder_Scrolls_V.jsonlines\",\"Warframe.jsonlines\"]\n",
        "cadaReview = \"https://raw.githubusercontent.com/mulhod/steam_reviews/master/data/%s\"\n",
        "\n",
        "#user/game, rating\n",
        "gamerat = [[],[]]\n",
        "reviews = []\n",
        "\n",
        "erros = 0\n",
        "\n",
        "#aqui o vetor reviews sera acrescido de instancias.\n",
        "for i in vetorarqui:\n",
        "  with req.urlopen(cadaReview%i) as f:\n",
        "    data = f.read().decode('charmap')\n",
        "  data = data.replace('}\\n', '}-----')\n",
        "  data = data.split('-----')\n",
        "  print(\"reviews coletadas para esse jogo\",len(data))\n",
        "  for j in data:\n",
        "    try:\n",
        "      jfk = json.loads(j)\n",
        "      # infelizmente a base de dados contem instancias duplicadas\n",
        "      # Eventualmente um jogador comentou em dois jogos\n",
        "      # Eventualmente os jogadores mudam de nome, entao eh mais seguro filtrar pelo \"orig_url\"\n",
        "      #hum += 1\n",
        "      user = \"%s in %s\"%(jfk[\"orig_url\"], i[:-10])\n",
        "      revi = jfk[\"review\"]\n",
        "      revi = gensim.utils.simple_preprocess(revi)\n",
        "      rati = jfk[\"rating\"]\n",
        "      if (not (user in gamerat[0])):\n",
        "        if len(revi) > 5 and len(revi) < 129:\n",
        "          gamerat[0].append(user)\n",
        "          reviews.append(revi)\n",
        "          gamerat[1].append(rati)\n",
        "        elif len(revi) > 128:\n",
        "          gamerat[0].append(user)\n",
        "          reviews.append(revi[:128])\n",
        "          gamerat[1].append(rati)\n",
        "    except:\n",
        "      erros += 1\n",
        "  print(reviews[-1])\n",
        "  print (\"Ha %i instancias\\nUm total de %i instancias ignoradas\"%(len(reviews),erros))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reviews coletadas para esse jogo 7274\n",
            "['simply', 'amazing', 'fun', 'to', 'play', 'insurgency', 'and', 'king', 'of', 'the', 'hill']\n",
            "Ha 881 instancias\n",
            "Um total de 135 instancias ignoradas\n",
            "reviews coletadas para esse jogo 6234\n",
            "['just', 'an', 'absolute', 'brilliant', 'game', 'you', 'can', 'play', 'on', 'any', 'server', 'you', 'want', 'and', 'you', 'will', 'have', 'lot', 'of', 'fun']\n",
            "Ha 2083 instancias\n",
            "Um total de 336 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7412\n",
            "['you', 'shoot', 'chickens', 'in', 'this', 'game']\n",
            "Ha 3001 instancias\n",
            "Um total de 691 instancias ignoradas\n",
            "reviews coletadas para esse jogo 9792\n",
            "['yeah', 'best', 'game', 'cant', 'imagine', 'if', 'this', 'game', 'if', 'rlly', 'closed']\n",
            "Ha 4550 instancias\n",
            "Um total de 774 instancias ignoradas\n",
            "reviews coletadas para esse jogo 1532\n",
            "['well', 'there', 'was', 'looking', 'to', 'enjoy', 'the', 'nexr', 'edition', 'off', 'fm', 'oh', 'dear', 'who', 'on', 'earth', 'made', 'this', 'one', 'must', 'be', 'someone', 'that', 'has', 'never', 'seen', 'game', 'of', 'football', 'in', 'their', 'life', 'goalkeepers', 'from', 'other', 'teams', 'play', 'like', 'gordan', 'banks', 'my', 'goalkeeper', 'is', 'making', 'all', 'kinds', 'of', 'blunders', 'agree', 'some', 'games', 'even', 'if', 'you', 'have', 'percent', 'possession', 'you', 'can', 'still', 'lose', 'to', 'counter', 'attack', 'however', 'not', 'every', 'game', 'there', 'is', 'too', 'many', 'times', 'that', 'you', 'have', 'shots', 'with', 'no', 'goal', 'and', 'the', 'other', 'team', 'have', 'shot', 'goal', 'highlights', 'still', 'look', 'like', 'we', 'have', 'graphics', 'engine', 'from', 'the', 'days', 'of', 'manic', 'miner', 'went', 'to', 'buy', 'player', 'at', 'man', 'united', 'and', 'asked', 'the', 'board', 'they', 'said', 'that', 'they', 'agree', 'however', 'cant', 'afford', 'lol', 'really', 'also', 'some', 'teams', 'are', 'way', 'overated']\n",
            "Ha 4730 instancias\n",
            "Um total de 785 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7281\n",
            "['you', 'can', 'kill', 'someone', 'with', 'water', 'melon', 'and', 'then', 'drop', 'nuke', 'do', 'yourself', 'favor', 'and', 'get', 'this', 'game']\n",
            "Ha 5592 instancias\n",
            "Um total de 923 instancias ignoradas\n",
            "reviews coletadas para esse jogo 13853\n",
            "['best', 'version', 'of', 'gta', 'out', 'there', 'played', 'xbox', 'version', 'but', 'the', 'pc', 'version', 'up', 'the', 'xbox', 'in', 'so', 'many', 'ways', 'worth', 'it']\n",
            "Ha 7224 instancias\n",
            "Um total de 1463 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7590\n",
            "['this', 'is', 'drugs', 'in', 'game', 'form']\n",
            "Ha 8130 instancias\n",
            "Um total de 1592 instancias ignoradas\n",
            "reviews coletadas para esse jogo 5760\n",
            "['the', 'game', 'is', 'amazing', 'other', 'poeple', 'in', 'the', 'game', 'are', 'usually', 'nice', 'and', 'fun', 'to', 'play', 'with', 'the', 'ommunity', 'for', 'this', 'game', 'is', 'huge', 'and', 'you', 'will', 'never', 'find', 'the', 'game', 'empty']\n",
            "Ha 8824 instancias\n",
            "Um total de 1684 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7441\n",
            "['enjoy', 'hundreds', 'upon', 'hundreds', 'of', 'copy', 'pasted', 'dungeons', 'boring', 'enemies', 'uninteresting', 'skills', 'basic', 'spells', 'fetch', 'quests', 'glitches', 'and', 'bugs', 'take', 'in', 'the', 'breath', 'takingly', 'small', 'skyrim', 'if', 'this', 'is', 'country', 'then', 'how', 'big', 'is', 'the', 'planet', 'as', 'you', 'click', 'on', 'draugrs', 'click', 'on', 'bandits', 'click', 'on', 'falmers', 'click', 'on', 'spiders', 'click', 'on', 'wizards', 'and', 'click', 'on', 'dragons', 'watch', 'as', 'your', 'hero', 'cinematically', 'kills', 'the', 'easiest', 'enemies', 'in', 'any', 'game', 'ever', 'and', 'when', 'you', 'turn', 'up', 'the', 'difficulty', 'the', 'game', 'lazily', 'only', 'increases', 'the', 'enemy', 'health', 'and', 'damage', 'feel', 'like', 'you', 'haven', 'gotten', 'any', 'stronger', 'due', 'to', 'the', 'amazing', 'scaling', 'enemies', 'but', 'people', 'keep', 'telling', 'me', 'that', 'this', 'is', 'the', 'best', 'game', 'ever', 'so', 'guess', 'they', 're', 'right', 'give', 'this', 'game']\n",
            "Ha 9660 instancias\n",
            "Um total de 1977 instancias ignoradas\n",
            "reviews coletadas para esse jogo 7642\n",
            "['even', 'with', 'all', 'unusual', 'style', 'and', 'gameplay', 'this', 'game', 'is', 'terrible', 'because', 'it', 'requires', 'tons', 'of', 'your', 'time', 'to', 'grind', 'so', 'you', 'can', 'get', 'decent', 'items', 'mods', 'and', 'become', 'player', 'who', 'worth', 'something', 'my', 'favorite', 'weapons', 'was', 'nerfed', 'new', 'classes', 'overpowered', 'and', 'old', 'ones', 'was', 'nerfed', 'hard', 'this', 'game', 'was', 'made', 'to', 'suck', 'money', 'because', 'without', 'donation', 'you', 'will', 'waste', 'many', 'hours', 'of', 'trying', 'to', 'complete', 'missions', 'you', 'want', 'or', 'get', 'items', 'you', 'need', 'with', 'money', 'in', 'your', 'pocket', 'you', 'can', 'easily', 'get', 'everything', 'and', 'turn', 'on', 'easy', 'mode', 've', 'played', 'long', 'time', 'ago', 'and', 'it', 'was', 'decent', 'there', 'was', 'of', 'course', 'one', 'of', 'the', 'starting', 'classes', 'that', 'could', 'win', 'everything', 'in', 'solo', 'but', 'the', 'rest', 'of', 'them', 'was', 'useful', 'now', 'everything', 'changed', 'in', 'bad', 'way', 'am', 'very']\n",
            "Ha 10548 instancias\n",
            "Um total de 2523 instancias ignoradas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OxcNRE7OZSN",
        "colab_type": "text"
      },
      "source": [
        "## Criando o Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKe9poUcOe_D",
        "colab_type": "code",
        "outputId": "b266937e-10e0-462b-c025-c121c2aa1d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dicionario = gensim.models.Word2Vec(\n",
        "        reviews,\n",
        "        size=128,\n",
        "        window=10,\n",
        "        min_count=2,\n",
        "        workers=100)\n",
        "dicionario.train(reviews, total_examples=len(reviews), epochs=20)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5924266, 8172540)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M8ThV2eRprN",
        "colab_type": "code",
        "outputId": "7890d1b4-be9b-4a88-e3ad-5ed6fa0cf9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "print(len(dicionario[\"good\"]))\n",
        "\n",
        "print(len(dicionario.wv.vocab))\n",
        "\n",
        "print(dicionario[\"good\"])\n"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "8669\n",
            "[-1.2259949e+00  1.9993063e+00  5.8566559e-02  2.2102705e-01\n",
            "  1.4508879e+00  1.5133581e+00 -1.2312982e+00  1.1861554e+00\n",
            " -3.6624763e+00 -1.2328969e+00  1.7400835e+00 -2.0218928e-01\n",
            "  7.5327468e-01  4.5907187e-01  2.4640264e-01  2.4597011e+00\n",
            "  6.4571917e-01  8.0510199e-01 -9.0763412e-02  1.1370085e+00\n",
            "  7.6558316e-01  1.8016051e+00  1.0349616e+00 -1.1807398e+00\n",
            " -1.0684725e+00 -1.2889031e+00 -7.5821739e-01  9.0404582e-01\n",
            "  2.9936960e-01 -1.5309575e+00 -1.6541843e+00  4.3744531e-02\n",
            "  1.0518887e+00 -2.5894451e-01 -9.8706551e-02  2.1057298e+00\n",
            " -1.5026595e-01  1.4706271e+00  4.7380897e-01 -1.9008769e+00\n",
            " -1.1936704e+00  1.8315812e+00 -2.7377719e-01  1.1052895e+00\n",
            " -7.2269541e-01 -1.0157968e+00  8.1258541e-01 -6.4162338e-01\n",
            "  1.3447130e-01  1.7760757e+00  2.5003834e+00 -2.0340405e+00\n",
            "  1.7368201e+00  1.1100343e+00 -9.6069515e-01 -2.8983623e-01\n",
            " -2.7555761e-01  2.5051558e-01 -4.9124801e-01 -3.9798239e-01\n",
            "  4.4681627e-01 -1.3490374e+00  1.0653763e+00  5.4898262e-01\n",
            " -3.2799783e-01  2.5983094e-03 -4.2917010e-01  2.6899698e+00\n",
            " -3.4814587e-01  5.4989868e-01 -3.0576930e+00 -1.0959612e+00\n",
            "  3.7725016e-01  1.3217528e+00 -1.6522703e+00  1.2617863e+00\n",
            "  7.6337773e-01  1.1852049e+00  1.2618747e-02  2.3351405e+00\n",
            "  1.1492647e+00 -1.7791827e-01  5.6593490e-01  1.2425833e+00\n",
            " -2.0595605e+00  2.8216368e-01  5.7146478e-01 -2.7899234e+00\n",
            "  2.5072610e-01 -6.6157264e-01  1.7181163e+00 -6.2336779e-01\n",
            "  3.5788745e-01 -1.2756425e+00  7.8935784e-01 -1.3215454e+00\n",
            "  8.3083433e-01  7.6794583e-01 -2.3708563e+00  2.0084031e+00\n",
            "  2.7103102e-01  1.7668414e+00  1.5663494e+00  5.3210676e-01\n",
            "  2.5460145e-01 -1.3059503e+00 -7.6633567e-01  5.4601008e-01\n",
            "  1.5053898e+00 -6.0861802e-01 -9.0956408e-01  1.4038149e+00\n",
            "  7.0923887e-02 -1.0452888e+00  1.0560170e+00 -2.0039058e+00\n",
            "  1.4327557e+00  3.2877743e+00 -1.4419504e+00 -1.9229198e+00\n",
            " -9.2680317e-01 -9.2025280e-02 -1.4316632e+00  1.4473176e+00\n",
            " -1.0079279e+00  1.0452791e+00  5.1809150e-01  1.5733582e+00]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fedqmi7F34Pb",
        "colab_type": "text"
      },
      "source": [
        "## Filtrando as instancias\n",
        "\n",
        "Devido algumas pequenas dificuldades, o projeto sera simplificado com uma filtragem das instancias. Com uma base de dados equilibrada, 50% de instancias recomendadas e 50% de instancias não recomendadas, a estratégia de dizer que todas as entradas são recomendadas não funcionará."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yfY_5pL4YiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "9332f7ae-287b-408d-ca71-93ddf5c7f5c9"
      },
      "source": [
        "print(len(reviews))\n",
        "print(len(gamerat))\n",
        "print(len(gamerat[0]))\n",
        "\n",
        "reviewsold = reviews\n",
        "gameratold = gamerat\n",
        "\n",
        "reviews = []\n",
        "gamerat = [[],[]]\n",
        "\n",
        "print(len(gameratold))\n",
        "print(len(gameratold[1]))\n",
        "len(reviewsold)\n",
        "\n",
        "rm = 0\n",
        "nr = 0\n",
        "\n",
        "for i in gameratold[1]:\n",
        "  if i == 'Recommended':\n",
        "    rm += 1\n",
        "  else:\n",
        "    nr += 1\n",
        "\n",
        "print(rm, nr)\n",
        "\n",
        "rm = min(rm, nr)\n",
        "nr = rm\n",
        "\n",
        "for i in range(len(reviewsold)):\n",
        "  if rm > 0 and gameratold[1][i] == 'Recommended':\n",
        "    reviews.append(reviewsold[i])\n",
        "    gamerat[0].append(gameratold[0][i])\n",
        "    gamerat[1].append(gameratold[1][i])\n",
        "    rm -= 1\n",
        "  if rn > 0 and gameratold[1][i] == 'Not Recommended':\n",
        "    reviews.append(reviewsold[i])\n",
        "    gamerat[0].append(gameratold[0][i])\n",
        "    gamerat[1].append(gameratold[1][i])\n",
        "    nr -= 1\n",
        "\n",
        "print(len(reviews), len(gamerat[1]))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10548\n",
            "2\n",
            "10548\n",
            "2\n",
            "10548\n",
            "9072 1476\n",
            "2952 2952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOnVn0-YSf_I",
        "colab_type": "text"
      },
      "source": [
        "## Transformando cada review em uma matriz\n",
        "\n",
        "Como usado anteriormente, mas sem o bert, cada review sera transformada em uma matriz, onde cada linha é uma palavra com 128 valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-8359RVTcGo",
        "colab_type": "code",
        "outputId": "0b2ddec6-a0f8-48bd-f2cf-d6e8f71c1d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "reviewsmat = []\n",
        "\n",
        "for i in reviews:\n",
        "  mm = []\n",
        "  for j in i:\n",
        "    try:\n",
        "      mm.append(dicionario[j])\n",
        "    except:\n",
        "      #print(\"Faltou\")\n",
        "      pass\n",
        "  mm = np.array(mm)\n",
        "  reviewsmat.append(mm)\n",
        "\n",
        "\n",
        "\n",
        "print(len(reviews))\n",
        "print(len(reviewsmat))\n",
        "print(len(reviewsmat[0]))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2952\n",
            "2952\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyYI2A6OWPh_",
        "colab_type": "code",
        "outputId": "959ed7dc-49fd-403b-d89d-295b5933ac64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#pading, para tudo ter o mesmo tamanho\n",
        "\n",
        "maxlen = 0\n",
        "\n",
        "revFiltradas = []\n",
        "\n",
        "for i in reviewsmat:\n",
        "  if i.shape[0] > maxlen:\n",
        "    maxlen = i.shape[0]\n",
        "\n",
        "erros = 0\n",
        "\n",
        "for i in range(len(reviewsmat)):\n",
        "  try:\n",
        "    pad = np.zeros((maxlen, 128))\n",
        "    pad[:reviewsmat[i].shape[0],:] = reviewsmat[i]\n",
        "    revFiltradas.append(pad)\n",
        "  except:\n",
        "    erros += 1\n",
        "\n",
        "print(maxlen, erros)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEdgHZdVbQLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "014b4f55-2435-45a4-b31b-dc3f0232244d"
      },
      "source": [
        "#Reshaping\n",
        "\n",
        "inst = len(revFiltradas)\n",
        "\n",
        "x = np.array(revFiltradas)\n",
        "\n",
        "x = x.reshape(inst, maxlen, 128, 1)\n",
        "\n",
        "len(x)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2952"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYOqRZRfePV",
        "colab_type": "text"
      },
      "source": [
        "## One hot encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gglvz7jidYKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "c9ddb3e7-7ef1-4c9f-b9b1-1fca474f209e"
      },
      "source": [
        "#Outputs\n",
        "\n",
        "ardata = np.array(gamerat[1])\n",
        "print(ardata)\n",
        "\n",
        "\n",
        "# https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(ardata)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([np.argmax(onehot_encoded[0, :])])\n",
        "print(inverted)\n",
        "\n",
        "\n",
        "y = keras.utils.to_categorical(onehot_encoded, 2)\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Recommended' 'Recommended' 'Recommended' ... 'Not Recommended'\n",
            " 'Not Recommended' 'Not Recommended']\n",
            "[1 1 1 ... 0 0 0]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "['Recommended']\n",
            "[[[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [0. 1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 1.]\n",
            "  [1. 0.]]\n",
            "\n",
            " [[0. 1.]\n",
            "  [1. 0.]]\n",
            "\n",
            " [[0. 1.]\n",
            "  [1. 0.]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS1vyNuIjbAz",
        "colab_type": "text"
      },
      "source": [
        "## Divisão treino/teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojDqhJMAjlnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a171ed0-2236-4357-db10-e7d167792b60"
      },
      "source": [
        "## divisao\n",
        "\n",
        "print (inst)\n",
        "\n",
        "x_tr = x[:2361] #80% da base de dados\n",
        "x_te = x[2361:] #20% da base de dados\n",
        "\n",
        "y_tr = onehot_encoded[:2361]\n",
        "y_te = onehot_encoded[2361:]"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLepzjVqg7Ay",
        "colab_type": "text"
      },
      "source": [
        "## Classificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1dS_1ethDcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Flatten, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ4X5EfGzZdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Recall \n",
        "#### https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n34T8Kfhpgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "1225b039-6b72-4c57-f483-25b9f17db635"
      },
      "source": [
        "cls = Sequential()\n",
        "cls.add(Conv2D(4, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Conv2D(8, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(Dropout(0.8))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Conv2D(16, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Conv2D(32, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Conv2D(64, kernel_size=(3,3), activation = \"tanh\", input_shape=(maxlen,128,1),padding=\"same\"))\n",
        "cls.add(Dropout(0.8))\n",
        "cls.add(MaxPooling2D(padding='same'))\n",
        "cls.add(Flatten())\n",
        "cls.add(Dense(8, activation = \"tanh\"))\n",
        "cls.add(Dropout(0.8))\n",
        "cls.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "print(cls.summary())\n",
        "print(cls.input_shape)\n",
        "print(cls.output_shape)\n",
        "\n",
        "\n",
        "cls.compile(\"adam\", \"mse\", [\"acc\", recall_m])"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_82 (Conv2D)           (None, 128, 128, 4)       40        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 64, 64, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 64, 64, 8)         296       \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 64, 64, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 32, 32, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 16, 16, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 8, 8, 64)          18496     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 8)                 8200      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 2)                 18        \n",
            "=================================================================\n",
            "Total params: 32,858\n",
            "Trainable params: 32,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "(None, 128, 128, 1)\n",
            "(None, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4GN29pUz9tO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc7a1f64-0845-4ea4-8ecb-a919044a257b"
      },
      "source": [
        "cls.fit(x_tr, y_tr, batch_size=160, epochs = 300, validation_split=0.1)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2124 samples, validate on 237 samples\n",
            "Epoch 1/300\n",
            "2124/2124 [==============================] - 2s 986us/step - loss: 0.2680 - acc: 0.6577 - recall_m: 0.6558 - val_loss: 0.3301 - val_acc: 0.3840 - val_recall_m: 0.3840\n",
            "Epoch 2/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.2748 - acc: 0.6648 - recall_m: 0.6648 - val_loss: 0.3401 - val_acc: 0.3671 - val_recall_m: 0.3671\n",
            "Epoch 3/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.2674 - acc: 0.6676 - recall_m: 0.6676 - val_loss: 0.4202 - val_acc: 0.3038 - val_recall_m: 0.3038\n",
            "Epoch 4/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2573 - acc: 0.6827 - recall_m: 0.6827 - val_loss: 0.4118 - val_acc: 0.2954 - val_recall_m: 0.2954\n",
            "Epoch 5/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2466 - acc: 0.6822 - recall_m: 0.6822 - val_loss: 0.3539 - val_acc: 0.2996 - val_recall_m: 0.2996\n",
            "Epoch 6/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2436 - acc: 0.6784 - recall_m: 0.6784 - val_loss: 0.2808 - val_acc: 0.3249 - val_recall_m: 0.3249\n",
            "Epoch 7/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2406 - acc: 0.6747 - recall_m: 0.6747 - val_loss: 0.2903 - val_acc: 0.3713 - val_recall_m: 0.3713\n",
            "Epoch 8/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2397 - acc: 0.6855 - recall_m: 0.6855 - val_loss: 0.2992 - val_acc: 0.3460 - val_recall_m: 0.3460\n",
            "Epoch 9/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2258 - acc: 0.6860 - recall_m: 0.6860 - val_loss: 0.2472 - val_acc: 0.5274 - val_recall_m: 0.5274\n",
            "Epoch 10/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2203 - acc: 0.6869 - recall_m: 0.6869 - val_loss: 0.2140 - val_acc: 0.7046 - val_recall_m: 0.7046\n",
            "Epoch 11/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2180 - acc: 0.6897 - recall_m: 0.6897 - val_loss: 0.2815 - val_acc: 0.3840 - val_recall_m: 0.3840\n",
            "Epoch 12/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2186 - acc: 0.6860 - recall_m: 0.6860 - val_loss: 0.2255 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 13/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.2169 - acc: 0.6860 - recall_m: 0.6860 - val_loss: 0.2228 - val_acc: 0.6540 - val_recall_m: 0.6540\n",
            "Epoch 14/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2134 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2298 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 15/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2127 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2383 - val_acc: 0.6414 - val_recall_m: 0.6414\n",
            "Epoch 16/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2108 - acc: 0.6921 - recall_m: 0.6921 - val_loss: 0.2317 - val_acc: 0.6540 - val_recall_m: 0.6540\n",
            "Epoch 17/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2072 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2312 - val_acc: 0.6667 - val_recall_m: 0.6667\n",
            "Epoch 18/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2112 - acc: 0.6874 - recall_m: 0.6874 - val_loss: 0.2377 - val_acc: 0.6540 - val_recall_m: 0.6540\n",
            "Epoch 19/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2103 - acc: 0.6987 - recall_m: 0.6987 - val_loss: 0.2348 - val_acc: 0.6624 - val_recall_m: 0.6624\n",
            "Epoch 20/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2107 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2419 - val_acc: 0.6540 - val_recall_m: 0.6540\n",
            "Epoch 21/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2094 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.2632 - val_acc: 0.5190 - val_recall_m: 0.5190\n",
            "Epoch 22/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2064 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.2499 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 23/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2076 - acc: 0.6916 - recall_m: 0.6916 - val_loss: 0.2326 - val_acc: 0.6582 - val_recall_m: 0.6582\n",
            "Epoch 24/300\n",
            "2124/2124 [==============================] - 0s 219us/step - loss: 0.2120 - acc: 0.6902 - recall_m: 0.6902 - val_loss: 0.2255 - val_acc: 0.6709 - val_recall_m: 0.6709\n",
            "Epoch 25/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2089 - acc: 0.6860 - recall_m: 0.6860 - val_loss: 0.2394 - val_acc: 0.6414 - val_recall_m: 0.6414\n",
            "Epoch 26/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2088 - acc: 0.6968 - recall_m: 0.6968 - val_loss: 0.2533 - val_acc: 0.4895 - val_recall_m: 0.4895\n",
            "Epoch 27/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2097 - acc: 0.6836 - recall_m: 0.6836 - val_loss: 0.2822 - val_acc: 0.4430 - val_recall_m: 0.4430\n",
            "Epoch 28/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.2085 - acc: 0.6897 - recall_m: 0.6897 - val_loss: 0.2827 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 29/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2082 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.2567 - val_acc: 0.5105 - val_recall_m: 0.5105\n",
            "Epoch 30/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2102 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2742 - val_acc: 0.4810 - val_recall_m: 0.4810\n",
            "Epoch 31/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2073 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.2812 - val_acc: 0.4768 - val_recall_m: 0.4768\n",
            "Epoch 32/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2074 - acc: 0.6916 - recall_m: 0.6916 - val_loss: 0.2683 - val_acc: 0.5105 - val_recall_m: 0.5105\n",
            "Epoch 33/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2057 - acc: 0.6940 - recall_m: 0.6940 - val_loss: 0.2799 - val_acc: 0.4937 - val_recall_m: 0.4937\n",
            "Epoch 34/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2068 - acc: 0.6916 - recall_m: 0.6916 - val_loss: 0.2747 - val_acc: 0.4937 - val_recall_m: 0.4937\n",
            "Epoch 35/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2057 - acc: 0.6883 - recall_m: 0.6883 - val_loss: 0.2793 - val_acc: 0.4810 - val_recall_m: 0.4810\n",
            "Epoch 36/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2083 - acc: 0.6897 - recall_m: 0.6897 - val_loss: 0.2850 - val_acc: 0.4641 - val_recall_m: 0.4641\n",
            "Epoch 37/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.2100 - acc: 0.6935 - recall_m: 0.6935 - val_loss: 0.2955 - val_acc: 0.4388 - val_recall_m: 0.4388\n",
            "Epoch 38/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2073 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2956 - val_acc: 0.4430 - val_recall_m: 0.4430\n",
            "Epoch 39/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2081 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.2969 - val_acc: 0.4430 - val_recall_m: 0.4430\n",
            "Epoch 40/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2077 - acc: 0.6902 - recall_m: 0.6902 - val_loss: 0.3064 - val_acc: 0.4219 - val_recall_m: 0.4219\n",
            "Epoch 41/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2062 - acc: 0.6992 - recall_m: 0.6992 - val_loss: 0.3148 - val_acc: 0.4219 - val_recall_m: 0.4219\n",
            "Epoch 42/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2073 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.3188 - val_acc: 0.4008 - val_recall_m: 0.4008\n",
            "Epoch 43/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2051 - acc: 0.6926 - recall_m: 0.6926 - val_loss: 0.2913 - val_acc: 0.4557 - val_recall_m: 0.4557\n",
            "Epoch 44/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2078 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.2941 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 45/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2085 - acc: 0.6930 - recall_m: 0.6930 - val_loss: 0.3066 - val_acc: 0.4346 - val_recall_m: 0.4346\n",
            "Epoch 46/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2053 - acc: 0.6926 - recall_m: 0.6926 - val_loss: 0.2849 - val_acc: 0.4726 - val_recall_m: 0.4726\n",
            "Epoch 47/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2043 - acc: 0.6982 - recall_m: 0.6982 - val_loss: 0.2791 - val_acc: 0.4810 - val_recall_m: 0.4810\n",
            "Epoch 48/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2058 - acc: 0.6954 - recall_m: 0.6954 - val_loss: 0.2676 - val_acc: 0.5190 - val_recall_m: 0.5190\n",
            "Epoch 49/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2056 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.2581 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 50/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2044 - acc: 0.6907 - recall_m: 0.6907 - val_loss: 0.2984 - val_acc: 0.4515 - val_recall_m: 0.4515\n",
            "Epoch 51/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2038 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.3246 - val_acc: 0.4008 - val_recall_m: 0.4008\n",
            "Epoch 52/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2044 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.3011 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 53/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2032 - acc: 0.7010 - recall_m: 0.7010 - val_loss: 0.2996 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 54/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2055 - acc: 0.6921 - recall_m: 0.6921 - val_loss: 0.2981 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 55/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2052 - acc: 0.6968 - recall_m: 0.6968 - val_loss: 0.2846 - val_acc: 0.4557 - val_recall_m: 0.4557\n",
            "Epoch 56/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2053 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.2633 - val_acc: 0.6371 - val_recall_m: 0.6371\n",
            "Epoch 57/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2034 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.2857 - val_acc: 0.4726 - val_recall_m: 0.4726\n",
            "Epoch 58/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2040 - acc: 0.6987 - recall_m: 0.6987 - val_loss: 0.2841 - val_acc: 0.4684 - val_recall_m: 0.4684\n",
            "Epoch 59/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2053 - acc: 0.6973 - recall_m: 0.6973 - val_loss: 0.2878 - val_acc: 0.4684 - val_recall_m: 0.4684\n",
            "Epoch 60/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2051 - acc: 0.6968 - recall_m: 0.6968 - val_loss: 0.3073 - val_acc: 0.4430 - val_recall_m: 0.4430\n",
            "Epoch 61/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2036 - acc: 0.7020 - recall_m: 0.7020 - val_loss: 0.3000 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 62/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2050 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.3111 - val_acc: 0.4093 - val_recall_m: 0.4093\n",
            "Epoch 63/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2051 - acc: 0.6940 - recall_m: 0.6940 - val_loss: 0.2780 - val_acc: 0.4684 - val_recall_m: 0.4684\n",
            "Epoch 64/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.2053 - acc: 0.6907 - recall_m: 0.6907 - val_loss: 0.3119 - val_acc: 0.3840 - val_recall_m: 0.3840\n",
            "Epoch 65/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2045 - acc: 0.6949 - recall_m: 0.6949 - val_loss: 0.3038 - val_acc: 0.4051 - val_recall_m: 0.4051\n",
            "Epoch 66/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2049 - acc: 0.6992 - recall_m: 0.6992 - val_loss: 0.2839 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 67/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2036 - acc: 0.6968 - recall_m: 0.6968 - val_loss: 0.2841 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 68/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2056 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.3019 - val_acc: 0.3755 - val_recall_m: 0.3755\n",
            "Epoch 69/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2045 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.3090 - val_acc: 0.3586 - val_recall_m: 0.3586\n",
            "Epoch 70/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2029 - acc: 0.6968 - recall_m: 0.6968 - val_loss: 0.2826 - val_acc: 0.4473 - val_recall_m: 0.4473\n",
            "Epoch 71/300\n",
            "2124/2124 [==============================] - 0s 217us/step - loss: 0.2042 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2757 - val_acc: 0.4515 - val_recall_m: 0.4515\n",
            "Epoch 72/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2049 - acc: 0.6921 - recall_m: 0.6921 - val_loss: 0.3048 - val_acc: 0.3797 - val_recall_m: 0.3797\n",
            "Epoch 73/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2051 - acc: 0.6959 - recall_m: 0.6959 - val_loss: 0.2813 - val_acc: 0.4557 - val_recall_m: 0.4557\n",
            "Epoch 74/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2028 - acc: 0.6977 - recall_m: 0.6977 - val_loss: 0.2967 - val_acc: 0.4262 - val_recall_m: 0.4262\n",
            "Epoch 75/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2042 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.3107 - val_acc: 0.3671 - val_recall_m: 0.3671\n",
            "Epoch 76/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2016 - acc: 0.7024 - recall_m: 0.7024 - val_loss: 0.3423 - val_acc: 0.2954 - val_recall_m: 0.2954\n",
            "Epoch 77/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2058 - acc: 0.6987 - recall_m: 0.6987 - val_loss: 0.3075 - val_acc: 0.3502 - val_recall_m: 0.3502\n",
            "Epoch 78/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2048 - acc: 0.6916 - recall_m: 0.6916 - val_loss: 0.3144 - val_acc: 0.3713 - val_recall_m: 0.3713\n",
            "Epoch 79/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.2021 - acc: 0.6982 - recall_m: 0.6982 - val_loss: 0.2869 - val_acc: 0.5612 - val_recall_m: 0.5612\n",
            "Epoch 80/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2014 - acc: 0.6992 - recall_m: 0.6992 - val_loss: 0.2611 - val_acc: 0.6160 - val_recall_m: 0.6160\n",
            "Epoch 81/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.2033 - acc: 0.6911 - recall_m: 0.6911 - val_loss: 0.2886 - val_acc: 0.4515 - val_recall_m: 0.4515\n",
            "Epoch 82/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2020 - acc: 0.7010 - recall_m: 0.7010 - val_loss: 0.2569 - val_acc: 0.6245 - val_recall_m: 0.6245\n",
            "Epoch 83/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2036 - acc: 0.6926 - recall_m: 0.6926 - val_loss: 0.2674 - val_acc: 0.6203 - val_recall_m: 0.6203\n",
            "Epoch 84/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2023 - acc: 0.6902 - recall_m: 0.6902 - val_loss: 0.2473 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 85/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2053 - acc: 0.6982 - recall_m: 0.6982 - val_loss: 0.2527 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 86/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.2032 - acc: 0.6987 - recall_m: 0.6987 - val_loss: 0.2470 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 87/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.2023 - acc: 0.6963 - recall_m: 0.6963 - val_loss: 0.2709 - val_acc: 0.5949 - val_recall_m: 0.5949\n",
            "Epoch 88/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2020 - acc: 0.6954 - recall_m: 0.6954 - val_loss: 0.2404 - val_acc: 0.6329 - val_recall_m: 0.6329\n",
            "Epoch 89/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.2015 - acc: 0.7001 - recall_m: 0.7001 - val_loss: 0.2602 - val_acc: 0.5907 - val_recall_m: 0.5907\n",
            "Epoch 90/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.2016 - acc: 0.6944 - recall_m: 0.6944 - val_loss: 0.2317 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 91/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2021 - acc: 0.7006 - recall_m: 0.7006 - val_loss: 0.2197 - val_acc: 0.6498 - val_recall_m: 0.6498\n",
            "Epoch 92/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2000 - acc: 0.7029 - recall_m: 0.7029 - val_loss: 0.2594 - val_acc: 0.5443 - val_recall_m: 0.5443\n",
            "Epoch 93/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1985 - acc: 0.7020 - recall_m: 0.7020 - val_loss: 0.2260 - val_acc: 0.6540 - val_recall_m: 0.6540\n",
            "Epoch 94/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.2015 - acc: 0.6987 - recall_m: 0.6987 - val_loss: 0.2613 - val_acc: 0.5949 - val_recall_m: 0.5949\n",
            "Epoch 95/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1993 - acc: 0.7043 - recall_m: 0.7043 - val_loss: 0.3161 - val_acc: 0.4684 - val_recall_m: 0.4684\n",
            "Epoch 96/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.2016 - acc: 0.6968 - recall_m: 0.6968 - val_loss: 0.3419 - val_acc: 0.3671 - val_recall_m: 0.3671\n",
            "Epoch 97/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1962 - acc: 0.7053 - recall_m: 0.7053 - val_loss: 0.3003 - val_acc: 0.4684 - val_recall_m: 0.4684\n",
            "Epoch 98/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1965 - acc: 0.7090 - recall_m: 0.7090 - val_loss: 0.3013 - val_acc: 0.4388 - val_recall_m: 0.4388\n",
            "Epoch 99/300\n",
            "2124/2124 [==============================] - 0s 219us/step - loss: 0.1955 - acc: 0.7147 - recall_m: 0.7147 - val_loss: 0.2621 - val_acc: 0.5907 - val_recall_m: 0.5907\n",
            "Epoch 100/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1951 - acc: 0.7034 - recall_m: 0.7034 - val_loss: 0.2658 - val_acc: 0.5907 - val_recall_m: 0.5907\n",
            "Epoch 101/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1932 - acc: 0.7166 - recall_m: 0.7166 - val_loss: 0.2660 - val_acc: 0.5823 - val_recall_m: 0.5823\n",
            "Epoch 102/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1856 - acc: 0.7298 - recall_m: 0.7298 - val_loss: 0.2170 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 103/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1911 - acc: 0.7137 - recall_m: 0.7137 - val_loss: 0.2082 - val_acc: 0.6962 - val_recall_m: 0.6962\n",
            "Epoch 104/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1899 - acc: 0.7246 - recall_m: 0.7246 - val_loss: 0.1863 - val_acc: 0.7300 - val_recall_m: 0.7300\n",
            "Epoch 105/300\n",
            "2124/2124 [==============================] - 0s 207us/step - loss: 0.1885 - acc: 0.7255 - recall_m: 0.7255 - val_loss: 0.2790 - val_acc: 0.5359 - val_recall_m: 0.5359\n",
            "Epoch 106/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1855 - acc: 0.7307 - recall_m: 0.7307 - val_loss: 0.2843 - val_acc: 0.4810 - val_recall_m: 0.4810\n",
            "Epoch 107/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1843 - acc: 0.7359 - recall_m: 0.7359 - val_loss: 0.2204 - val_acc: 0.6835 - val_recall_m: 0.6835\n",
            "Epoch 108/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1836 - acc: 0.7302 - recall_m: 0.7302 - val_loss: 0.2146 - val_acc: 0.6920 - val_recall_m: 0.6920\n",
            "Epoch 109/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1853 - acc: 0.7302 - recall_m: 0.7302 - val_loss: 0.1523 - val_acc: 0.8101 - val_recall_m: 0.8101\n",
            "Epoch 110/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1805 - acc: 0.7462 - recall_m: 0.7462 - val_loss: 0.1765 - val_acc: 0.7468 - val_recall_m: 0.7468\n",
            "Epoch 111/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1904 - acc: 0.7208 - recall_m: 0.7208 - val_loss: 0.2121 - val_acc: 0.6962 - val_recall_m: 0.6962\n",
            "Epoch 112/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1851 - acc: 0.7283 - recall_m: 0.7283 - val_loss: 0.1804 - val_acc: 0.7342 - val_recall_m: 0.7342\n",
            "Epoch 113/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1820 - acc: 0.7326 - recall_m: 0.7326 - val_loss: 0.2021 - val_acc: 0.7046 - val_recall_m: 0.7046\n",
            "Epoch 114/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1793 - acc: 0.7491 - recall_m: 0.7491 - val_loss: 0.1854 - val_acc: 0.7215 - val_recall_m: 0.7215\n",
            "Epoch 115/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1823 - acc: 0.7345 - recall_m: 0.7345 - val_loss: 0.1696 - val_acc: 0.7553 - val_recall_m: 0.7553\n",
            "Epoch 116/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1776 - acc: 0.7396 - recall_m: 0.7396 - val_loss: 0.1995 - val_acc: 0.7089 - val_recall_m: 0.7089\n",
            "Epoch 117/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1775 - acc: 0.7519 - recall_m: 0.7519 - val_loss: 0.2419 - val_acc: 0.6160 - val_recall_m: 0.6160\n",
            "Epoch 118/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1774 - acc: 0.7444 - recall_m: 0.7444 - val_loss: 0.2567 - val_acc: 0.5949 - val_recall_m: 0.5949\n",
            "Epoch 119/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1758 - acc: 0.7528 - recall_m: 0.7528 - val_loss: 0.2369 - val_acc: 0.6329 - val_recall_m: 0.6329\n",
            "Epoch 120/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1776 - acc: 0.7415 - recall_m: 0.7415 - val_loss: 0.2658 - val_acc: 0.5401 - val_recall_m: 0.5401\n",
            "Epoch 121/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1762 - acc: 0.7476 - recall_m: 0.7476 - val_loss: 0.1931 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 122/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1753 - acc: 0.7533 - recall_m: 0.7533 - val_loss: 0.1884 - val_acc: 0.7173 - val_recall_m: 0.7173\n",
            "Epoch 123/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1712 - acc: 0.7613 - recall_m: 0.7613 - val_loss: 0.1584 - val_acc: 0.7722 - val_recall_m: 0.7722\n",
            "Epoch 124/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1744 - acc: 0.7542 - recall_m: 0.7542 - val_loss: 0.2049 - val_acc: 0.6793 - val_recall_m: 0.6793\n",
            "Epoch 125/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1721 - acc: 0.7552 - recall_m: 0.7552 - val_loss: 0.1937 - val_acc: 0.7089 - val_recall_m: 0.7089\n",
            "Epoch 126/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1728 - acc: 0.7622 - recall_m: 0.7622 - val_loss: 0.1974 - val_acc: 0.7089 - val_recall_m: 0.7089\n",
            "Epoch 127/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1750 - acc: 0.7594 - recall_m: 0.7594 - val_loss: 0.1839 - val_acc: 0.7257 - val_recall_m: 0.7257\n",
            "Epoch 128/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1780 - acc: 0.7491 - recall_m: 0.7491 - val_loss: 0.2532 - val_acc: 0.5527 - val_recall_m: 0.5527\n",
            "Epoch 129/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1669 - acc: 0.7604 - recall_m: 0.7604 - val_loss: 0.1975 - val_acc: 0.7131 - val_recall_m: 0.7131\n",
            "Epoch 130/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1694 - acc: 0.7726 - recall_m: 0.7726 - val_loss: 0.1845 - val_acc: 0.7426 - val_recall_m: 0.7426\n",
            "Epoch 131/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1690 - acc: 0.7589 - recall_m: 0.7589 - val_loss: 0.1575 - val_acc: 0.8101 - val_recall_m: 0.8101\n",
            "Epoch 132/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1680 - acc: 0.7575 - recall_m: 0.7575 - val_loss: 0.1276 - val_acc: 0.8692 - val_recall_m: 0.8692\n",
            "Epoch 133/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1639 - acc: 0.7665 - recall_m: 0.7665 - val_loss: 0.1278 - val_acc: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 134/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1671 - acc: 0.7688 - recall_m: 0.7688 - val_loss: 0.1257 - val_acc: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 135/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1637 - acc: 0.7731 - recall_m: 0.7731 - val_loss: 0.1399 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 136/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1706 - acc: 0.7618 - recall_m: 0.7618 - val_loss: 0.1311 - val_acc: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 137/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1668 - acc: 0.7707 - recall_m: 0.7707 - val_loss: 0.1380 - val_acc: 0.8354 - val_recall_m: 0.8354\n",
            "Epoch 138/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1666 - acc: 0.7604 - recall_m: 0.7604 - val_loss: 0.1621 - val_acc: 0.7932 - val_recall_m: 0.7932\n",
            "Epoch 139/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1610 - acc: 0.7815 - recall_m: 0.7815 - val_loss: 0.1486 - val_acc: 0.8143 - val_recall_m: 0.8143\n",
            "Epoch 140/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1588 - acc: 0.7778 - recall_m: 0.7778 - val_loss: 0.1553 - val_acc: 0.7932 - val_recall_m: 0.7932\n",
            "Epoch 141/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.1624 - acc: 0.7707 - recall_m: 0.7707 - val_loss: 0.1907 - val_acc: 0.7257 - val_recall_m: 0.7257\n",
            "Epoch 142/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1639 - acc: 0.7637 - recall_m: 0.7637 - val_loss: 0.1723 - val_acc: 0.7595 - val_recall_m: 0.7595\n",
            "Epoch 143/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1545 - acc: 0.7895 - recall_m: 0.7895 - val_loss: 0.1696 - val_acc: 0.7511 - val_recall_m: 0.7511\n",
            "Epoch 144/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1622 - acc: 0.7806 - recall_m: 0.7806 - val_loss: 0.1461 - val_acc: 0.7890 - val_recall_m: 0.7890\n",
            "Epoch 145/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1632 - acc: 0.7768 - recall_m: 0.7768 - val_loss: 0.1134 - val_acc: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 146/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.1607 - acc: 0.7797 - recall_m: 0.7797 - val_loss: 0.1239 - val_acc: 0.8481 - val_recall_m: 0.8481\n",
            "Epoch 147/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1598 - acc: 0.7844 - recall_m: 0.7844 - val_loss: 0.1409 - val_acc: 0.8017 - val_recall_m: 0.8017\n",
            "Epoch 148/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1530 - acc: 0.7853 - recall_m: 0.7853 - val_loss: 0.1426 - val_acc: 0.8017 - val_recall_m: 0.8017\n",
            "Epoch 149/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1605 - acc: 0.7764 - recall_m: 0.7764 - val_loss: 0.1477 - val_acc: 0.8059 - val_recall_m: 0.8059\n",
            "Epoch 150/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1573 - acc: 0.7834 - recall_m: 0.7834 - val_loss: 0.1281 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 151/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1564 - acc: 0.7844 - recall_m: 0.7844 - val_loss: 0.1413 - val_acc: 0.8017 - val_recall_m: 0.8017\n",
            "Epoch 152/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1615 - acc: 0.7801 - recall_m: 0.7801 - val_loss: 0.1466 - val_acc: 0.7975 - val_recall_m: 0.7975\n",
            "Epoch 153/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1607 - acc: 0.7806 - recall_m: 0.7806 - val_loss: 0.1840 - val_acc: 0.7468 - val_recall_m: 0.7468\n",
            "Epoch 154/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1585 - acc: 0.7778 - recall_m: 0.7778 - val_loss: 0.1371 - val_acc: 0.8101 - val_recall_m: 0.8101\n",
            "Epoch 155/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1514 - acc: 0.8004 - recall_m: 0.8004 - val_loss: 0.1350 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 156/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1582 - acc: 0.7768 - recall_m: 0.7768 - val_loss: 0.1330 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 157/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1536 - acc: 0.7806 - recall_m: 0.7806 - val_loss: 0.1261 - val_acc: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 158/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1669 - acc: 0.7712 - recall_m: 0.7712 - val_loss: 0.1558 - val_acc: 0.8059 - val_recall_m: 0.8059\n",
            "Epoch 159/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1529 - acc: 0.7952 - recall_m: 0.7952 - val_loss: 0.1165 - val_acc: 0.8523 - val_recall_m: 0.8523\n",
            "Epoch 160/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1573 - acc: 0.7787 - recall_m: 0.7787 - val_loss: 0.1943 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 161/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1501 - acc: 0.7895 - recall_m: 0.7895 - val_loss: 0.2321 - val_acc: 0.6287 - val_recall_m: 0.6287\n",
            "Epoch 162/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1558 - acc: 0.7867 - recall_m: 0.7867 - val_loss: 0.2255 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 163/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1558 - acc: 0.7825 - recall_m: 0.7825 - val_loss: 0.2400 - val_acc: 0.6245 - val_recall_m: 0.6245\n",
            "Epoch 164/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1577 - acc: 0.7834 - recall_m: 0.7834 - val_loss: 0.1903 - val_acc: 0.7215 - val_recall_m: 0.7215\n",
            "Epoch 165/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1546 - acc: 0.7952 - recall_m: 0.7952 - val_loss: 0.1823 - val_acc: 0.7384 - val_recall_m: 0.7384\n",
            "Epoch 166/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1561 - acc: 0.7848 - recall_m: 0.7848 - val_loss: 0.1972 - val_acc: 0.7089 - val_recall_m: 0.7089\n",
            "Epoch 167/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1550 - acc: 0.7867 - recall_m: 0.7867 - val_loss: 0.2057 - val_acc: 0.7004 - val_recall_m: 0.7004\n",
            "Epoch 168/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1551 - acc: 0.7919 - recall_m: 0.7919 - val_loss: 0.1944 - val_acc: 0.7046 - val_recall_m: 0.7046\n",
            "Epoch 169/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1520 - acc: 0.7966 - recall_m: 0.7966 - val_loss: 0.2128 - val_acc: 0.6751 - val_recall_m: 0.6751\n",
            "Epoch 170/300\n",
            "2124/2124 [==============================] - 0s 218us/step - loss: 0.1546 - acc: 0.7900 - recall_m: 0.7900 - val_loss: 0.1911 - val_acc: 0.7426 - val_recall_m: 0.7426\n",
            "Epoch 171/300\n",
            "2124/2124 [==============================] - 0s 221us/step - loss: 0.1514 - acc: 0.7919 - recall_m: 0.7919 - val_loss: 0.1520 - val_acc: 0.7975 - val_recall_m: 0.7975\n",
            "Epoch 172/300\n",
            "2124/2124 [==============================] - 0s 221us/step - loss: 0.1497 - acc: 0.7957 - recall_m: 0.7957 - val_loss: 0.1729 - val_acc: 0.7595 - val_recall_m: 0.7595\n",
            "Epoch 173/300\n",
            "2124/2124 [==============================] - 0s 217us/step - loss: 0.1551 - acc: 0.7867 - recall_m: 0.7867 - val_loss: 0.1354 - val_acc: 0.8186 - val_recall_m: 0.8186\n",
            "Epoch 174/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1501 - acc: 0.7971 - recall_m: 0.7971 - val_loss: 0.1324 - val_acc: 0.8101 - val_recall_m: 0.8101\n",
            "Epoch 175/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1512 - acc: 0.7877 - recall_m: 0.7877 - val_loss: 0.1784 - val_acc: 0.7426 - val_recall_m: 0.7426\n",
            "Epoch 176/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1576 - acc: 0.7928 - recall_m: 0.7928 - val_loss: 0.0904 - val_acc: 0.8776 - val_recall_m: 0.8776\n",
            "Epoch 177/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1548 - acc: 0.7872 - recall_m: 0.7872 - val_loss: 0.1335 - val_acc: 0.8186 - val_recall_m: 0.8186\n",
            "Epoch 178/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1485 - acc: 0.8041 - recall_m: 0.8041 - val_loss: 0.1038 - val_acc: 0.8565 - val_recall_m: 0.8565\n",
            "Epoch 179/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1554 - acc: 0.7943 - recall_m: 0.7943 - val_loss: 0.1302 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 180/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1577 - acc: 0.7872 - recall_m: 0.7872 - val_loss: 0.0984 - val_acc: 0.8692 - val_recall_m: 0.8692\n",
            "Epoch 181/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1531 - acc: 0.7919 - recall_m: 0.7919 - val_loss: 0.1231 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 182/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1530 - acc: 0.7877 - recall_m: 0.7877 - val_loss: 0.1068 - val_acc: 0.8565 - val_recall_m: 0.8565\n",
            "Epoch 183/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1531 - acc: 0.7895 - recall_m: 0.7895 - val_loss: 0.1052 - val_acc: 0.8565 - val_recall_m: 0.8565\n",
            "Epoch 184/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1547 - acc: 0.7848 - recall_m: 0.7848 - val_loss: 0.0853 - val_acc: 0.8903 - val_recall_m: 0.8903\n",
            "Epoch 185/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1523 - acc: 0.7900 - recall_m: 0.7900 - val_loss: 0.1160 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 186/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1521 - acc: 0.7966 - recall_m: 0.7966 - val_loss: 0.0846 - val_acc: 0.8945 - val_recall_m: 0.8945\n",
            "Epoch 187/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1453 - acc: 0.8027 - recall_m: 0.8027 - val_loss: 0.0992 - val_acc: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 188/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1485 - acc: 0.7985 - recall_m: 0.7985 - val_loss: 0.0962 - val_acc: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 189/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1510 - acc: 0.7994 - recall_m: 0.7994 - val_loss: 0.0845 - val_acc: 0.8945 - val_recall_m: 0.8945\n",
            "Epoch 190/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1523 - acc: 0.7947 - recall_m: 0.7947 - val_loss: 0.0514 - val_acc: 0.9620 - val_recall_m: 0.9620\n",
            "Epoch 191/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1512 - acc: 0.7891 - recall_m: 0.7891 - val_loss: 0.0683 - val_acc: 0.9283 - val_recall_m: 0.9283\n",
            "Epoch 192/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1459 - acc: 0.8013 - recall_m: 0.8013 - val_loss: 0.0868 - val_acc: 0.8903 - val_recall_m: 0.8903\n",
            "Epoch 193/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1471 - acc: 0.7999 - recall_m: 0.7999 - val_loss: 0.0995 - val_acc: 0.8692 - val_recall_m: 0.8692\n",
            "Epoch 194/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1543 - acc: 0.7877 - recall_m: 0.7877 - val_loss: 0.1138 - val_acc: 0.8354 - val_recall_m: 0.8354\n",
            "Epoch 195/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1512 - acc: 0.7910 - recall_m: 0.7910 - val_loss: 0.0863 - val_acc: 0.8903 - val_recall_m: 0.8903\n",
            "Epoch 196/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1487 - acc: 0.8013 - recall_m: 0.8013 - val_loss: 0.1236 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 197/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1477 - acc: 0.7994 - recall_m: 0.7994 - val_loss: 0.1057 - val_acc: 0.8523 - val_recall_m: 0.8523\n",
            "Epoch 198/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1513 - acc: 0.8046 - recall_m: 0.8046 - val_loss: 0.1052 - val_acc: 0.8523 - val_recall_m: 0.8523\n",
            "Epoch 199/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1510 - acc: 0.7985 - recall_m: 0.7985 - val_loss: 0.0890 - val_acc: 0.8776 - val_recall_m: 0.8776\n",
            "Epoch 200/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1548 - acc: 0.7867 - recall_m: 0.7867 - val_loss: 0.0693 - val_acc: 0.9114 - val_recall_m: 0.9114\n",
            "Epoch 201/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1500 - acc: 0.7914 - recall_m: 0.7914 - val_loss: 0.0709 - val_acc: 0.9156 - val_recall_m: 0.9156\n",
            "Epoch 202/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1469 - acc: 0.8008 - recall_m: 0.8008 - val_loss: 0.0747 - val_acc: 0.9030 - val_recall_m: 0.9030\n",
            "Epoch 203/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1449 - acc: 0.7999 - recall_m: 0.7999 - val_loss: 0.0817 - val_acc: 0.8945 - val_recall_m: 0.8945\n",
            "Epoch 204/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1424 - acc: 0.8041 - recall_m: 0.8041 - val_loss: 0.0784 - val_acc: 0.9030 - val_recall_m: 0.9030\n",
            "Epoch 205/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1481 - acc: 0.8056 - recall_m: 0.8056 - val_loss: 0.1055 - val_acc: 0.8523 - val_recall_m: 0.8523\n",
            "Epoch 206/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1456 - acc: 0.8023 - recall_m: 0.8023 - val_loss: 0.0815 - val_acc: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 207/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1490 - acc: 0.8041 - recall_m: 0.8041 - val_loss: 0.0932 - val_acc: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 208/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1418 - acc: 0.8070 - recall_m: 0.8070 - val_loss: 0.0926 - val_acc: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 209/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1516 - acc: 0.7924 - recall_m: 0.7924 - val_loss: 0.1062 - val_acc: 0.8523 - val_recall_m: 0.8523\n",
            "Epoch 210/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1424 - acc: 0.8084 - recall_m: 0.8084 - val_loss: 0.0815 - val_acc: 0.8861 - val_recall_m: 0.8861\n",
            "Epoch 211/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1425 - acc: 0.8084 - recall_m: 0.8084 - val_loss: 0.1092 - val_acc: 0.8354 - val_recall_m: 0.8354\n",
            "Epoch 212/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1459 - acc: 0.8041 - recall_m: 0.8041 - val_loss: 0.1075 - val_acc: 0.8523 - val_recall_m: 0.8523\n",
            "Epoch 213/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1490 - acc: 0.8027 - recall_m: 0.8027 - val_loss: 0.1189 - val_acc: 0.8312 - val_recall_m: 0.8312\n",
            "Epoch 214/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1464 - acc: 0.7999 - recall_m: 0.7999 - val_loss: 0.0758 - val_acc: 0.8987 - val_recall_m: 0.8987\n",
            "Epoch 215/300\n",
            "2124/2124 [==============================] - 0s 217us/step - loss: 0.1445 - acc: 0.8089 - recall_m: 0.8089 - val_loss: 0.1193 - val_acc: 0.8312 - val_recall_m: 0.8312\n",
            "Epoch 216/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1479 - acc: 0.7961 - recall_m: 0.7961 - val_loss: 0.1252 - val_acc: 0.8228 - val_recall_m: 0.8228\n",
            "Epoch 217/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1466 - acc: 0.7985 - recall_m: 0.7985 - val_loss: 0.0838 - val_acc: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 218/300\n",
            "2124/2124 [==============================] - 0s 221us/step - loss: 0.1449 - acc: 0.8023 - recall_m: 0.8023 - val_loss: 0.1104 - val_acc: 0.8397 - val_recall_m: 0.8397\n",
            "Epoch 219/300\n",
            "2124/2124 [==============================] - 0s 217us/step - loss: 0.1428 - acc: 0.8089 - recall_m: 0.8089 - val_loss: 0.1259 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 220/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1476 - acc: 0.7957 - recall_m: 0.7957 - val_loss: 0.1259 - val_acc: 0.8270 - val_recall_m: 0.8270\n",
            "Epoch 221/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1447 - acc: 0.8056 - recall_m: 0.8056 - val_loss: 0.1002 - val_acc: 0.8439 - val_recall_m: 0.8439\n",
            "Epoch 222/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1443 - acc: 0.8093 - recall_m: 0.8093 - val_loss: 0.0905 - val_acc: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 223/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1380 - acc: 0.8145 - recall_m: 0.8145 - val_loss: 0.1325 - val_acc: 0.8228 - val_recall_m: 0.8228\n",
            "Epoch 224/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1437 - acc: 0.8060 - recall_m: 0.8060 - val_loss: 0.1191 - val_acc: 0.8312 - val_recall_m: 0.8312\n",
            "Epoch 225/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1428 - acc: 0.8074 - recall_m: 0.8074 - val_loss: 0.1223 - val_acc: 0.8186 - val_recall_m: 0.8186\n",
            "Epoch 226/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1489 - acc: 0.7910 - recall_m: 0.7910 - val_loss: 0.1193 - val_acc: 0.8228 - val_recall_m: 0.8228\n",
            "Epoch 227/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1424 - acc: 0.8051 - recall_m: 0.8051 - val_loss: 0.1187 - val_acc: 0.8186 - val_recall_m: 0.8186\n",
            "Epoch 228/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1450 - acc: 0.8079 - recall_m: 0.8079 - val_loss: 0.1209 - val_acc: 0.8228 - val_recall_m: 0.8228\n",
            "Epoch 229/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1442 - acc: 0.8084 - recall_m: 0.8084 - val_loss: 0.1712 - val_acc: 0.7637 - val_recall_m: 0.7637\n",
            "Epoch 230/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1390 - acc: 0.8136 - recall_m: 0.8136 - val_loss: 0.1784 - val_acc: 0.7637 - val_recall_m: 0.7637\n",
            "Epoch 231/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1426 - acc: 0.8051 - recall_m: 0.8051 - val_loss: 0.1964 - val_acc: 0.7300 - val_recall_m: 0.7300\n",
            "Epoch 232/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1364 - acc: 0.8164 - recall_m: 0.8164 - val_loss: 0.1473 - val_acc: 0.7975 - val_recall_m: 0.7975\n",
            "Epoch 233/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1385 - acc: 0.8070 - recall_m: 0.8070 - val_loss: 0.1633 - val_acc: 0.7890 - val_recall_m: 0.7890\n",
            "Epoch 234/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1363 - acc: 0.8211 - recall_m: 0.8211 - val_loss: 0.1527 - val_acc: 0.7975 - val_recall_m: 0.7975\n",
            "Epoch 235/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1422 - acc: 0.8084 - recall_m: 0.8084 - val_loss: 0.1595 - val_acc: 0.7932 - val_recall_m: 0.7932\n",
            "Epoch 236/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1426 - acc: 0.8117 - recall_m: 0.8117 - val_loss: 0.1368 - val_acc: 0.8059 - val_recall_m: 0.8059\n",
            "Epoch 237/300\n",
            "2124/2124 [==============================] - 0s 220us/step - loss: 0.1454 - acc: 0.7976 - recall_m: 0.7976 - val_loss: 0.1437 - val_acc: 0.8143 - val_recall_m: 0.8143\n",
            "Epoch 238/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1395 - acc: 0.8056 - recall_m: 0.8056 - val_loss: 0.0672 - val_acc: 0.9072 - val_recall_m: 0.9072\n",
            "Epoch 239/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1397 - acc: 0.8121 - recall_m: 0.8121 - val_loss: 0.0761 - val_acc: 0.8945 - val_recall_m: 0.8945\n",
            "Epoch 240/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1401 - acc: 0.8145 - recall_m: 0.8145 - val_loss: 0.0887 - val_acc: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 241/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1356 - acc: 0.8216 - recall_m: 0.8216 - val_loss: 0.0948 - val_acc: 0.8650 - val_recall_m: 0.8650\n",
            "Epoch 242/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1444 - acc: 0.8084 - recall_m: 0.8084 - val_loss: 0.0887 - val_acc: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 243/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1354 - acc: 0.8202 - recall_m: 0.8202 - val_loss: 0.0811 - val_acc: 0.8945 - val_recall_m: 0.8945\n",
            "Epoch 244/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1417 - acc: 0.8173 - recall_m: 0.8173 - val_loss: 0.0808 - val_acc: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 245/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1422 - acc: 0.8065 - recall_m: 0.8065 - val_loss: 0.0852 - val_acc: 0.8819 - val_recall_m: 0.8819\n",
            "Epoch 246/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1376 - acc: 0.8121 - recall_m: 0.8121 - val_loss: 0.0820 - val_acc: 0.8987 - val_recall_m: 0.8987\n",
            "Epoch 247/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1456 - acc: 0.8089 - recall_m: 0.8089 - val_loss: 0.0850 - val_acc: 0.8903 - val_recall_m: 0.8903\n",
            "Epoch 248/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1433 - acc: 0.8074 - recall_m: 0.8074 - val_loss: 0.0796 - val_acc: 0.8945 - val_recall_m: 0.8945\n",
            "Epoch 249/300\n",
            "2124/2124 [==============================] - 0s 215us/step - loss: 0.1365 - acc: 0.8192 - recall_m: 0.8192 - val_loss: 0.1141 - val_acc: 0.8439 - val_recall_m: 0.8439\n",
            "Epoch 250/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1406 - acc: 0.8136 - recall_m: 0.8136 - val_loss: 0.1058 - val_acc: 0.8608 - val_recall_m: 0.8608\n",
            "Epoch 251/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1429 - acc: 0.8084 - recall_m: 0.8084 - val_loss: 0.0791 - val_acc: 0.8987 - val_recall_m: 0.8987\n",
            "Epoch 252/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1446 - acc: 0.8070 - recall_m: 0.8070 - val_loss: 0.0884 - val_acc: 0.8734 - val_recall_m: 0.8734\n",
            "Epoch 253/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1357 - acc: 0.8183 - recall_m: 0.8183 - val_loss: 0.0853 - val_acc: 0.8776 - val_recall_m: 0.8776\n",
            "Epoch 254/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1359 - acc: 0.8159 - recall_m: 0.8159 - val_loss: 0.0754 - val_acc: 0.8945 - val_recall_m: 0.8945\n",
            "Epoch 255/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1388 - acc: 0.8098 - recall_m: 0.8098 - val_loss: 0.1063 - val_acc: 0.8439 - val_recall_m: 0.8439\n",
            "Epoch 256/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1432 - acc: 0.8103 - recall_m: 0.8103 - val_loss: 0.0970 - val_acc: 0.8608 - val_recall_m: 0.8608\n",
            "Epoch 257/300\n",
            "2124/2124 [==============================] - 0s 214us/step - loss: 0.1401 - acc: 0.8089 - recall_m: 0.8089 - val_loss: 0.1166 - val_acc: 0.8354 - val_recall_m: 0.8354\n",
            "Epoch 258/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1342 - acc: 0.8239 - recall_m: 0.8239 - val_loss: 0.0910 - val_acc: 0.8861 - val_recall_m: 0.8861\n",
            "Epoch 259/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1372 - acc: 0.8150 - recall_m: 0.8150 - val_loss: 0.1059 - val_acc: 0.8481 - val_recall_m: 0.8481\n",
            "Epoch 260/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1329 - acc: 0.8286 - recall_m: 0.8286 - val_loss: 0.0894 - val_acc: 0.8776 - val_recall_m: 0.8776\n",
            "Epoch 261/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1454 - acc: 0.8056 - recall_m: 0.8056 - val_loss: 0.2053 - val_acc: 0.7257 - val_recall_m: 0.7257\n",
            "Epoch 262/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1410 - acc: 0.8136 - recall_m: 0.8136 - val_loss: 0.1316 - val_acc: 0.8228 - val_recall_m: 0.8228\n",
            "Epoch 263/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1383 - acc: 0.8169 - recall_m: 0.8169 - val_loss: 0.1857 - val_acc: 0.7553 - val_recall_m: 0.7553\n",
            "Epoch 264/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1393 - acc: 0.8145 - recall_m: 0.8145 - val_loss: 0.1371 - val_acc: 0.8186 - val_recall_m: 0.8186\n",
            "Epoch 265/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1365 - acc: 0.8136 - recall_m: 0.8136 - val_loss: 0.1116 - val_acc: 0.8523 - val_recall_m: 0.8523\n",
            "Epoch 266/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1400 - acc: 0.8136 - recall_m: 0.8136 - val_loss: 0.1467 - val_acc: 0.8143 - val_recall_m: 0.8143\n",
            "Epoch 267/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1370 - acc: 0.8169 - recall_m: 0.8169 - val_loss: 0.1545 - val_acc: 0.8017 - val_recall_m: 0.8017\n",
            "Epoch 268/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1412 - acc: 0.8145 - recall_m: 0.8145 - val_loss: 0.1496 - val_acc: 0.7975 - val_recall_m: 0.7975\n",
            "Epoch 269/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1385 - acc: 0.8216 - recall_m: 0.8216 - val_loss: 0.1828 - val_acc: 0.7553 - val_recall_m: 0.7553\n",
            "Epoch 270/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1403 - acc: 0.8159 - recall_m: 0.8159 - val_loss: 0.1555 - val_acc: 0.7890 - val_recall_m: 0.7890\n",
            "Epoch 271/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1373 - acc: 0.8131 - recall_m: 0.8131 - val_loss: 0.1640 - val_acc: 0.7848 - val_recall_m: 0.7848\n",
            "Epoch 272/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1352 - acc: 0.8164 - recall_m: 0.8164 - val_loss: 0.1887 - val_acc: 0.7511 - val_recall_m: 0.7511\n",
            "Epoch 273/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1335 - acc: 0.8178 - recall_m: 0.8178 - val_loss: 0.1965 - val_acc: 0.7257 - val_recall_m: 0.7257\n",
            "Epoch 274/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1290 - acc: 0.8263 - recall_m: 0.8263 - val_loss: 0.2481 - val_acc: 0.6582 - val_recall_m: 0.6582\n",
            "Epoch 275/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1403 - acc: 0.8126 - recall_m: 0.8126 - val_loss: 0.1851 - val_acc: 0.7511 - val_recall_m: 0.7511\n",
            "Epoch 276/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1319 - acc: 0.8258 - recall_m: 0.8258 - val_loss: 0.1812 - val_acc: 0.7595 - val_recall_m: 0.7595\n",
            "Epoch 277/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1415 - acc: 0.8079 - recall_m: 0.8079 - val_loss: 0.1929 - val_acc: 0.7468 - val_recall_m: 0.7468\n",
            "Epoch 278/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1349 - acc: 0.8164 - recall_m: 0.8164 - val_loss: 0.1900 - val_acc: 0.7553 - val_recall_m: 0.7553\n",
            "Epoch 279/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1314 - acc: 0.8234 - recall_m: 0.8234 - val_loss: 0.1558 - val_acc: 0.8017 - val_recall_m: 0.8017\n",
            "Epoch 280/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1410 - acc: 0.8103 - recall_m: 0.8103 - val_loss: 0.2445 - val_acc: 0.6456 - val_recall_m: 0.6456\n",
            "Epoch 281/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1384 - acc: 0.8178 - recall_m: 0.8178 - val_loss: 0.2147 - val_acc: 0.7046 - val_recall_m: 0.7046\n",
            "Epoch 282/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1330 - acc: 0.8249 - recall_m: 0.8249 - val_loss: 0.2129 - val_acc: 0.7046 - val_recall_m: 0.7046\n",
            "Epoch 283/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1308 - acc: 0.8282 - recall_m: 0.8282 - val_loss: 0.1874 - val_acc: 0.7468 - val_recall_m: 0.7468\n",
            "Epoch 284/300\n",
            "2124/2124 [==============================] - 0s 206us/step - loss: 0.1349 - acc: 0.8249 - recall_m: 0.8249 - val_loss: 0.1595 - val_acc: 0.8059 - val_recall_m: 0.8059\n",
            "Epoch 285/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1374 - acc: 0.8126 - recall_m: 0.8126 - val_loss: 0.1725 - val_acc: 0.7890 - val_recall_m: 0.7890\n",
            "Epoch 286/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1305 - acc: 0.8263 - recall_m: 0.8263 - val_loss: 0.1718 - val_acc: 0.7932 - val_recall_m: 0.7932\n",
            "Epoch 287/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1364 - acc: 0.8178 - recall_m: 0.8178 - val_loss: 0.1839 - val_acc: 0.7722 - val_recall_m: 0.7722\n",
            "Epoch 288/300\n",
            "2124/2124 [==============================] - 0s 216us/step - loss: 0.1347 - acc: 0.8197 - recall_m: 0.8197 - val_loss: 0.2204 - val_acc: 0.6793 - val_recall_m: 0.6793\n",
            "Epoch 289/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1365 - acc: 0.8234 - recall_m: 0.8234 - val_loss: 0.2557 - val_acc: 0.6414 - val_recall_m: 0.6414\n",
            "Epoch 290/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1355 - acc: 0.8164 - recall_m: 0.8164 - val_loss: 0.2687 - val_acc: 0.6245 - val_recall_m: 0.6245\n",
            "Epoch 291/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1349 - acc: 0.8291 - recall_m: 0.8291 - val_loss: 0.2385 - val_acc: 0.6751 - val_recall_m: 0.6751\n",
            "Epoch 292/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1397 - acc: 0.8145 - recall_m: 0.8145 - val_loss: 0.1668 - val_acc: 0.7806 - val_recall_m: 0.7806\n",
            "Epoch 293/300\n",
            "2124/2124 [==============================] - 0s 208us/step - loss: 0.1365 - acc: 0.8253 - recall_m: 0.8253 - val_loss: 0.1456 - val_acc: 0.8143 - val_recall_m: 0.8143\n",
            "Epoch 294/300\n",
            "2124/2124 [==============================] - 0s 211us/step - loss: 0.1328 - acc: 0.8197 - recall_m: 0.8197 - val_loss: 0.1533 - val_acc: 0.7975 - val_recall_m: 0.7975\n",
            "Epoch 295/300\n",
            "2124/2124 [==============================] - 0s 213us/step - loss: 0.1324 - acc: 0.8267 - recall_m: 0.8267 - val_loss: 0.1643 - val_acc: 0.7848 - val_recall_m: 0.7848\n",
            "Epoch 296/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1298 - acc: 0.8300 - recall_m: 0.8300 - val_loss: 0.1927 - val_acc: 0.7468 - val_recall_m: 0.7468\n",
            "Epoch 297/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1274 - acc: 0.8258 - recall_m: 0.8258 - val_loss: 0.1674 - val_acc: 0.7722 - val_recall_m: 0.7722\n",
            "Epoch 298/300\n",
            "2124/2124 [==============================] - 0s 212us/step - loss: 0.1407 - acc: 0.8173 - recall_m: 0.8173 - val_loss: 0.1559 - val_acc: 0.7890 - val_recall_m: 0.7890\n",
            "Epoch 299/300\n",
            "2124/2124 [==============================] - 0s 209us/step - loss: 0.1349 - acc: 0.8211 - recall_m: 0.8211 - val_loss: 0.1394 - val_acc: 0.8143 - val_recall_m: 0.8143\n",
            "Epoch 300/300\n",
            "2124/2124 [==============================] - 0s 210us/step - loss: 0.1262 - acc: 0.8305 - recall_m: 0.8305 - val_loss: 0.1918 - val_acc: 0.7468 - val_recall_m: 0.7468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d0460a278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1FdGFad9kyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6f0387e2-2f7f-4709-efd5-8ee6a459aeec"
      },
      "source": [
        "cls.evaluate(x_te, y_te)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "591/591 [==============================] - 0s 141us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2296112567035075, 0.6785109984592335, 0.6785109984592335]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QYKIsSgHvqh",
        "colab_type": "text"
      },
      "source": [
        "## Os erros metodológicos\n",
        "\n",
        "1. Os parâmetros não tem referências, foram feitos no teste.\n",
        "\n",
        "2. O Word2Vec computa todos os valores do banco de dados, o que pode enviezar os valores do dicionário. Como Rosa Weber \"Pelo principio do colegiado, darei meu voto para seguir a maioria que será composta por mim\".\n",
        "\n",
        "3. Não há outro classificador para comparar.\n",
        "\n",
        "4. Não há medida estatistica para saber qual a chance desse modelo realmente funcionar em problemas do mundo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK4CtNKfAFwv",
        "colab_type": "text"
      },
      "source": [
        "## Referencias\n",
        "\n"
      ]
    }
  ]
}